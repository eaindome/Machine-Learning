{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e2635a",
   "metadata": {},
   "source": [
    "train.csv - The training set.\n",
    "Id Unique identifier for each observation.\n",
    "AB-GL Fifty-six anonymized health characteristics. All are numeric except for EJ, which is categorical.\n",
    "Class A binary target: 1 indicates the subject has been diagnosed with one of the three conditions, 0 indicates they have not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac707430",
   "metadata": {},
   "source": [
    "[Logistic Regression, Random Forest, Gradient Boosting Models (e.g., XGBoost, LightGBM, Support Vector Machines (SVM), Decision Trees, Naive Bayes, k-nearest neighbors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042a6eb",
   "metadata": {},
   "source": [
    "GridSearchCV\n",
    "RandomizedSearchCV\n",
    "Bayesian Optimization\n",
    "HyperOpt\n",
    "Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d420924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815517f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>...</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id        AB          AF          AH         AM        AR  \\\n",
       "0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n",
       "1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n",
       "2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n",
       "3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n",
       "4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n",
       "\n",
       "         AX        AY         AZ          BC  ...        FL        FR  \\\n",
       "0  0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855   \n",
       "1  3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n",
       "2  6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n",
       "3  3.685344  0.025578  11.053708    1.229900  ...  6.122162   0.49706   \n",
       "4  3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n",
       "\n",
       "         FS         GB          GE            GF         GH         GI  \\\n",
       "0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n",
       "1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n",
       "2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n",
       "3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n",
       "4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n",
       "\n",
       "          GL  Class  \n",
       "0   0.120343      1  \n",
       "1  21.978000      0  \n",
       "2   0.196941      0  \n",
       "3   0.155829      0  \n",
       "4   0.096614      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f102e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      557 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      615 non-null    float64\n",
      " 17  CC      614 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      616 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    object \n",
      " 41  EL      557 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      616 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      616 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      615 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      616 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(1), object(2)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84bb3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    395\n",
       "A    222\n",
       "Name: EJ, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EJ'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2da4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting categorical columns\n",
    "data = data.replace({'EJ':{'A':0, 'B':1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f51b25c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id        0\n",
       "AB        0\n",
       "AF        0\n",
       "AH        0\n",
       "AM        0\n",
       "AR        0\n",
       "AX        0\n",
       "AY        0\n",
       "AZ        0\n",
       "BC        0\n",
       "BD        0\n",
       "BN        0\n",
       "BP        0\n",
       "BQ       60\n",
       "BR        0\n",
       "BZ        0\n",
       "CB        2\n",
       "CC        3\n",
       "CD        0\n",
       "CF        0\n",
       "CH        0\n",
       "CL        0\n",
       "CR        0\n",
       "CS        0\n",
       "CU        0\n",
       "CW        0\n",
       "DA        0\n",
       "DE        0\n",
       "DF        0\n",
       "DH        0\n",
       "DI        0\n",
       "DL        0\n",
       "DN        0\n",
       "DU        1\n",
       "DV        0\n",
       "DY        0\n",
       "EB        0\n",
       "EE        0\n",
       "EG        0\n",
       "EH        0\n",
       "EJ        0\n",
       "EL       60\n",
       "EP        0\n",
       "EU        0\n",
       "FC        1\n",
       "FD        0\n",
       "FE        0\n",
       "FI        0\n",
       "FL        1\n",
       "FR        0\n",
       "FS        2\n",
       "GB        0\n",
       "GE        0\n",
       "GF        0\n",
       "GH        0\n",
       "GI        0\n",
       "GL        1\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6257b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing age values with the median value\n",
    "data['BQ'] = data['BQ'].fillna(data['BQ'].mean())\n",
    "data['CB'] = data['CB'].fillna(data['CB'].mean())\n",
    "data['CC'] = data['CC'].fillna(data['CC'].mean())\n",
    "data['DU'] = data['DU'].fillna(data['DU'].mean())\n",
    "data['EL'] = data['EL'].fillna(data['EL'].mean())\n",
    "\n",
    "data['FC'] = data['FC'].fillna(data['FC'].mean())\n",
    "data['FL'] = data['FL'].fillna(data['FL'].mean())\n",
    "data['FS'] = data['FS'].fillna(data['FS'].mean())\n",
    "data['GL'] = data['GL'].fillna(data['GL'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848a725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc533d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8119f380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      617 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      617 non-null    float64\n",
      " 17  CC      617 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      617 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    int64  \n",
      " 41  EL      617 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      617 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      617 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      617 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      617 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(2), object(1)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e44dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
       "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
       "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
       "       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
       "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38af55e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1    108\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1bf54f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.477149</td>\n",
       "      <td>3502.013221</td>\n",
       "      <td>118.624513</td>\n",
       "      <td>38.968552</td>\n",
       "      <td>10.128242</td>\n",
       "      <td>5.545576</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>10.566447</td>\n",
       "      <td>8.053012</td>\n",
       "      <td>5350.388655</td>\n",
       "      <td>...</td>\n",
       "      <td>5.433199</td>\n",
       "      <td>3.533905</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>20.724856</td>\n",
       "      <td>131.714987</td>\n",
       "      <td>14679.595398</td>\n",
       "      <td>31.489716</td>\n",
       "      <td>50.584437</td>\n",
       "      <td>8.530961</td>\n",
       "      <td>0.175041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468388</td>\n",
       "      <td>2300.322717</td>\n",
       "      <td>127.838950</td>\n",
       "      <td>69.728226</td>\n",
       "      <td>10.518877</td>\n",
       "      <td>2.551696</td>\n",
       "      <td>0.416817</td>\n",
       "      <td>4.350645</td>\n",
       "      <td>65.166943</td>\n",
       "      <td>3021.326641</td>\n",
       "      <td>...</td>\n",
       "      <td>11.486922</td>\n",
       "      <td>50.181948</td>\n",
       "      <td>1.303244</td>\n",
       "      <td>9.991907</td>\n",
       "      <td>144.181524</td>\n",
       "      <td>19352.959387</td>\n",
       "      <td>9.864239</td>\n",
       "      <td>36.266251</td>\n",
       "      <td>10.318624</td>\n",
       "      <td>0.380310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.081187</td>\n",
       "      <td>192.593280</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>3.177522</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>1693.624320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>4.102182</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>13.038894</td>\n",
       "      <td>9.432735</td>\n",
       "      <td>0.897628</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>2197.345480</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>12.270314</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.128294</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.129580</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4155.702870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>14.036718</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2798.992584</td>\n",
       "      <td>25.034888</td>\n",
       "      <td>23.011684</td>\n",
       "      <td>0.124414</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.354659</td>\n",
       "      <td>3120.318960</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>20.533110</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>5.031912</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>10.461320</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4997.960730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.036891</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>0.257374</td>\n",
       "      <td>18.771436</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>7838.273610</td>\n",
       "      <td>30.608946</td>\n",
       "      <td>41.007968</td>\n",
       "      <td>0.339429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559763</td>\n",
       "      <td>4361.637390</td>\n",
       "      <td>113.739540</td>\n",
       "      <td>39.139886</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.431634</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>12.969516</td>\n",
       "      <td>5.081244</td>\n",
       "      <td>6035.885700</td>\n",
       "      <td>...</td>\n",
       "      <td>6.237329</td>\n",
       "      <td>1.512060</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>25.608406</td>\n",
       "      <td>127.591671</td>\n",
       "      <td>19035.709240</td>\n",
       "      <td>36.863947</td>\n",
       "      <td>67.931664</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.161666</td>\n",
       "      <td>28688.187660</td>\n",
       "      <td>1910.123198</td>\n",
       "      <td>630.518230</td>\n",
       "      <td>178.943634</td>\n",
       "      <td>38.270880</td>\n",
       "      <td>10.315851</td>\n",
       "      <td>38.971568</td>\n",
       "      <td>1463.693448</td>\n",
       "      <td>53060.599240</td>\n",
       "      <td>...</td>\n",
       "      <td>137.932739</td>\n",
       "      <td>1244.227020</td>\n",
       "      <td>31.365763</td>\n",
       "      <td>135.781294</td>\n",
       "      <td>1497.351958</td>\n",
       "      <td>143790.071200</td>\n",
       "      <td>81.210825</td>\n",
       "      <td>191.194764</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AB            AF           AH          AM          AR  \\\n",
       "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
       "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
       "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
       "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
       "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
       "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
       "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
       "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
       "\n",
       "               AX          AY          AZ           BC           BD   ...  \\\n",
       "count  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \n",
       "mean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \n",
       "std      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \n",
       "min      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n",
       "25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n",
       "50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n",
       "75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \n",
       "max     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n",
       "\n",
       "               FL           FR          FS          GB           GE  \\\n",
       "count  617.000000   617.000000  617.000000  617.000000   617.000000   \n",
       "mean     5.433199     3.533905    0.421501   20.724856   131.714987   \n",
       "std     11.486922    50.181948    1.303244    9.991907   144.181524   \n",
       "min      0.173229     0.497060    0.067730    4.102182    72.611063   \n",
       "25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n",
       "50%      3.036891     1.131000    0.257374   18.771436    72.611063   \n",
       "75%      6.237329     1.512060    0.535067   25.608406   127.591671   \n",
       "max    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n",
       "\n",
       "                  GF          GH          GI          GL       Class  \n",
       "count     617.000000  617.000000  617.000000  617.000000  617.000000  \n",
       "mean    14679.595398   31.489716   50.584437    8.530961    0.175041  \n",
       "std     19352.959387    9.864239   36.266251   10.318624    0.380310  \n",
       "min        13.038894    9.432735    0.897628    0.001129    0.000000  \n",
       "25%      2798.992584   25.034888   23.011684    0.124414    0.000000  \n",
       "50%      7838.273610   30.608946   41.007968    0.339429    0.000000  \n",
       "75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \n",
       "max    143790.071200   81.210825  191.194764   21.978000    1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb792bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "\n",
    "correlation_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "644e1b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "AB - AM: 0.53\n",
      "AH - AR: 0.75\n",
      "AH - CH: 0.68\n",
      "AH - CL: 0.69\n",
      "AH - CS: 0.63\n",
      "AH - DV: 0.75\n",
      "AH - EB: 0.71\n",
      "AH - EP: 0.68\n",
      "AM - AB: 0.53\n",
      "AR - AH: 0.75\n",
      "AR - CH: 0.66\n",
      "AR - CL: 0.75\n",
      "AR - CS: 0.72\n",
      "AR - DV: 0.82\n",
      "AR - EB: 0.74\n",
      "AR - EP: 0.75\n",
      "AY - BD : 0.51\n",
      "BC - BD : 0.75\n",
      "BC - BZ: 0.91\n",
      "BC - CF: 0.55\n",
      "BD  - AY: 0.51\n",
      "BD  - BC: 0.75\n",
      "BD  - BZ: 0.68\n",
      "BZ - BC: 0.91\n",
      "BZ - BD : 0.68\n",
      "BZ - CC: 0.51\n",
      "BZ - CF: 0.54\n",
      "CC - BZ: 0.51\n",
      "CF - BC: 0.55\n",
      "CF - BZ: 0.54\n",
      "CH - AH: 0.68\n",
      "CH - AR: 0.66\n",
      "CH - CL: 0.56\n",
      "CH - CS: 0.60\n",
      "CH - DV: 0.61\n",
      "CH - EB: 0.62\n",
      "CH - EP: 0.57\n",
      "CL - AH: 0.69\n",
      "CL - AR: 0.75\n",
      "CL - CH: 0.56\n",
      "CL - CS: 0.63\n",
      "CL - DV: 0.95\n",
      "CL - EB: 0.62\n",
      "CL - EP: 0.65\n",
      "CS - AH: 0.63\n",
      "CS - AR: 0.72\n",
      "CS - CH: 0.60\n",
      "CS - CL: 0.63\n",
      "CS - DV: 0.69\n",
      "CS - EB: 0.69\n",
      "CS - EP: 0.79\n",
      "DU - EH: 0.85\n",
      "DU - FD : 0.81\n",
      "DU - FL: 0.61\n",
      "DV - AH: 0.75\n",
      "DV - AR: 0.82\n",
      "DV - CH: 0.61\n",
      "DV - CL: 0.95\n",
      "DV - CS: 0.69\n",
      "DV - EB: 0.69\n",
      "DV - EP: 0.72\n",
      "EB - AH: 0.71\n",
      "EB - AR: 0.74\n",
      "EB - CH: 0.62\n",
      "EB - CL: 0.62\n",
      "EB - CS: 0.69\n",
      "EB - DV: 0.69\n",
      "EB - EP: 0.73\n",
      "EH - DU: 0.85\n",
      "EH - FD : 0.97\n",
      "EH - FL: 0.54\n",
      "EJ - GL: -0.98\n",
      "EP - AH: 0.68\n",
      "EP - AR: 0.75\n",
      "EP - CH: 0.57\n",
      "EP - CL: 0.65\n",
      "EP - CS: 0.79\n",
      "EP - DV: 0.72\n",
      "EP - EB: 0.73\n",
      "FD  - DU: 0.81\n",
      "FD  - EH: 0.97\n",
      "FD  - FL: 0.53\n",
      "FL - DU: 0.61\n",
      "FL - EH: 0.54\n",
      "FL - FD : 0.53\n",
      "GL - EJ: -0.98\n"
     ]
    }
   ],
   "source": [
    "# Find highly correlated features\n",
    "highly_correlated_features = correlation_matrix[((correlation_matrix > correlation_threshold) | (correlation_matrix < -correlation_threshold)) & (correlation_matrix != 1)]\n",
    "highly_correlated_features = highly_correlated_features.unstack().dropna().reset_index()\n",
    "\n",
    "# Print the highly correlated features\n",
    "print(\"Highly Correlated Features:\")\n",
    "for index, row in highly_correlated_features.iterrows():\n",
    "    feature1 = row['level_0']\n",
    "    feature2 = row['level_1']\n",
    "    correlation = row[0]\n",
    "    print(f\"{feature1} - {feature2}: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4382832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features with Diagnosis: \n",
      "Class: 1.00\n"
     ]
    }
   ],
   "source": [
    "# find highly correlated features with diagnosis\n",
    "highly_correlated_features = np.abs(correlation_matrix['Class']).sort_values(ascending=False)\n",
    "highly_correlated_features= highly_correlated_features[highly_correlated_features > correlation_threshold]\n",
    "\n",
    "# print the highly correlated features\n",
    "print(\"Highly Correlated Features with Diagnosis: \")\n",
    "for feature, correlation in highly_correlated_features.iteritems():\n",
    "    print(f\"{feature}: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f67aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b1ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Class', 'Id'], axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d90c7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4a95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178ea02",
   "metadata": {},
   "source": [
    "###### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50156c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.87096774193549\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fe9675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.70967741935483\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35fc6818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'C': 10}\n",
      "\n",
      "Accuracy: 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "print()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0223259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'C': 0.1}\n",
      "\n",
      "Accuracy: 89.24731182795699\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "print()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968d6eb",
   "metadata": {},
   "source": [
    "###### support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "582bd73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.72043010752688\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd2e9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.78494623655914\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beadc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.56989247311827\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': [0.1, 1, 10, 100],\n",
    "    'kernel': ['lnear', 'rbf']\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# support vector machine model\n",
    "model = SVC(**best_params)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test datad\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8cdf38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.18279569892472\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': [0.1, 1, 10, 100],\n",
    "    'kernel': ['lnear', 'rbf']\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# logistic regression model\n",
    "model = SVC(**best_params)\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b8015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e2ca3d",
   "metadata": {},
   "source": [
    "###### random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "932252ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.93548387096774\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc8ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.70967741935483\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b0ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0aab7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888f3823",
   "metadata": {},
   "source": [
    "###### gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc135e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.01075268817203\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "921d6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.48387096774194\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a85fb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec6f9d",
   "metadata": {},
   "source": [
    "###### decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1790aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.70967741935483\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0595f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a54e3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'max_depth': 7, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "\n",
      "Accuracy: 90.32258064516128\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'max_depth': [3, 5, 7, None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "# Create a decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "print()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc57fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'max_depth': 7, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\n",
      "Accuracy: 61.82795698924731\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'max_depth': [3, 5, 7, None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "# Create a decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "print()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1ed19",
   "metadata": {},
   "source": [
    "###### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a05320e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.94623655913979\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8d04ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.118279569892472\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "322d4fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'var_smoothing': 0.01873817422860384}\n",
      "Accuracy: 81.72043010752688\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'var_smoothing': np.logspace(0, -9, num=100)}\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b74f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'var_smoothing': 5.3366992312063123e-05}\n",
      "Accuracy: 25.268817204301076\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'var_smoothing': np.logspace(0, -9, num=100)}\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ed9a1",
   "metadata": {},
   "source": [
    "###### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba204d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.18279569892472\n"
     ]
    }
   ],
   "source": [
    "# Create a KNN classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "448aebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.63440860215054\n"
     ]
    }
   ],
   "source": [
    "# Create a KNN classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69c49de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'n_neighbors': 9}\n",
      "Accuracy: 81.72043010752688\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2e1d6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: \n",
      "{'n_neighbors': 3}\n",
      "Accuracy: 88.17204301075269\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters: \")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2e98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361ae81",
   "metadata": {},
   "source": [
    "###### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63b92fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:01:27,483]\u001b[0m A new study created in memory with name: no-name-2ce06725-c99d-4c0a-8727-e9176857afaf\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:27,806]\u001b[0m Trial 0 finished with value: -0.8064516129032258 and parameters: {'C': 4.470897909685265, 'max_iter': 300}. Best is trial 0 with value: -0.8064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:27,938]\u001b[0m Trial 1 finished with value: -0.8225806451612904 and parameters: {'C': 0.03565299251224623, 'max_iter': 200}. Best is trial 1 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:28,249]\u001b[0m Trial 2 finished with value: -0.8225806451612904 and parameters: {'C': 2.625693405975026, 'max_iter': 700}. Best is trial 1 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:28,617]\u001b[0m Trial 3 finished with value: -0.8440860215053764 and parameters: {'C': 0.5009228837929462, 'max_iter': 800}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:28,685]\u001b[0m Trial 4 finished with value: -0.8333333333333334 and parameters: {'C': 8.897381517834818, 'max_iter': 100}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:28,900]\u001b[0m Trial 5 finished with value: -0.8279569892473119 and parameters: {'C': 0.10967099618510821, 'max_iter': 500}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:29,090]\u001b[0m Trial 6 finished with value: -0.8064516129032258 and parameters: {'C': 4.929334028702133, 'max_iter': 400}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:29,478]\u001b[0m Trial 7 finished with value: -0.8387096774193549 and parameters: {'C': 0.020164834958549496, 'max_iter': 900}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:29,576]\u001b[0m Trial 8 finished with value: -0.8333333333333334 and parameters: {'C': 0.8608259869950599, 'max_iter': 200}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:29,855]\u001b[0m Trial 9 finished with value: -0.8225806451612904 and parameters: {'C': 0.16619237490673952, 'max_iter': 600}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:30,345]\u001b[0m Trial 10 finished with value: -0.8387096774193549 and parameters: {'C': 0.6199096987579121, 'max_iter': 1000}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:30,768]\u001b[0m Trial 11 finished with value: -0.8387096774193549 and parameters: {'C': 0.010267627365989667, 'max_iter': 900}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:31,134]\u001b[0m Trial 12 finished with value: -0.8387096774193549 and parameters: {'C': 0.2698306774458554, 'max_iter': 800}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:31,590]\u001b[0m Trial 13 finished with value: -0.8333333333333334 and parameters: {'C': 0.056291007434975865, 'max_iter': 1000}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:31,970]\u001b[0m Trial 14 finished with value: -0.8387096774193549 and parameters: {'C': 0.6641770433980247, 'max_iter': 800}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:32,291]\u001b[0m Trial 15 finished with value: -0.8333333333333334 and parameters: {'C': 0.012024792911181388, 'max_iter': 700}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:32,722]\u001b[0m Trial 16 finished with value: -0.8279569892473119 and parameters: {'C': 0.035305987672703695, 'max_iter': 900}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:33,006]\u001b[0m Trial 17 finished with value: -0.8279569892473119 and parameters: {'C': 0.293646325806616, 'max_iter': 600}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:33,408]\u001b[0m Trial 18 finished with value: -0.8333333333333334 and parameters: {'C': 0.09271608582694449, 'max_iter': 800}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:33,826]\u001b[0m Trial 19 finished with value: -0.8387096774193549 and parameters: {'C': 1.3117995663137922, 'max_iter': 900}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:34,187]\u001b[0m Trial 20 finished with value: -0.8333333333333334 and parameters: {'C': 0.47240732574697275, 'max_iter': 700}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:34,661]\u001b[0m Trial 21 finished with value: -0.8333333333333334 and parameters: {'C': 0.43067975516315654, 'max_iter': 1000}. Best is trial 3 with value: -0.8440860215053764.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:35,140]\u001b[0m Trial 22 finished with value: -0.8494623655913979 and parameters: {'C': 1.426796418926741, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:35,576]\u001b[0m Trial 23 finished with value: -0.8494623655913979 and parameters: {'C': 1.4986797866821742, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:36,051]\u001b[0m Trial 24 finished with value: -0.8279569892473119 and parameters: {'C': 1.404598862796696, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:36,466]\u001b[0m Trial 25 finished with value: -0.8279569892473119 and parameters: {'C': 1.7712217697132173, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:36,899]\u001b[0m Trial 26 finished with value: -0.8387096774193549 and parameters: {'C': 0.9425151748680907, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:37,376]\u001b[0m Trial 27 finished with value: -0.8387096774193549 and parameters: {'C': 1.9041350754590007, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:37,625]\u001b[0m Trial 28 finished with value: -0.8064516129032258 and parameters: {'C': 0.7492597094172379, 'max_iter': 500}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:37,964]\u001b[0m Trial 29 finished with value: -0.8387096774193549 and parameters: {'C': 3.269824443855909, 'max_iter': 700}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:38,366]\u001b[0m Trial 30 finished with value: -0.8387096774193549 and parameters: {'C': 1.310166449362749, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:38,850]\u001b[0m Trial 31 finished with value: -0.8333333333333334 and parameters: {'C': 0.4478467375968198, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:39,293]\u001b[0m Trial 32 finished with value: -0.8225806451612904 and parameters: {'C': 0.1759111582521566, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:39,788]\u001b[0m Trial 33 finished with value: -0.8387096774193549 and parameters: {'C': 2.1665058493353277, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:40,223]\u001b[0m Trial 34 finished with value: -0.8333333333333334 and parameters: {'C': 1.0985843447811001, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:40,599]\u001b[0m Trial 35 finished with value: -0.8333333333333334 and parameters: {'C': 3.3003949689189715, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:40,938]\u001b[0m Trial 36 finished with value: -0.8279569892473119 and parameters: {'C': 6.9103013093087, 'max_iter': 700}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:41,142]\u001b[0m Trial 37 finished with value: -0.8064516129032258 and parameters: {'C': 2.676269128980258, 'max_iter': 400}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:41,454]\u001b[0m Trial 38 finished with value: -0.8279569892473119 and parameters: {'C': 5.087518690120333, 'max_iter': 600}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:41,919]\u001b[0m Trial 39 finished with value: -0.8387096774193549 and parameters: {'C': 0.8739696181724663, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:42,004]\u001b[0m Trial 40 finished with value: -0.8440860215053764 and parameters: {'C': 0.5359292657540113, 'max_iter': 100}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:01:42,091]\u001b[0m Trial 41 finished with value: -0.8387096774193549 and parameters: {'C': 0.6449372496293956, 'max_iter': 100}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:42,276]\u001b[0m Trial 42 finished with value: -0.8064516129032258 and parameters: {'C': 0.32750190741607393, 'max_iter': 300}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:42,403]\u001b[0m Trial 43 finished with value: -0.8279569892473119 and parameters: {'C': 0.9737682882782778, 'max_iter': 200}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:42,578]\u001b[0m Trial 44 finished with value: -0.8064516129032258 and parameters: {'C': 0.5704259463657328, 'max_iter': 300}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:42,671]\u001b[0m Trial 45 finished with value: -0.8387096774193549 and parameters: {'C': 1.4722775254644773, 'max_iter': 100}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:43,115]\u001b[0m Trial 46 finished with value: -0.8440860215053764 and parameters: {'C': 0.20926973873280474, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:43,345]\u001b[0m Trial 47 finished with value: -0.8225806451612904 and parameters: {'C': 0.20599451068161573, 'max_iter': 400}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:43,587]\u001b[0m Trial 48 finished with value: -0.8387096774193549 and parameters: {'C': 0.3450652583663289, 'max_iter': 500}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:43,998]\u001b[0m Trial 49 finished with value: -0.8333333333333334 and parameters: {'C': 0.23277399725174924, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:44,371]\u001b[0m Trial 50 finished with value: -0.8279569892473119 and parameters: {'C': 0.5227444187738137, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:44,857]\u001b[0m Trial 51 finished with value: -0.8279569892473119 and parameters: {'C': 0.11358291660376384, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:45,283]\u001b[0m Trial 52 finished with value: -0.8440860215053764 and parameters: {'C': 0.7662015428693364, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:45,703]\u001b[0m Trial 53 finished with value: -0.8387096774193549 and parameters: {'C': 0.7106195363307556, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:46,107]\u001b[0m Trial 54 finished with value: -0.8440860215053764 and parameters: {'C': 0.36388135914525854, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:46,554]\u001b[0m Trial 55 finished with value: -0.8494623655913979 and parameters: {'C': 1.0640829467420012, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:47,029]\u001b[0m Trial 56 finished with value: -0.8279569892473119 and parameters: {'C': 0.2712250715341835, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:47,504]\u001b[0m Trial 57 finished with value: -0.8440860215053764 and parameters: {'C': 0.5296769824188291, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:47,930]\u001b[0m Trial 58 finished with value: -0.8387096774193549 and parameters: {'C': 1.165554042568125, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:48,380]\u001b[0m Trial 59 finished with value: -0.8333333333333334 and parameters: {'C': 1.6156704407742373, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:48,687]\u001b[0m Trial 60 finished with value: -0.8279569892473119 and parameters: {'C': 0.9176922560815146, 'max_iter': 700}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:49,084]\u001b[0m Trial 61 finished with value: -0.8333333333333334 and parameters: {'C': 0.6287217626749487, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:49,515]\u001b[0m Trial 62 finished with value: -0.8333333333333334 and parameters: {'C': 1.1360163088975657, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:49,982]\u001b[0m Trial 63 finished with value: -0.8333333333333334 and parameters: {'C': 0.8444533050848626, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:50,381]\u001b[0m Trial 64 finished with value: -0.8440860215053764 and parameters: {'C': 0.4096667514387725, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:50,767]\u001b[0m Trial 65 finished with value: -0.8333333333333334 and parameters: {'C': 0.7680495952997142, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:51,174]\u001b[0m Trial 66 finished with value: -0.8387096774193549 and parameters: {'C': 1.497357028691843, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:51,559]\u001b[0m Trial 67 finished with value: -0.8494623655913979 and parameters: {'C': 2.0882517860322234, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:51,953]\u001b[0m Trial 68 finished with value: -0.8440860215053764 and parameters: {'C': 2.451035207641908, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:52,430]\u001b[0m Trial 69 finished with value: -0.8440860215053764 and parameters: {'C': 2.1091902932892075, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:52,879]\u001b[0m Trial 70 finished with value: -0.8387096774193549 and parameters: {'C': 1.7063529134636461, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:53,285]\u001b[0m Trial 71 finished with value: -0.8172043010752689 and parameters: {'C': 1.1730516683839192, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:53,715]\u001b[0m Trial 72 finished with value: -0.8279569892473119 and parameters: {'C': 0.48175120856971004, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:54,175]\u001b[0m Trial 73 finished with value: -0.8387096774193549 and parameters: {'C': 0.6908095793482076, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:54,559]\u001b[0m Trial 74 finished with value: -0.8279569892473119 and parameters: {'C': 1.3057967250703242, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:54,990]\u001b[0m Trial 75 finished with value: -0.8279569892473119 and parameters: {'C': 0.9899035527831079, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:55,448]\u001b[0m Trial 76 finished with value: -0.8440860215053764 and parameters: {'C': 1.8686712719443481, 'max_iter': 1000}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:55,764]\u001b[0m Trial 77 finished with value: -0.8440860215053764 and parameters: {'C': 0.8541866149722325, 'max_iter': 600}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:55,894]\u001b[0m Trial 78 finished with value: -0.8279569892473119 and parameters: {'C': 0.3710772516035495, 'max_iter': 200}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:56,283]\u001b[0m Trial 79 finished with value: -0.8387096774193549 and parameters: {'C': 0.5909929692489959, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:56,693]\u001b[0m Trial 80 finished with value: -0.8279569892473119 and parameters: {'C': 1.513090410187331, 'max_iter': 900}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:57,088]\u001b[0m Trial 81 finished with value: -0.8225806451612904 and parameters: {'C': 0.3963524966226972, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:01:57,429]\u001b[0m Trial 82 finished with value: -0.8387096774193549 and parameters: {'C': 0.32182632548758594, 'max_iter': 700}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:57,832]\u001b[0m Trial 83 finished with value: -0.8333333333333334 and parameters: {'C': 0.48889803105831847, 'max_iter': 800}. Best is trial 22 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:58,159]\u001b[0m Trial 84 finished with value: -0.8548387096774194 and parameters: {'C': 0.3006039871164258, 'max_iter': 700}. Best is trial 84 with value: -0.8548387096774194.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:58,516]\u001b[0m Trial 85 finished with value: -0.8602150537634409 and parameters: {'C': 0.2823688668541671, 'max_iter': 700}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:58,881]\u001b[0m Trial 86 finished with value: -0.8225806451612904 and parameters: {'C': 0.4425075229563935, 'max_iter': 700}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:59,192]\u001b[0m Trial 87 finished with value: -0.8279569892473119 and parameters: {'C': 0.25963119447659866, 'max_iter': 600}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:59,520]\u001b[0m Trial 88 finished with value: -0.8333333333333334 and parameters: {'C': 0.19949910555584466, 'max_iter': 600}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:01:59,872]\u001b[0m Trial 89 finished with value: -0.8225806451612904 and parameters: {'C': 0.2796507060392718, 'max_iter': 700}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:00,244]\u001b[0m Trial 90 finished with value: -0.8279569892473119 and parameters: {'C': 0.16912780568458957, 'max_iter': 700}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:00,640]\u001b[0m Trial 91 finished with value: -0.8333333333333334 and parameters: {'C': 0.315143861897176, 'max_iter': 800}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:01,065]\u001b[0m Trial 92 finished with value: -0.8333333333333334 and parameters: {'C': 0.7359742149031436, 'max_iter': 900}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:01,321]\u001b[0m Trial 93 finished with value: -0.8064516129032258 and parameters: {'C': 0.5734301936752865, 'max_iter': 500}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:01,760]\u001b[0m Trial 94 finished with value: -0.8440860215053764 and parameters: {'C': 1.276327122351418, 'max_iter': 900}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:02,177]\u001b[0m Trial 95 finished with value: -0.8333333333333334 and parameters: {'C': 1.0573514301599214, 'max_iter': 1000}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:02,534]\u001b[0m Trial 96 finished with value: -0.8279569892473119 and parameters: {'C': 0.23266498298154428, 'max_iter': 700}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:03,045]\u001b[0m Trial 97 finished with value: -0.8279569892473119 and parameters: {'C': 0.4101483711588465, 'max_iter': 1000}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:03,482]\u001b[0m Trial 98 finished with value: -0.8333333333333334 and parameters: {'C': 0.7964989246263687, 'max_iter': 900}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:02:03,859]\u001b[0m Trial 99 finished with value: -0.8333333333333334 and parameters: {'C': 0.9737506400787662, 'max_iter': 800}. Best is trial 85 with value: -0.8602150537634409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.2823688668541671, 'max_iter': 700}\n",
      "Best Accuracy: 0.8602150537634409\n",
      "Accuracy: 86.02150537634408\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform(\"C\", 0.01, 10)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000, step=100)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=max_iter, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the logistic regression model with the best hyperparameters\n",
    "best_model = LogisticRegression(\n",
    "    C=study.best_params[\"C\"], max_iter=study.best_params[\"max_iter\"], random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b520a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:04,341]\u001b[0m A new study created in memory with name: no-name-7b6c30c6-fc38-4556-a3ed-baae4a7c61e2\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,366]\u001b[0m Trial 0 finished with value: -0.8924731182795699 and parameters: {'C': 0.13001539984480753, 'max_iter': 100}. Best is trial 0 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,393]\u001b[0m Trial 1 finished with value: -0.8870967741935484 and parameters: {'C': 1.1223182969757548, 'max_iter': 200}. Best is trial 0 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,421]\u001b[0m Trial 2 finished with value: -0.8978494623655914 and parameters: {'C': 0.4686368453467886, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,443]\u001b[0m Trial 3 finished with value: -0.8924731182795699 and parameters: {'C': 0.3410523817783667, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,477]\u001b[0m Trial 4 finished with value: -0.8924731182795699 and parameters: {'C': 2.552302414197984, 'max_iter': 400}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,519]\u001b[0m Trial 5 finished with value: -0.8924731182795699 and parameters: {'C': 3.9939590123627067, 'max_iter': 1000}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,570]\u001b[0m Trial 6 finished with value: -0.8978494623655914 and parameters: {'C': 6.143815808034582, 'max_iter': 600}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,621]\u001b[0m Trial 7 finished with value: -0.8978494623655914 and parameters: {'C': 6.834416360212546, 'max_iter': 1000}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,637]\u001b[0m Trial 8 finished with value: -0.8655913978494624 and parameters: {'C': 0.015237680287658869, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,652]\u001b[0m Trial 9 finished with value: -0.8870967741935484 and parameters: {'C': 0.023337623314373394, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,701]\u001b[0m Trial 10 finished with value: -0.8924731182795699 and parameters: {'C': 0.5432193497673363, 'max_iter': 700}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,760]\u001b[0m Trial 11 finished with value: -0.8817204301075269 and parameters: {'C': 1.4998656550719136, 'max_iter': 700}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,835]\u001b[0m Trial 12 finished with value: -0.8924731182795699 and parameters: {'C': 8.240992520869716, 'max_iter': 700}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,887]\u001b[0m Trial 13 finished with value: -0.8924731182795699 and parameters: {'C': 0.1481341349227999, 'max_iter': 600}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:04,950]\u001b[0m Trial 14 finished with value: -0.8924731182795699 and parameters: {'C': 2.9603914993417644, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,029]\u001b[0m Trial 15 finished with value: -0.8870967741935484 and parameters: {'C': 9.674229099826709, 'max_iter': 800}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,067]\u001b[0m Trial 16 finished with value: -0.8870967741935484 and parameters: {'C': 0.8421497603294966, 'max_iter': 400}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,118]\u001b[0m Trial 17 finished with value: -0.8870967741935484 and parameters: {'C': 1.7684340927926474, 'max_iter': 800}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,179]\u001b[0m Trial 18 finished with value: -0.8924731182795699 and parameters: {'C': 4.4096671430883685, 'max_iter': 600}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,224]\u001b[0m Trial 19 finished with value: -0.8924731182795699 and parameters: {'C': 0.6865217966468466, 'max_iter': 400}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,281]\u001b[0m Trial 20 finished with value: -0.8870967741935484 and parameters: {'C': 1.776509504153564, 'max_iter': 900}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,345]\u001b[0m Trial 21 finished with value: -0.8924731182795699 and parameters: {'C': 5.412609519019837, 'max_iter': 1000}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,413]\u001b[0m Trial 22 finished with value: -0.8870967741935484 and parameters: {'C': 9.795887755685566, 'max_iter': 900}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,477]\u001b[0m Trial 23 finished with value: -0.8924731182795699 and parameters: {'C': 5.1238567148561245, 'max_iter': 600}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,535]\u001b[0m Trial 24 finished with value: -0.8870967741935484 and parameters: {'C': 2.0791207359037442, 'max_iter': 800}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,594]\u001b[0m Trial 25 finished with value: -0.8924731182795699 and parameters: {'C': 3.419204761204943, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,667]\u001b[0m Trial 26 finished with value: -0.8978494623655914 and parameters: {'C': 6.14673976125503, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,725]\u001b[0m Trial 27 finished with value: -0.8870967741935484 and parameters: {'C': 1.1133410920494806, 'max_iter': 900}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,784]\u001b[0m Trial 28 finished with value: -0.8924731182795699 and parameters: {'C': 3.6207244036657076, 'max_iter': 100}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,837]\u001b[0m Trial 29 finished with value: -0.8978494623655914 and parameters: {'C': 0.46261119822234276, 'max_iter': 100}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,896]\u001b[0m Trial 30 finished with value: -0.8924731182795699 and parameters: {'C': 2.411332259647502, 'max_iter': 700}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:05,981]\u001b[0m Trial 31 finished with value: -0.8978494623655914 and parameters: {'C': 6.274556750628773, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,050]\u001b[0m Trial 32 finished with value: -0.8978494623655914 and parameters: {'C': 7.6640441878077015, 'max_iter': 200}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,121]\u001b[0m Trial 33 finished with value: -0.8978494623655914 and parameters: {'C': 5.901829769318655, 'max_iter': 200}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,179]\u001b[0m Trial 34 finished with value: -0.8870967741935484 and parameters: {'C': 1.11982879963783, 'max_iter': 400}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,244]\u001b[0m Trial 35 finished with value: -0.8924731182795699 and parameters: {'C': 3.276480057118206, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,277]\u001b[0m Trial 36 finished with value: -0.8924731182795699 and parameters: {'C': 0.23454129598942042, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,335]\u001b[0m Trial 37 finished with value: -0.8924731182795699 and parameters: {'C': 5.027674628439645, 'max_iter': 500}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,393]\u001b[0m Trial 38 finished with value: -0.8924731182795699 and parameters: {'C': 2.344650191180301, 'max_iter': 1000}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,463]\u001b[0m Trial 39 finished with value: -0.8978494623655914 and parameters: {'C': 7.051254479306894, 'max_iter': 300}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,518]\u001b[0m Trial 40 finished with value: -0.8817204301075269 and parameters: {'C': 1.3792341145982772, 'max_iter': 200}. Best is trial 2 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:06,564]\u001b[0m Trial 41 finished with value: -0.9086021505376344 and parameters: {'C': 0.05893402197539367, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,610]\u001b[0m Trial 42 finished with value: -0.9032258064516129 and parameters: {'C': 0.047097013379811044, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,654]\u001b[0m Trial 43 finished with value: -0.9086021505376344 and parameters: {'C': 0.05098363556849973, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,693]\u001b[0m Trial 44 finished with value: -0.9086021505376344 and parameters: {'C': 0.05646316976765035, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,738]\u001b[0m Trial 45 finished with value: -0.9086021505376344 and parameters: {'C': 0.05803105329303791, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,783]\u001b[0m Trial 46 finished with value: -0.9086021505376344 and parameters: {'C': 0.06134799611065504, 'max_iter': 100}. Best is trial 41 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,830]\u001b[0m Trial 47 finished with value: -0.9139784946236559 and parameters: {'C': 0.06713197643627092, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,877]\u001b[0m Trial 48 finished with value: -0.9139784946236559 and parameters: {'C': 0.06645466965982456, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,918]\u001b[0m Trial 49 finished with value: -0.9032258064516129 and parameters: {'C': 0.09003025027997048, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:06,965]\u001b[0m Trial 50 finished with value: -0.8978494623655914 and parameters: {'C': 0.035536391539131996, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,011]\u001b[0m Trial 51 finished with value: -0.9139784946236559 and parameters: {'C': 0.08041988151232742, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,053]\u001b[0m Trial 52 finished with value: -0.8924731182795699 and parameters: {'C': 0.11027992719151204, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,077]\u001b[0m Trial 53 finished with value: -0.8817204301075269 and parameters: {'C': 0.027146729136492867, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,125]\u001b[0m Trial 54 finished with value: -0.9139784946236559 and parameters: {'C': 0.07702869509243072, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,172]\u001b[0m Trial 55 finished with value: -0.9032258064516129 and parameters: {'C': 0.09053632123878157, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,226]\u001b[0m Trial 56 finished with value: -0.8924731182795699 and parameters: {'C': 0.1507570868920465, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,276]\u001b[0m Trial 57 finished with value: -0.8978494623655914 and parameters: {'C': 0.040439530013589645, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,321]\u001b[0m Trial 58 finished with value: -0.9139784946236559 and parameters: {'C': 0.0734425412158208, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,368]\u001b[0m Trial 59 finished with value: -0.9139784946236559 and parameters: {'C': 0.07327893889702589, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,414]\u001b[0m Trial 60 finished with value: -0.9139784946236559 and parameters: {'C': 0.07589135637864883, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,459]\u001b[0m Trial 61 finished with value: -0.9139784946236559 and parameters: {'C': 0.0786883236570703, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,510]\u001b[0m Trial 62 finished with value: -0.8924731182795699 and parameters: {'C': 0.13775970497826184, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,560]\u001b[0m Trial 63 finished with value: -0.9139784946236559 and parameters: {'C': 0.0770484417961936, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,610]\u001b[0m Trial 64 finished with value: -0.8924731182795699 and parameters: {'C': 0.11350866162549472, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,661]\u001b[0m Trial 65 finished with value: -0.9139784946236559 and parameters: {'C': 0.06925099510392149, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,710]\u001b[0m Trial 66 finished with value: -0.8924731182795699 and parameters: {'C': 0.17443769504827764, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,759]\u001b[0m Trial 67 finished with value: -0.8924731182795699 and parameters: {'C': 0.1000115176209733, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,805]\u001b[0m Trial 68 finished with value: -0.9139784946236559 and parameters: {'C': 0.07331959752923715, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,837]\u001b[0m Trial 69 finished with value: -0.8978494623655914 and parameters: {'C': 0.04172846764213676, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,887]\u001b[0m Trial 70 finished with value: -0.8924731182795699 and parameters: {'C': 0.11534234319318509, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,919]\u001b[0m Trial 71 finished with value: -0.9139784946236559 and parameters: {'C': 0.0852430974815015, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:07,967]\u001b[0m Trial 72 finished with value: -0.9139784946236559 and parameters: {'C': 0.07054428781947923, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,014]\u001b[0m Trial 73 finished with value: -0.9139784946236559 and parameters: {'C': 0.08348789774559214, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,060]\u001b[0m Trial 74 finished with value: -0.9086021505376344 and parameters: {'C': 0.04926011055901669, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,110]\u001b[0m Trial 75 finished with value: -0.9139784946236559 and parameters: {'C': 0.0686855524675381, 'max_iter': 400}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,144]\u001b[0m Trial 76 finished with value: -0.8978494623655914 and parameters: {'C': 0.0988464958574873, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,186]\u001b[0m Trial 77 finished with value: -0.8978494623655914 and parameters: {'C': 0.0335425422377042, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,251]\u001b[0m Trial 78 finished with value: -0.8924731182795699 and parameters: {'C': 0.12606342929546202, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,296]\u001b[0m Trial 79 finished with value: -0.8924731182795699 and parameters: {'C': 0.18495700953246252, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,343]\u001b[0m Trial 80 finished with value: -0.9086021505376344 and parameters: {'C': 0.06229789416273661, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,384]\u001b[0m Trial 81 finished with value: -0.9139784946236559 and parameters: {'C': 0.07780785811393527, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:08,426]\u001b[0m Trial 82 finished with value: -0.9139784946236559 and parameters: {'C': 0.07981382600575755, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,467]\u001b[0m Trial 83 finished with value: -0.9086021505376344 and parameters: {'C': 0.05006349112029403, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,510]\u001b[0m Trial 84 finished with value: -0.8924731182795699 and parameters: {'C': 0.1039013879974892, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,550]\u001b[0m Trial 85 finished with value: -0.9086021505376344 and parameters: {'C': 0.06417003192968325, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,603]\u001b[0m Trial 86 finished with value: -0.9032258064516129 and parameters: {'C': 0.09017197602319273, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,650]\u001b[0m Trial 87 finished with value: -0.8924731182795699 and parameters: {'C': 0.13575464891890784, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,702]\u001b[0m Trial 88 finished with value: -0.9086021505376344 and parameters: {'C': 0.05518427891898901, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,743]\u001b[0m Trial 89 finished with value: -0.9032258064516129 and parameters: {'C': 0.04302849060602342, 'max_iter': 300}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,784]\u001b[0m Trial 90 finished with value: -0.9139784946236559 and parameters: {'C': 0.06948500070746531, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,828]\u001b[0m Trial 91 finished with value: -0.9139784946236559 and parameters: {'C': 0.07541199195470921, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,885]\u001b[0m Trial 92 finished with value: -0.9086021505376344 and parameters: {'C': 0.05696606465544154, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,938]\u001b[0m Trial 93 finished with value: -0.8924731182795699 and parameters: {'C': 0.10006546118228088, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:08,985]\u001b[0m Trial 94 finished with value: -0.9139784946236559 and parameters: {'C': 0.06667077804062113, 'max_iter': 400}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,026]\u001b[0m Trial 95 finished with value: -0.9086021505376344 and parameters: {'C': 0.05062192253487266, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,078]\u001b[0m Trial 96 finished with value: -0.9032258064516129 and parameters: {'C': 0.08957655685072582, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,120]\u001b[0m Trial 97 finished with value: -0.8978494623655914 and parameters: {'C': 0.03556717102489189, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,161]\u001b[0m Trial 98 finished with value: -0.8924731182795699 and parameters: {'C': 0.12259266723432705, 'max_iter': 200}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,209]\u001b[0m Trial 99 finished with value: -0.9139784946236559 and parameters: {'C': 0.07727603060390328, 'max_iter': 100}. Best is trial 47 with value: -0.9139784946236559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.06713197643627092, 'max_iter': 100}\n",
      "Best Accuracy: 0.9139784946236559\n",
      "Accuracy: 91.39784946236558\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform(\"C\", 0.01, 10)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000, step=100)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=max_iter, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the logistic regression model with the best hyperparameters\n",
    "best_model = LogisticRegression(\n",
    "    C=study.best_params[\"C\"], max_iter=study.best_params[\"max_iter\"], random_state=42\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e31050",
   "metadata": {},
   "source": [
    "###### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a7ba13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:09,261]\u001b[0m A new study created in memory with name: no-name-c4901baa-2140-48d9-a993-bb296715ca82\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,300]\u001b[0m Trial 0 finished with value: -0.8870967741935484 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 0 with value: -0.8870967741935484.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,341]\u001b[0m Trial 1 finished with value: -0.8709677419354839 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 0 with value: -0.8870967741935484.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,384]\u001b[0m Trial 2 finished with value: -0.8870967741935484 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: -0.8870967741935484.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,421]\u001b[0m Trial 3 finished with value: -0.8924731182795699 and parameters: {'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,442]\u001b[0m Trial 4 finished with value: -0.8655913978494624 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,476]\u001b[0m Trial 5 finished with value: -0.8655913978494624 and parameters: {'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 3 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,510]\u001b[0m Trial 6 finished with value: -0.8709677419354839 and parameters: {'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 3 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,550]\u001b[0m Trial 7 finished with value: -0.8870967741935484 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 3 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,584]\u001b[0m Trial 8 finished with value: -0.9032258064516129 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,608]\u001b[0m Trial 9 finished with value: -0.8655913978494624 and parameters: {'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,685]\u001b[0m Trial 10 finished with value: -0.9032258064516129 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,772]\u001b[0m Trial 11 finished with value: -0.9032258064516129 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,849]\u001b[0m Trial 12 finished with value: -0.9032258064516129 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:09,934]\u001b[0m Trial 13 finished with value: -0.8817204301075269 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 8 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,011]\u001b[0m Trial 14 finished with value: -0.9139784946236559 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 14 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,079]\u001b[0m Trial 15 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,159]\u001b[0m Trial 16 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,214]\u001b[0m Trial 17 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,276]\u001b[0m Trial 18 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,358]\u001b[0m Trial 19 finished with value: -0.8978494623655914 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,452]\u001b[0m Trial 20 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,533]\u001b[0m Trial 21 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,609]\u001b[0m Trial 22 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,694]\u001b[0m Trial 23 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,763]\u001b[0m Trial 24 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,841]\u001b[0m Trial 25 finished with value: -0.9139784946236559 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,908]\u001b[0m Trial 26 finished with value: -0.8709677419354839 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:10,989]\u001b[0m Trial 27 finished with value: -0.8924731182795699 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,072]\u001b[0m Trial 28 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,155]\u001b[0m Trial 29 finished with value: -0.9193548387096774 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,238]\u001b[0m Trial 30 finished with value: -0.8602150537634409 and parameters: {'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,307]\u001b[0m Trial 31 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,392]\u001b[0m Trial 32 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,485]\u001b[0m Trial 33 finished with value: -0.8924731182795699 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,569]\u001b[0m Trial 34 finished with value: -0.8978494623655914 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,645]\u001b[0m Trial 35 finished with value: -0.8978494623655914 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,729]\u001b[0m Trial 36 finished with value: -0.8709677419354839 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:11,815]\u001b[0m Trial 37 finished with value: -0.8924731182795699 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,898]\u001b[0m Trial 38 finished with value: -0.8870967741935484 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:11,996]\u001b[0m Trial 39 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,072]\u001b[0m Trial 40 finished with value: -0.8924731182795699 and parameters: {'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,149]\u001b[0m Trial 41 finished with value: -0.9193548387096774 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,230]\u001b[0m Trial 42 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,315]\u001b[0m Trial 43 finished with value: -0.8978494623655914 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,398]\u001b[0m Trial 44 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,495]\u001b[0m Trial 45 finished with value: -0.8978494623655914 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,579]\u001b[0m Trial 46 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,665]\u001b[0m Trial 47 finished with value: -0.8870967741935484 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,755]\u001b[0m Trial 48 finished with value: -0.9086021505376344 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,838]\u001b[0m Trial 49 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,891]\u001b[0m Trial 50 finished with value: -0.9032258064516129 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:12,968]\u001b[0m Trial 51 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,072]\u001b[0m Trial 52 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,158]\u001b[0m Trial 53 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,257]\u001b[0m Trial 54 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,342]\u001b[0m Trial 55 finished with value: -0.9139784946236559 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,427]\u001b[0m Trial 56 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,518]\u001b[0m Trial 57 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,611]\u001b[0m Trial 58 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,698]\u001b[0m Trial 59 finished with value: -0.8870967741935484 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,791]\u001b[0m Trial 60 finished with value: -0.9032258064516129 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,878]\u001b[0m Trial 61 finished with value: -0.9193548387096774 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:13,975]\u001b[0m Trial 62 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,060]\u001b[0m Trial 63 finished with value: -0.9139784946236559 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,148]\u001b[0m Trial 64 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,241]\u001b[0m Trial 65 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,324]\u001b[0m Trial 66 finished with value: -0.8817204301075269 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,400]\u001b[0m Trial 67 finished with value: -0.9086021505376344 and parameters: {'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,485]\u001b[0m Trial 68 finished with value: -0.8978494623655914 and parameters: {'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,570]\u001b[0m Trial 69 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,664]\u001b[0m Trial 70 finished with value: -0.8978494623655914 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,758]\u001b[0m Trial 71 finished with value: -0.9193548387096774 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,827]\u001b[0m Trial 72 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:14,902]\u001b[0m Trial 73 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:14,997]\u001b[0m Trial 74 finished with value: -0.8924731182795699 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,085]\u001b[0m Trial 75 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,179]\u001b[0m Trial 76 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,260]\u001b[0m Trial 77 finished with value: -0.8709677419354839 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,347]\u001b[0m Trial 78 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,435]\u001b[0m Trial 79 finished with value: -0.9032258064516129 and parameters: {'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,526]\u001b[0m Trial 80 finished with value: -0.9193548387096774 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,613]\u001b[0m Trial 81 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,707]\u001b[0m Trial 82 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,812]\u001b[0m Trial 83 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,897]\u001b[0m Trial 84 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:15,991]\u001b[0m Trial 85 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,086]\u001b[0m Trial 86 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,172]\u001b[0m Trial 87 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,268]\u001b[0m Trial 88 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,363]\u001b[0m Trial 89 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,447]\u001b[0m Trial 90 finished with value: -0.9032258064516129 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,540]\u001b[0m Trial 91 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,631]\u001b[0m Trial 92 finished with value: -0.9193548387096774 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,723]\u001b[0m Trial 93 finished with value: -0.8978494623655914 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,828]\u001b[0m Trial 94 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,902]\u001b[0m Trial 95 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:16,997]\u001b[0m Trial 96 finished with value: -0.9139784946236559 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,085]\u001b[0m Trial 97 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,182]\u001b[0m Trial 98 finished with value: -0.9032258064516129 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,273]\u001b[0m Trial 99 finished with value: -0.9139784946236559 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 15 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
      "Best Accuracy: 0.9193548387096774\n",
      "Accuracy: 91.93548387096774\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the decision tree model with the best hyperparameters\n",
    "best_model = DecisionTreeClassifier(\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45d28eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:17,357]\u001b[0m A new study created in memory with name: no-name-fe2db8f5-5e68-4524-b467-8663359b94e4\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,391]\u001b[0m Trial 0 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,423]\u001b[0m Trial 1 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,458]\u001b[0m Trial 2 finished with value: -0.7849462365591398 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,489]\u001b[0m Trial 3 finished with value: -0.6612903225806451 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,517]\u001b[0m Trial 4 finished with value: -0.6505376344086021 and parameters: {'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,542]\u001b[0m Trial 5 finished with value: -0.8064516129032258 and parameters: {'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,573]\u001b[0m Trial 6 finished with value: -0.6451612903225806 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,597]\u001b[0m Trial 7 finished with value: -0.7634408602150538 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,633]\u001b[0m Trial 8 finished with value: -0.6397849462365591 and parameters: {'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,657]\u001b[0m Trial 9 finished with value: -0.6344086021505376 and parameters: {'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,712]\u001b[0m Trial 10 finished with value: -0.7580645161290323 and parameters: {'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,774]\u001b[0m Trial 11 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,847]\u001b[0m Trial 12 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,924]\u001b[0m Trial 13 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:17,990]\u001b[0m Trial 14 finished with value: -0.6559139784946236 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,057]\u001b[0m Trial 15 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,117]\u001b[0m Trial 16 finished with value: -0.7634408602150538 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,187]\u001b[0m Trial 17 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,249]\u001b[0m Trial 18 finished with value: -0.7580645161290323 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,323]\u001b[0m Trial 19 finished with value: -0.6559139784946236 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,391]\u001b[0m Trial 20 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,458]\u001b[0m Trial 21 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,535]\u001b[0m Trial 22 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,606]\u001b[0m Trial 23 finished with value: -0.7580645161290323 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,675]\u001b[0m Trial 24 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,740]\u001b[0m Trial 25 finished with value: -0.7580645161290323 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,823]\u001b[0m Trial 26 finished with value: -0.8279569892473119 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,906]\u001b[0m Trial 27 finished with value: -0.6182795698924731 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:18,991]\u001b[0m Trial 28 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,057]\u001b[0m Trial 29 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,130]\u001b[0m Trial 30 finished with value: -0.7580645161290323 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,206]\u001b[0m Trial 31 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,275]\u001b[0m Trial 32 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,344]\u001b[0m Trial 33 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,413]\u001b[0m Trial 34 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,486]\u001b[0m Trial 35 finished with value: -0.6397849462365591 and parameters: {'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,568]\u001b[0m Trial 36 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:19,641]\u001b[0m Trial 37 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,730]\u001b[0m Trial 38 finished with value: -0.6182795698924731 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,810]\u001b[0m Trial 39 finished with value: -0.7849462365591398 and parameters: {'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,885]\u001b[0m Trial 40 finished with value: -0.6612903225806451 and parameters: {'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:19,961]\u001b[0m Trial 41 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,074]\u001b[0m Trial 42 finished with value: -0.8225806451612904 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,157]\u001b[0m Trial 43 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,238]\u001b[0m Trial 44 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,313]\u001b[0m Trial 45 finished with value: -0.6559139784946236 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,397]\u001b[0m Trial 46 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,464]\u001b[0m Trial 47 finished with value: -0.7634408602150538 and parameters: {'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,540]\u001b[0m Trial 48 finished with value: -0.7580645161290323 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,615]\u001b[0m Trial 49 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,681]\u001b[0m Trial 50 finished with value: -0.8225806451612904 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,755]\u001b[0m Trial 51 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,827]\u001b[0m Trial 52 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,915]\u001b[0m Trial 53 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:20,982]\u001b[0m Trial 54 finished with value: -0.7795698924731183 and parameters: {'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,065]\u001b[0m Trial 55 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,141]\u001b[0m Trial 56 finished with value: -0.8225806451612904 and parameters: {'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,229]\u001b[0m Trial 57 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,309]\u001b[0m Trial 58 finished with value: -0.6129032258064516 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,384]\u001b[0m Trial 59 finished with value: -0.8225806451612904 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,457]\u001b[0m Trial 60 finished with value: -0.6344086021505376 and parameters: {'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,534]\u001b[0m Trial 61 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,616]\u001b[0m Trial 62 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,691]\u001b[0m Trial 63 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,776]\u001b[0m Trial 64 finished with value: -0.8279569892473119 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,851]\u001b[0m Trial 65 finished with value: -0.8225806451612904 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:21,935]\u001b[0m Trial 66 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,012]\u001b[0m Trial 67 finished with value: -0.7580645161290323 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,105]\u001b[0m Trial 68 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,190]\u001b[0m Trial 69 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,262]\u001b[0m Trial 70 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,345]\u001b[0m Trial 71 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,419]\u001b[0m Trial 72 finished with value: -0.8387096774193549 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,492]\u001b[0m Trial 73 finished with value: -0.8225806451612904 and parameters: {'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:22,577]\u001b[0m Trial 74 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,649]\u001b[0m Trial 75 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,734]\u001b[0m Trial 76 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,821]\u001b[0m Trial 77 finished with value: -0.6236559139784946 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,897]\u001b[0m Trial 78 finished with value: -0.7634408602150538 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:22,983]\u001b[0m Trial 79 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,068]\u001b[0m Trial 80 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,128]\u001b[0m Trial 81 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,214]\u001b[0m Trial 82 finished with value: -0.8387096774193549 and parameters: {'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,292]\u001b[0m Trial 83 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,376]\u001b[0m Trial 84 finished with value: -0.8387096774193549 and parameters: {'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,462]\u001b[0m Trial 85 finished with value: -0.8387096774193549 and parameters: {'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,550]\u001b[0m Trial 86 finished with value: -0.6559139784946236 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,639]\u001b[0m Trial 87 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,727]\u001b[0m Trial 88 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,807]\u001b[0m Trial 89 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,889]\u001b[0m Trial 90 finished with value: -0.6290322580645161 and parameters: {'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:23,980]\u001b[0m Trial 91 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,072]\u001b[0m Trial 92 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,162]\u001b[0m Trial 93 finished with value: -0.8387096774193549 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,243]\u001b[0m Trial 94 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,328]\u001b[0m Trial 95 finished with value: -0.6559139784946236 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,422]\u001b[0m Trial 96 finished with value: -0.8387096774193549 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,504]\u001b[0m Trial 97 finished with value: -0.8387096774193549 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,595]\u001b[0m Trial 98 finished with value: -0.6559139784946236 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:24,678]\u001b[0m Trial 99 finished with value: -0.8225806451612904 and parameters: {'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 12 with value: -0.8387096774193549.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 5}\n",
      "Best Accuracy: 0.8387096774193549\n",
      "Accuracy: 83.87096774193549\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the decision tree model with the best hyperparameters\n",
    "best_model = DecisionTreeClassifier(\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9f49c",
   "metadata": {},
   "source": [
    "###### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea0e1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:03:24,744]\u001b[0m A new study created in memory with name: no-name-d3263ba1-1637-4cbc-92e6-0679098561f6\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:25,598]\u001b[0m Trial 0 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:33,944]\u001b[0m Trial 1 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:40,772]\u001b[0m Trial 2 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:46,264]\u001b[0m Trial 3 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:48,456]\u001b[0m Trial 4 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:50,679]\u001b[0m Trial 5 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 300, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:54,493]\u001b[0m Trial 6 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:03:58,453]\u001b[0m Trial 7 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:03,879]\u001b[0m Trial 8 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 700, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:10,219]\u001b[0m Trial 9 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 900, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:16,364]\u001b[0m Trial 10 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:17,275]\u001b[0m Trial 11 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: -0.9247311827956989.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:18,227]\u001b[0m Trial 12 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 12 with value: -0.9354838709677419.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:20,962]\u001b[0m Trial 13 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 13 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:23,724]\u001b[0m Trial 14 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 13 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:26,234]\u001b[0m Trial 15 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 13 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:29,686]\u001b[0m Trial 16 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 400, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 13 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:31,563]\u001b[0m Trial 17 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:33,172]\u001b[0m Trial 18 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:37,072]\u001b[0m Trial 19 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 600, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:38,876]\u001b[0m Trial 20 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:42,540]\u001b[0m Trial 21 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 400, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:44,487]\u001b[0m Trial 22 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:46,323]\u001b[0m Trial 23 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:49,805]\u001b[0m Trial 24 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:51,667]\u001b[0m Trial 25 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:52,573]\u001b[0m Trial 26 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:54,231]\u001b[0m Trial 27 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 200, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:57,841]\u001b[0m Trial 28 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:04:58,713]\u001b[0m Trial 29 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:00,862]\u001b[0m Trial 30 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:02,730]\u001b[0m Trial 31 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:04,571]\u001b[0m Trial 32 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:05,455]\u001b[0m Trial 33 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:05:08,172]\u001b[0m Trial 34 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:09,884]\u001b[0m Trial 35 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:12,528]\u001b[0m Trial 36 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 300, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:16,238]\u001b[0m Trial 37 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:19,340]\u001b[0m Trial 38 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 400, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:24,352]\u001b[0m Trial 39 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 600, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:25,311]\u001b[0m Trial 40 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:27,197]\u001b[0m Trial 41 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:29,089]\u001b[0m Trial 42 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:31,847]\u001b[0m Trial 43 finished with value: -0.946236559139785 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:32,841]\u001b[0m Trial 44 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:39,978]\u001b[0m Trial 45 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 800, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:42,711]\u001b[0m Trial 46 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:44,362]\u001b[0m Trial 47 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:45,380]\u001b[0m Trial 48 finished with value: -0.946236559139785 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:48,020]\u001b[0m Trial 49 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:49,877]\u001b[0m Trial 50 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:51,776]\u001b[0m Trial 51 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:53,739]\u001b[0m Trial 52 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:56,183]\u001b[0m Trial 53 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:57,113]\u001b[0m Trial 54 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:05:59,100]\u001b[0m Trial 55 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:02,942]\u001b[0m Trial 56 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 400, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:03,887]\u001b[0m Trial 57 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:08,044]\u001b[0m Trial 58 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 500, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:10,068]\u001b[0m Trial 59 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:12,908]\u001b[0m Trial 60 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:14,862]\u001b[0m Trial 61 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:16,751]\u001b[0m Trial 62 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:17,784]\u001b[0m Trial 63 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:18,750]\u001b[0m Trial 64 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:19,827]\u001b[0m Trial 65 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:21,787]\u001b[0m Trial 66 finished with value: -0.946236559139785 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:29,857]\u001b[0m Trial 67 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 900, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:06:32,635]\u001b[0m Trial 68 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:33,632]\u001b[0m Trial 69 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:34,602]\u001b[0m Trial 70 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:35,626]\u001b[0m Trial 71 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:36,632]\u001b[0m Trial 72 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:37,568]\u001b[0m Trial 73 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:38,390]\u001b[0m Trial 74 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:40,150]\u001b[0m Trial 75 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:42,057]\u001b[0m Trial 76 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:49,003]\u001b[0m Trial 77 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 700, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:49,994]\u001b[0m Trial 78 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:51,912]\u001b[0m Trial 79 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:53,065]\u001b[0m Trial 80 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:54,418]\u001b[0m Trial 81 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:55,642]\u001b[0m Trial 82 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:57,803]\u001b[0m Trial 83 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:06:58,992]\u001b[0m Trial 84 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:00,782]\u001b[0m Trial 85 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:01,654]\u001b[0m Trial 86 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:03,439]\u001b[0m Trial 87 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:04,387]\u001b[0m Trial 88 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:05,908]\u001b[0m Trial 89 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:06,744]\u001b[0m Trial 90 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:07,683]\u001b[0m Trial 91 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:08,591]\u001b[0m Trial 92 finished with value: -0.956989247311828 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:10,389]\u001b[0m Trial 93 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:12,208]\u001b[0m Trial 94 finished with value: -0.956989247311828 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:13,093]\u001b[0m Trial 95 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:13,920]\u001b[0m Trial 96 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:16,571]\u001b[0m Trial 97 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:18,363]\u001b[0m Trial 98 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:23,316]\u001b[0m Trial 99 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 600, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 17 with value: -0.956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "Best Accuracy: 0.956989247311828\n",
      "Accuracy: 95.6989247311828\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the random forest model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=study.best_params[\"n_estimators\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "616cac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.6989247311828"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "95.6989247311828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8b04a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:07:25,244]\u001b[0m A new study created in memory with name: no-name-cac2e45b-55d9-4fa6-9e0a-3c7da1f1fc59\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:28,672]\u001b[0m Trial 0 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 400, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 0 with value: -0.8870967741935484.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:33,713]\u001b[0m Trial 1 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 600, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:37,721]\u001b[0m Trial 2 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 500, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:39,947]\u001b[0m Trial 3 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:46,958]\u001b[0m Trial 4 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 800, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: -0.9032258064516129.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:52,571]\u001b[0m Trial 5 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:07:59,410]\u001b[0m Trial 6 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:00,790]\u001b[0m Trial 7 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:08,565]\u001b[0m Trial 8 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 900, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:14,050]\u001b[0m Trial 9 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 700, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:19,390]\u001b[0m Trial 10 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 700, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:25,573]\u001b[0m Trial 11 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:32,833]\u001b[0m Trial 12 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:38,779]\u001b[0m Trial 13 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 800, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:39,485]\u001b[0m Trial 14 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:47,294]\u001b[0m Trial 15 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 900, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:51,839]\u001b[0m Trial 16 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 600, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:08:58,003]\u001b[0m Trial 17 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 800, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:01,701]\u001b[0m Trial 18 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:10,293]\u001b[0m Trial 19 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 1000, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:14,968]\u001b[0m Trial 20 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:22,562]\u001b[0m Trial 21 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:29,544]\u001b[0m Trial 22 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:36,966]\u001b[0m Trial 23 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:43,164]\u001b[0m Trial 24 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:48,123]\u001b[0m Trial 25 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 800, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:09:54,264]\u001b[0m Trial 26 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:00,347]\u001b[0m Trial 27 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 700, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:07,221]\u001b[0m Trial 28 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 900, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:09,791]\u001b[0m Trial 29 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 400, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:14,152]\u001b[0m Trial 30 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:18,289]\u001b[0m Trial 31 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:22,398]\u001b[0m Trial 32 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:25,224]\u001b[0m Trial 33 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 400, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:10:28,934]\u001b[0m Trial 34 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 600, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:32,635]\u001b[0m Trial 35 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:34,726]\u001b[0m Trial 36 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:39,431]\u001b[0m Trial 37 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 600, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:43,205]\u001b[0m Trial 38 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:45,567]\u001b[0m Trial 39 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:49,343]\u001b[0m Trial 40 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 600, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:10:55,125]\u001b[0m Trial 41 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:00,907]\u001b[0m Trial 42 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:06,096]\u001b[0m Trial 43 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 600, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:09,607]\u001b[0m Trial 44 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:15,505]\u001b[0m Trial 45 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 800, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:19,238]\u001b[0m Trial 46 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 600, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:23,917]\u001b[0m Trial 47 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:27,557]\u001b[0m Trial 48 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 500, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:31,015]\u001b[0m Trial 49 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 400, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:35,818]\u001b[0m Trial 50 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 800, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:41,858]\u001b[0m Trial 51 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:45,808]\u001b[0m Trial 52 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:50,559]\u001b[0m Trial 53 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:11:58,577]\u001b[0m Trial 54 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:05,698]\u001b[0m Trial 55 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:10,954]\u001b[0m Trial 56 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 800, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:17,011]\u001b[0m Trial 57 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:21,368]\u001b[0m Trial 58 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:26,634]\u001b[0m Trial 59 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 800, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:32,966]\u001b[0m Trial 60 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 700, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:40,330]\u001b[0m Trial 61 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:46,940]\u001b[0m Trial 62 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 900, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:12:54,028]\u001b[0m Trial 63 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:01,035]\u001b[0m Trial 64 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:07,567]\u001b[0m Trial 65 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:13,971]\u001b[0m Trial 66 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:15,381]\u001b[0m Trial 67 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:13:21,382]\u001b[0m Trial 68 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:27,383]\u001b[0m Trial 69 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:33,558]\u001b[0m Trial 70 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:39,559]\u001b[0m Trial 71 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:45,553]\u001b[0m Trial 72 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:52,752]\u001b[0m Trial 73 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:13:58,868]\u001b[0m Trial 74 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:04,247]\u001b[0m Trial 75 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 800, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:10,262]\u001b[0m Trial 76 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:11,038]\u001b[0m Trial 77 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:17,733]\u001b[0m Trial 78 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:23,155]\u001b[0m Trial 79 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 900, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:29,139]\u001b[0m Trial 80 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:35,105]\u001b[0m Trial 81 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:39,163]\u001b[0m Trial 82 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 600, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:46,062]\u001b[0m Trial 83 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:51,783]\u001b[0m Trial 84 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 800, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:14:57,792]\u001b[0m Trial 85 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:03,304]\u001b[0m Trial 86 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 900, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:07,836]\u001b[0m Trial 87 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 600, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:13,516]\u001b[0m Trial 88 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 800, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:19,901]\u001b[0m Trial 89 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:23,276]\u001b[0m Trial 90 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:29,342]\u001b[0m Trial 91 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:35,501]\u001b[0m Trial 92 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:41,549]\u001b[0m Trial 93 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:46,884]\u001b[0m Trial 94 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 800, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:53,603]\u001b[0m Trial 95 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:15:57,948]\u001b[0m Trial 96 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 600, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:02,784]\u001b[0m Trial 97 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:08,213]\u001b[0m Trial 98 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 900, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:15,417]\u001b[0m Trial 99 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 1000, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: -0.9193548387096774.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 900, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}\n",
      "Best Accuracy: 0.9193548387096774\n",
      "Accuracy: 91.93548387096774\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000, step=100)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the random forest model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=study.best_params[\"n_estimators\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=study.best_params[\"min_samples_leaf\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0fe348",
   "metadata": {},
   "source": [
    "###### support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3999dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:21,417]\u001b[0m A new study created in memory with name: no-name-6e6b9f91-4831-4928-a746-55b2c761608f\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,513]\u001b[0m Trial 0 finished with value: -0.7956989247311828 and parameters: {'C': 151.2421953738923, 'gamma': 220.5768944054082}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,611]\u001b[0m Trial 1 finished with value: -0.7956989247311828 and parameters: {'C': 55.937305990653925, 'gamma': 54.75582052029073}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,703]\u001b[0m Trial 2 finished with value: -0.7956989247311828 and parameters: {'C': 8.165106203133089, 'gamma': 453.25641569359357}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,799]\u001b[0m Trial 3 finished with value: -0.7956989247311828 and parameters: {'C': 0.03194213804558949, 'gamma': 0.3084681751364566}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,893]\u001b[0m Trial 4 finished with value: -0.7956989247311828 and parameters: {'C': 165.27029784117315, 'gamma': 112.9968885561803}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:21,942]\u001b[0m Trial 5 finished with value: -0.7956989247311828 and parameters: {'C': 0.0018635897179331527, 'gamma': 0.41454500265203564}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,032]\u001b[0m Trial 6 finished with value: -0.7956989247311828 and parameters: {'C': 504.23027714023425, 'gamma': 0.004337375822548434}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,129]\u001b[0m Trial 7 finished with value: -0.7956989247311828 and parameters: {'C': 0.2796918124790781, 'gamma': 213.678154122418}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,227]\u001b[0m Trial 8 finished with value: -0.7956989247311828 and parameters: {'C': 12.609457386219189, 'gamma': 34.98612250436248}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,335]\u001b[0m Trial 9 finished with value: -0.7956989247311828 and parameters: {'C': 93.31958090886911, 'gamma': 6.164561773096666}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,463]\u001b[0m Trial 10 finished with value: -0.7956989247311828 and parameters: {'C': 792.2424989810912, 'gamma': 4.309642548028817}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,586]\u001b[0m Trial 11 finished with value: -0.7956989247311828 and parameters: {'C': 22.54896766509836, 'gamma': 919.754937001809}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,699]\u001b[0m Trial 12 finished with value: -0.7956989247311828 and parameters: {'C': 1.7999787053780287, 'gamma': 33.988116204970325}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,815]\u001b[0m Trial 13 finished with value: -0.7956989247311828 and parameters: {'C': 71.18094955983497, 'gamma': 895.5074909450758}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:22,940]\u001b[0m Trial 14 finished with value: -0.7956989247311828 and parameters: {'C': 986.9283874045892, 'gamma': 59.80824414291159}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,058]\u001b[0m Trial 15 finished with value: -0.7956989247311828 and parameters: {'C': 44.39829368317859, 'gamma': 7.413031199861728}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,163]\u001b[0m Trial 16 finished with value: -0.7956989247311828 and parameters: {'C': 187.19771800866397, 'gamma': 169.88155775668974}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,292]\u001b[0m Trial 17 finished with value: -0.7956989247311828 and parameters: {'C': 3.4769582448680025, 'gamma': 17.530241250991754}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,414]\u001b[0m Trial 18 finished with value: -0.7956989247311828 and parameters: {'C': 20.01867150444371, 'gamma': 187.21989628337323}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,529]\u001b[0m Trial 19 finished with value: -0.7956989247311828 and parameters: {'C': 0.9524844403884835, 'gamma': 2.3489059578866684}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,647]\u001b[0m Trial 20 finished with value: -0.7956989247311828 and parameters: {'C': 208.24307201726998, 'gamma': 23.911619044572753}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,770]\u001b[0m Trial 21 finished with value: -0.7956989247311828 and parameters: {'C': 8.762855408004794, 'gamma': 987.6339988147561}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:23,886]\u001b[0m Trial 22 finished with value: -0.7956989247311828 and parameters: {'C': 39.643478642453275, 'gamma': 304.8797223333514}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,003]\u001b[0m Trial 23 finished with value: -0.7956989247311828 and parameters: {'C': 6.642216123919067, 'gamma': 91.5934277838293}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,120]\u001b[0m Trial 24 finished with value: -0.7956989247311828 and parameters: {'C': 38.664939454528124, 'gamma': 380.3887378934858}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,236]\u001b[0m Trial 25 finished with value: -0.7956989247311828 and parameters: {'C': 228.61473739162815, 'gamma': 64.29637355988895}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,349]\u001b[0m Trial 26 finished with value: -0.7956989247311828 and parameters: {'C': 7.6769903541925295, 'gamma': 472.9204773075118}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,468]\u001b[0m Trial 27 finished with value: -0.7956989247311828 and parameters: {'C': 52.90329994705111, 'gamma': 17.378014540577038}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,583]\u001b[0m Trial 28 finished with value: -0.7956989247311828 and parameters: {'C': 27.24003270416272, 'gamma': 84.79529564012144}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,707]\u001b[0m Trial 29 finished with value: -0.7956989247311828 and parameters: {'C': 346.7224957557658, 'gamma': 364.9086273784209}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,829]\u001b[0m Trial 30 finished with value: -0.7956989247311828 and parameters: {'C': 105.26476697389177, 'gamma': 1.7031643349654444}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:24,928]\u001b[0m Trial 31 finished with value: -0.7956989247311828 and parameters: {'C': 0.09535343207573721, 'gamma': 0.5005705336871634}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,041]\u001b[0m Trial 32 finished with value: -0.7956989247311828 and parameters: {'C': 0.02880036887395847, 'gamma': 0.14685257786865305}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,113]\u001b[0m Trial 33 finished with value: -0.7956989247311828 and parameters: {'C': 0.0014136323116359783, 'gamma': 125.3085082663699}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,234]\u001b[0m Trial 34 finished with value: -0.7956989247311828 and parameters: {'C': 356.5576564091563, 'gamma': 0.11971547625728073}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,348]\u001b[0m Trial 35 finished with value: -0.7956989247311828 and parameters: {'C': 0.005429475365338186, 'gamma': 208.20294173916528}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,468]\u001b[0m Trial 36 finished with value: -0.7956989247311828 and parameters: {'C': 0.6263775957015036, 'gamma': 64.70602626572368}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,589]\u001b[0m Trial 37 finished with value: -0.7956989247311828 and parameters: {'C': 2.929115821813884, 'gamma': 13.106115326876326}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,711]\u001b[0m Trial 38 finished with value: -0.7956989247311828 and parameters: {'C': 109.38611267384002, 'gamma': 523.6835488144967}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:25,830]\u001b[0m Trial 39 finished with value: -0.7956989247311828 and parameters: {'C': 15.4692437528405, 'gamma': 39.700812759552186}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:25,951]\u001b[0m Trial 40 finished with value: -0.7956989247311828 and parameters: {'C': 510.410744587342, 'gamma': 149.88303804887414}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,077]\u001b[0m Trial 41 finished with value: -0.7956989247311828 and parameters: {'C': 111.00304028650304, 'gamma': 119.50344838516814}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,282]\u001b[0m Trial 42 finished with value: -0.7956989247311828 and parameters: {'C': 15.184150677925144, 'gamma': 32.66682827598535}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,408]\u001b[0m Trial 43 finished with value: -0.7956989247311828 and parameters: {'C': 667.5464726448087, 'gamma': 614.2640849316305}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,533]\u001b[0m Trial 44 finished with value: -0.7956989247311828 and parameters: {'C': 67.45401068518564, 'gamma': 234.95172635080047}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,648]\u001b[0m Trial 45 finished with value: -0.7956989247311828 and parameters: {'C': 160.29893772317305, 'gamma': 39.22946606191918}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,782]\u001b[0m Trial 46 finished with value: -0.7956989247311828 and parameters: {'C': 25.32763569959754, 'gamma': 9.683185877273052}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:26,904]\u001b[0m Trial 47 finished with value: -0.7956989247311828 and parameters: {'C': 57.86350935204422, 'gamma': 258.66362699674096}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,023]\u001b[0m Trial 48 finished with value: -0.7956989247311828 and parameters: {'C': 300.8204150122425, 'gamma': 4.098691927042033}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,140]\u001b[0m Trial 49 finished with value: -0.7956989247311828 and parameters: {'C': 140.93918899066162, 'gamma': 804.66500806563}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,254]\u001b[0m Trial 50 finished with value: -0.7956989247311828 and parameters: {'C': 817.1163308138616, 'gamma': 119.88223162262905}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,377]\u001b[0m Trial 51 finished with value: -0.7956989247311828 and parameters: {'C': 0.019799422119771287, 'gamma': 0.4327332176360023}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,450]\u001b[0m Trial 52 finished with value: -0.7956989247311828 and parameters: {'C': 0.0013818968157876313, 'gamma': 342.6238952644928}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,564]\u001b[0m Trial 53 finished with value: -0.7956989247311828 and parameters: {'C': 76.05401324507463, 'gamma': 910.4330856031597}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,687]\u001b[0m Trial 54 finished with value: -0.7956989247311828 and parameters: {'C': 5.086101298773477, 'gamma': 22.616652085692426}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,802]\u001b[0m Trial 55 finished with value: -0.7956989247311828 and parameters: {'C': 0.2591790992505426, 'gamma': 49.34373542222866}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:27,927]\u001b[0m Trial 56 finished with value: -0.7956989247311828 and parameters: {'C': 185.7446826904613, 'gamma': 76.1272738846857}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,057]\u001b[0m Trial 57 finished with value: -0.7956989247311828 and parameters: {'C': 12.973419660084936, 'gamma': 190.9153467403331}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,180]\u001b[0m Trial 58 finished with value: -0.7956989247311828 and parameters: {'C': 1.8228260436924337, 'gamma': 566.3527708979422}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,293]\u001b[0m Trial 59 finished with value: -0.7956989247311828 and parameters: {'C': 39.834829031290866, 'gamma': 336.0199574391216}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,417]\u001b[0m Trial 60 finished with value: -0.7956989247311828 and parameters: {'C': 9.909562208294098, 'gamma': 93.1319134115872}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,550]\u001b[0m Trial 61 finished with value: -0.7956989247311828 and parameters: {'C': 535.7794681427735, 'gamma': 0.019423830207796478}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,665]\u001b[0m Trial 62 finished with value: -0.7956989247311828 and parameters: {'C': 293.7852799872327, 'gamma': 0.0011143124481958248}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,789]\u001b[0m Trial 63 finished with value: -0.7956989247311828 and parameters: {'C': 26.701263932988777, 'gamma': 7.6783721049246}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:28,905]\u001b[0m Trial 64 finished with value: -0.7956989247311828 and parameters: {'C': 180.13889798980003, 'gamma': 3.600389488082747}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,028]\u001b[0m Trial 65 finished with value: -0.7956989247311828 and parameters: {'C': 944.6555198627194, 'gamma': 1.154325795735285}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,148]\u001b[0m Trial 66 finished with value: -0.7956989247311828 and parameters: {'C': 85.49141084402105, 'gamma': 18.35873012338306}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,272]\u001b[0m Trial 67 finished with value: -0.7956989247311828 and parameters: {'C': 350.4015762269613, 'gamma': 11.023105114300284}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,386]\u001b[0m Trial 68 finished with value: -0.7956989247311828 and parameters: {'C': 40.0658978042771, 'gamma': 6.489900587000959}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,510]\u001b[0m Trial 69 finished with value: -0.7956989247311828 and parameters: {'C': 110.17230627004955, 'gamma': 30.00530084804545}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,623]\u001b[0m Trial 70 finished with value: -0.7956989247311828 and parameters: {'C': 0.003899509843715903, 'gamma': 164.8599636108191}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,746]\u001b[0m Trial 71 finished with value: -0.7956989247311828 and parameters: {'C': 0.1654684637225995, 'gamma': 502.59033952190737}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,860]\u001b[0m Trial 72 finished with value: -0.7956989247311828 and parameters: {'C': 0.03720590412399802, 'gamma': 57.95983053413701}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:29,992]\u001b[0m Trial 73 finished with value: -0.7956989247311828 and parameters: {'C': 0.7850360262209766, 'gamma': 245.67597858556348}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,108]\u001b[0m Trial 74 finished with value: -0.7956989247311828 and parameters: {'C': 520.6231756432668, 'gamma': 106.30120121502897}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,230]\u001b[0m Trial 75 finished with value: -0.7956989247311828 and parameters: {'C': 0.42236091152921573, 'gamma': 162.85934247751885}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,363]\u001b[0m Trial 76 finished with value: -0.7956989247311828 and parameters: {'C': 254.46259186048025, 'gamma': 411.7932792583201}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,486]\u001b[0m Trial 77 finished with value: -0.7956989247311828 and parameters: {'C': 66.2607527407672, 'gamma': 71.2377949124279}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:30,609]\u001b[0m Trial 78 finished with value: -0.7956989247311828 and parameters: {'C': 1.7731897743987404, 'gamma': 271.48431744843174}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,736]\u001b[0m Trial 79 finished with value: -0.7956989247311828 and parameters: {'C': 141.59275892040316, 'gamma': 664.9261635932362}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,849]\u001b[0m Trial 80 finished with value: -0.7956989247311828 and parameters: {'C': 0.09415149566598836, 'gamma': 44.13460692809864}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:30,964]\u001b[0m Trial 81 finished with value: -0.7956989247311828 and parameters: {'C': 6.283116447543879, 'gamma': 122.13064405093529}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,097]\u001b[0m Trial 82 finished with value: -0.7956989247311828 and parameters: {'C': 23.70973493764282, 'gamma': 15.693175522206484}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,223]\u001b[0m Trial 83 finished with value: -0.7956989247311828 and parameters: {'C': 17.99827498763539, 'gamma': 55.86998260738557}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,336]\u001b[0m Trial 84 finished with value: -0.7956989247311828 and parameters: {'C': 30.82425499655729, 'gamma': 24.953994466687224}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,449]\u001b[0m Trial 85 finished with value: -0.7956989247311828 and parameters: {'C': 44.237484788854886, 'gamma': 90.58174339089965}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,574]\u001b[0m Trial 86 finished with value: -0.7956989247311828 and parameters: {'C': 208.2684350571288, 'gamma': 207.78666598000297}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,699]\u001b[0m Trial 87 finished with value: -0.7956989247311828 and parameters: {'C': 52.434492867241424, 'gamma': 324.6900060942237}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,812]\u001b[0m Trial 88 finished with value: -0.7956989247311828 and parameters: {'C': 4.053604874462906, 'gamma': 36.46016755716419}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:31,937]\u001b[0m Trial 89 finished with value: -0.7956989247311828 and parameters: {'C': 10.195391735094228, 'gamma': 145.0724613755751}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,052]\u001b[0m Trial 90 finished with value: -0.7956989247311828 and parameters: {'C': 86.03771261329835, 'gamma': 970.9303953839492}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,176]\u001b[0m Trial 91 finished with value: -0.7956989247311828 and parameters: {'C': 106.90839588442869, 'gamma': 73.14647432849681}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,295]\u001b[0m Trial 92 finished with value: -0.7956989247311828 and parameters: {'C': 420.36244388893243, 'gamma': 23.93173815232}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,419]\u001b[0m Trial 93 finished with value: -0.7956989247311828 and parameters: {'C': 232.88018021566674, 'gamma': 48.98749336063328}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,533]\u001b[0m Trial 94 finished with value: -0.7956989247311828 and parameters: {'C': 145.8451733002623, 'gamma': 2.9091694803454016}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,658]\u001b[0m Trial 95 finished with value: -0.7956989247311828 and parameters: {'C': 19.1990481500792, 'gamma': 1.9525272094226234}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,774]\u001b[0m Trial 96 finished with value: -0.7956989247311828 and parameters: {'C': 50.740589131244235, 'gamma': 97.71906470826693}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,855]\u001b[0m Trial 97 finished with value: -0.7956989247311828 and parameters: {'C': 0.0010077278742229774, 'gamma': 0.5107387683117488}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:32,978]\u001b[0m Trial 98 finished with value: -0.7956989247311828 and parameters: {'C': 11.86065613720945, 'gamma': 197.24727876781787}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,099]\u001b[0m Trial 99 finished with value: -0.7956989247311828 and parameters: {'C': 32.75515912338437, 'gamma': 5.035577360494179}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 151.2421953738923, 'gamma': 220.5768944054082}\n",
      "Best Accuracy: 0.7956989247311828\n",
      "Accuracy: 79.56989247311827\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n",
    "    gamma = trial.suggest_loguniform(\"gamma\", 1e-3, 1e3)\n",
    "\n",
    "    model = SVC(C=C, gamma=gamma, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the support vector machine model with the best hyperparameters\n",
    "best_model = SVC(\n",
    "    C=study.best_params[\"C\"],\n",
    "    gamma=study.best_params[\"gamma\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f5b4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:33,233]\u001b[0m A new study created in memory with name: no-name-b44da10e-1039-414f-8478-64e17dd57868\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,300]\u001b[0m Trial 0 finished with value: -0.7956989247311828 and parameters: {'C': 0.0020671055041594825, 'gamma': 246.795438165782}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,372]\u001b[0m Trial 1 finished with value: -0.7956989247311828 and parameters: {'C': 476.7339616918006, 'gamma': 0.9491913212468617}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,467]\u001b[0m Trial 2 finished with value: -0.7956989247311828 and parameters: {'C': 168.0149087827016, 'gamma': 80.57631956815447}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,534]\u001b[0m Trial 3 finished with value: -0.7956989247311828 and parameters: {'C': 9.198094812112187, 'gamma': 0.21202242991516618}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,575]\u001b[0m Trial 4 finished with value: -0.7956989247311828 and parameters: {'C': 0.0275874217704142, 'gamma': 0.04558010549602454}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,634]\u001b[0m Trial 5 finished with value: -0.7956989247311828 and parameters: {'C': 0.036035945445651564, 'gamma': 0.12676539594704722}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,710]\u001b[0m Trial 6 finished with value: -0.7956989247311828 and parameters: {'C': 0.01937325312095713, 'gamma': 135.43095459674385}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,777]\u001b[0m Trial 7 finished with value: -0.7956989247311828 and parameters: {'C': 162.03428020260543, 'gamma': 3.8037004091497604}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,864]\u001b[0m Trial 8 finished with value: -0.7956989247311828 and parameters: {'C': 427.9898343292553, 'gamma': 276.3252449851481}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,931]\u001b[0m Trial 9 finished with value: -0.7956989247311828 and parameters: {'C': 0.5075571479547749, 'gamma': 6.887615040662517}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:33,974]\u001b[0m Trial 10 finished with value: -0.7956989247311828 and parameters: {'C': 0.001391512414989506, 'gamma': 0.0025654093592201036}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,083]\u001b[0m Trial 11 finished with value: -0.7956989247311828 and parameters: {'C': 4.74677590521901, 'gamma': 14.67257743077178}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,194]\u001b[0m Trial 12 finished with value: -0.7956989247311828 and parameters: {'C': 17.981525146075313, 'gamma': 742.5519290496687}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,287]\u001b[0m Trial 13 finished with value: -0.7956989247311828 and parameters: {'C': 809.4854736526594, 'gamma': 1.4442369452263817}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,382]\u001b[0m Trial 14 finished with value: -0.7956989247311828 and parameters: {'C': 0.7971956812561731, 'gamma': 24.0392841612892}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,438]\u001b[0m Trial 15 finished with value: -0.7956989247311828 and parameters: {'C': 0.0010435827770859773, 'gamma': 1.1037060437233086}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,553]\u001b[0m Trial 16 finished with value: -0.7956989247311828 and parameters: {'C': 33.405931304846014, 'gamma': 761.6055568971132}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,659]\u001b[0m Trial 17 finished with value: -0.7956989247311828 and parameters: {'C': 2.76280132506357, 'gamma': 31.78891802466973}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,745]\u001b[0m Trial 18 finished with value: -0.7956989247311828 and parameters: {'C': 64.63062830441368, 'gamma': 4.178481110734506}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,842]\u001b[0m Trial 19 finished with value: -0.7956989247311828 and parameters: {'C': 0.39653453535960825, 'gamma': 50.20373432069363}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:34,952]\u001b[0m Trial 20 finished with value: -0.7956989247311828 and parameters: {'C': 0.16183522723445187, 'gamma': 165.31152668909587}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,069]\u001b[0m Trial 21 finished with value: -0.7956989247311828 and parameters: {'C': 122.9640193057279, 'gamma': 67.97836483300088}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,174]\u001b[0m Trial 22 finished with value: -0.7956989247311828 and parameters: {'C': 357.65203968292553, 'gamma': 12.976738565133958}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,283]\u001b[0m Trial 23 finished with value: -0.7956989247311828 and parameters: {'C': 42.00899018441847, 'gamma': 999.7937548364968}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,390]\u001b[0m Trial 24 finished with value: -0.7956989247311828 and parameters: {'C': 941.1725980416327, 'gamma': 111.64534016856987}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,492]\u001b[0m Trial 25 finished with value: -0.7956989247311828 and parameters: {'C': 172.3061370561769, 'gamma': 45.02136828245571}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,610]\u001b[0m Trial 26 finished with value: -0.7956989247311828 and parameters: {'C': 2.9780204554851375, 'gamma': 358.57438916236515}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,722]\u001b[0m Trial 27 finished with value: -0.7956989247311828 and parameters: {'C': 26.78701581749666, 'gamma': 244.3236250230062}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,837]\u001b[0m Trial 28 finished with value: -0.7956989247311828 and parameters: {'C': 79.55246266246071, 'gamma': 11.175953525452366}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:35,921]\u001b[0m Trial 29 finished with value: -0.7956989247311828 and parameters: {'C': 10.121263428910192, 'gamma': 0.42760988069768724}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,019]\u001b[0m Trial 30 finished with value: -0.7956989247311828 and parameters: {'C': 12.353450744624425, 'gamma': 2.3147540691038566}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,094]\u001b[0m Trial 31 finished with value: -0.7956989247311828 and parameters: {'C': 272.0891984448316, 'gamma': 0.25370633803925735}. Best is trial 0 with value: -0.7956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,179]\u001b[0m Trial 32 finished with value: -0.8172043010752689 and parameters: {'C': 50.150614849076966, 'gamma': 0.06906480303504743}. Best is trial 32 with value: -0.8172043010752689.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,254]\u001b[0m Trial 33 finished with value: -0.8279569892473119 and parameters: {'C': 78.0967440765113, 'gamma': 0.05736527020964925}. Best is trial 33 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,329]\u001b[0m Trial 34 finished with value: -0.8225806451612904 and parameters: {'C': 82.32645686395333, 'gamma': 0.06708924621655886}. Best is trial 33 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,402]\u001b[0m Trial 35 finished with value: -0.8763440860215054 and parameters: {'C': 69.21077895630778, 'gamma': 0.04228773587125157}. Best is trial 35 with value: -0.8763440860215054.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,475]\u001b[0m Trial 36 finished with value: -0.8763440860215054 and parameters: {'C': 59.53210281509234, 'gamma': 0.04139402772371032}. Best is trial 35 with value: -0.8763440860215054.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,540]\u001b[0m Trial 37 finished with value: -0.8978494623655914 and parameters: {'C': 21.444255630634743, 'gamma': 0.022376069194965677}. Best is trial 37 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,593]\u001b[0m Trial 38 finished with value: -0.8924731182795699 and parameters: {'C': 6.758606056154831, 'gamma': 0.02361696141985294}. Best is trial 37 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:36,665]\u001b[0m Trial 39 finished with value: -0.8924731182795699 and parameters: {'C': 22.637070692146064, 'gamma': 0.02313727748792173}. Best is trial 37 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,722]\u001b[0m Trial 40 finished with value: -0.9086021505376344 and parameters: {'C': 18.358658008186485, 'gamma': 0.017281841926823565}. Best is trial 40 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,772]\u001b[0m Trial 41 finished with value: -0.9032258064516129 and parameters: {'C': 22.26254043492283, 'gamma': 0.020382499366019543}. Best is trial 40 with value: -0.9086021505376344.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,827]\u001b[0m Trial 42 finished with value: -0.9139784946236559 and parameters: {'C': 6.303410510857286, 'gamma': 0.017403054416094126}. Best is trial 42 with value: -0.9139784946236559.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,871]\u001b[0m Trial 43 finished with value: -0.9193548387096774 and parameters: {'C': 5.40616613023465, 'gamma': 0.010605939456979928}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,926]\u001b[0m Trial 44 finished with value: -0.9086021505376344 and parameters: {'C': 13.27471053952844, 'gamma': 0.007298319173518863}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:36,971]\u001b[0m Trial 45 finished with value: -0.9139784946236559 and parameters: {'C': 4.195949104792248, 'gamma': 0.006157948371646305}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,028]\u001b[0m Trial 46 finished with value: -0.9139784946236559 and parameters: {'C': 4.51581467580141, 'gamma': 0.006266046989075695}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,079]\u001b[0m Trial 47 finished with value: -0.8494623655913979 and parameters: {'C': 1.8272358575257148, 'gamma': 0.0016682650452895023}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,138]\u001b[0m Trial 48 finished with value: -0.8978494623655914 and parameters: {'C': 6.606749686393167, 'gamma': 0.005937071610989117}. Best is trial 43 with value: -0.9193548387096774.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,179]\u001b[0m Trial 49 finished with value: -0.9301075268817204 and parameters: {'C': 4.337493225309348, 'gamma': 0.004428023949986605}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,225]\u001b[0m Trial 50 finished with value: -0.9086021505376344 and parameters: {'C': 3.6150811374008205, 'gamma': 0.0035593552277615446}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,279]\u001b[0m Trial 51 finished with value: -0.8924731182795699 and parameters: {'C': 6.498553276002179, 'gamma': 0.0010101307465347842}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,338]\u001b[0m Trial 52 finished with value: -0.9193548387096774 and parameters: {'C': 1.670632055007712, 'gamma': 0.010021091869870569}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,388]\u001b[0m Trial 53 finished with value: -0.9193548387096774 and parameters: {'C': 1.6796037265225108, 'gamma': 0.008784664748282671}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,443]\u001b[0m Trial 54 finished with value: -0.9247311827956989 and parameters: {'C': 1.493522294846178, 'gamma': 0.010646059974668007}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,498]\u001b[0m Trial 55 finished with value: -0.9086021505376344 and parameters: {'C': 1.7527132768925124, 'gamma': 0.011965366625629486}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,555]\u001b[0m Trial 56 finished with value: -0.8655913978494624 and parameters: {'C': 1.3391939365037389, 'gamma': 0.0031447041565736042}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,614]\u001b[0m Trial 57 finished with value: -0.8924731182795699 and parameters: {'C': 0.8885712315496115, 'gamma': 0.012291775731836627}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,660]\u001b[0m Trial 58 finished with value: -0.8064516129032258 and parameters: {'C': 0.6058438598984365, 'gamma': 0.00395870915508221}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,721]\u001b[0m Trial 59 finished with value: -0.8602150537634409 and parameters: {'C': 1.9569146962218305, 'gamma': 0.0019715988891806035}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,762]\u001b[0m Trial 60 finished with value: -0.8978494623655914 and parameters: {'C': 1.0307882731869422, 'gamma': 0.008302354635141866}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,825]\u001b[0m Trial 61 finished with value: -0.9086021505376344 and parameters: {'C': 2.6134527726101244, 'gamma': 0.012185946947778213}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,880]\u001b[0m Trial 62 finished with value: -0.9193548387096774 and parameters: {'C': 5.993476385264856, 'gamma': 0.004688647435649843}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,931]\u001b[0m Trial 63 finished with value: -0.9032258064516129 and parameters: {'C': 8.774212306748188, 'gamma': 0.004934218342237303}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:37,986]\u001b[0m Trial 64 finished with value: -0.8870967741935484 and parameters: {'C': 2.700679686837603, 'gamma': 0.0026049036832926096}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,038]\u001b[0m Trial 65 finished with value: -0.9086021505376344 and parameters: {'C': 5.131584698737884, 'gamma': 0.00927625341812358}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,079]\u001b[0m Trial 66 finished with value: -0.7956989247311828 and parameters: {'C': 0.41379023365370937, 'gamma': 0.0038115644425698626}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,130]\u001b[0m Trial 67 finished with value: -0.8440860215053764 and parameters: {'C': 1.4858706222197384, 'gamma': 0.001945444101128201}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,186]\u001b[0m Trial 68 finished with value: -0.9032258064516129 and parameters: {'C': 9.805152130370944, 'gamma': 0.004361585432433544}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,238]\u001b[0m Trial 69 finished with value: -0.9032258064516129 and parameters: {'C': 2.9308482814850114, 'gamma': 0.01547335015006981}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,290]\u001b[0m Trial 70 finished with value: -0.9086021505376344 and parameters: {'C': 1.0621293477730016, 'gamma': 0.010992068674715135}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,338]\u001b[0m Trial 71 finished with value: -0.9139784946236559 and parameters: {'C': 4.041541849662672, 'gamma': 0.006322801747649046}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,396]\u001b[0m Trial 72 finished with value: -0.9086021505376344 and parameters: {'C': 4.9701682025952545, 'gamma': 0.007194110390204674}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,448]\u001b[0m Trial 73 finished with value: -0.9086021505376344 and parameters: {'C': 2.201083311345278, 'gamma': 0.004999153472953186}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,512]\u001b[0m Trial 74 finished with value: -0.8817204301075269 and parameters: {'C': 3.7400253842735047, 'gamma': 0.031505480804570926}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,576]\u001b[0m Trial 75 finished with value: -0.9193548387096774 and parameters: {'C': 13.900484723698725, 'gamma': 0.01307945358410909}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,629]\u001b[0m Trial 76 finished with value: -0.9032258064516129 and parameters: {'C': 14.611901486718631, 'gamma': 0.015760307048491552}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,703]\u001b[0m Trial 77 finished with value: -0.8924731182795699 and parameters: {'C': 7.8231506660089245, 'gamma': 0.030408175556695095}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:38,757]\u001b[0m Trial 78 finished with value: -0.9086021505376344 and parameters: {'C': 14.266847876934802, 'gamma': 0.0097036583721944}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,843]\u001b[0m Trial 79 finished with value: -0.8118279569892473 and parameters: {'C': 1.3676186911322152, 'gamma': 0.085881705514487}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,918]\u001b[0m Trial 80 finished with value: -0.8817204301075269 and parameters: {'C': 32.774758083095364, 'gamma': 0.0318949243257301}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:38,971]\u001b[0m Trial 81 finished with value: -0.9086021505376344 and parameters: {'C': 5.8728452983282535, 'gamma': 0.008133460275289503}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,034]\u001b[0m Trial 82 finished with value: -0.9086021505376344 and parameters: {'C': 3.925532168749192, 'gamma': 0.015976749348230887}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,088]\u001b[0m Trial 83 finished with value: -0.9032258064516129 and parameters: {'C': 9.821001915589946, 'gamma': 0.005431201606095147}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,143]\u001b[0m Trial 84 finished with value: -0.8978494623655914 and parameters: {'C': 2.4354154406047654, 'gamma': 0.003184457824216146}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,196]\u001b[0m Trial 85 finished with value: -0.9193548387096774 and parameters: {'C': 7.371298501921899, 'gamma': 0.009022853177990217}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,249]\u001b[0m Trial 86 finished with value: -0.9193548387096774 and parameters: {'C': 7.580646438550096, 'gamma': 0.010976004283356183}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,304]\u001b[0m Trial 87 finished with value: -0.9139784946236559 and parameters: {'C': 12.633912726536114, 'gamma': 0.009301737183828358}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,354]\u001b[0m Trial 88 finished with value: -0.9193548387096774 and parameters: {'C': 17.032150765666714, 'gamma': 0.002806979226003727}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,404]\u001b[0m Trial 89 finished with value: -0.8978494623655914 and parameters: {'C': 8.758429085921863, 'gamma': 0.021947570236902608}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,460]\u001b[0m Trial 90 finished with value: -0.8978494623655914 and parameters: {'C': 3.2441961780612782, 'gamma': 0.014187203612170943}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,514]\u001b[0m Trial 91 finished with value: -0.9086021505376344 and parameters: {'C': 15.56565389316552, 'gamma': 0.002580389700830114}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,579]\u001b[0m Trial 92 finished with value: -0.9086021505376344 and parameters: {'C': 32.794900597660224, 'gamma': 0.004500637734305209}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,634]\u001b[0m Trial 93 finished with value: -0.9139784946236559 and parameters: {'C': 7.243429440371356, 'gamma': 0.007247505026833124}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,687]\u001b[0m Trial 94 finished with value: -0.9139784946236559 and parameters: {'C': 20.29578711483221, 'gamma': 0.0013305403910719646}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,741]\u001b[0m Trial 95 finished with value: -0.9247311827956989 and parameters: {'C': 10.253720452378717, 'gamma': 0.0027008982031557576}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,796]\u001b[0m Trial 96 finished with value: -0.9086021505376344 and parameters: {'C': 5.354305414849675, 'gamma': 0.002122458965350431}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,860]\u001b[0m Trial 97 finished with value: -0.9139784946236559 and parameters: {'C': 1.9256725813221907, 'gamma': 0.00995393638485031}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,913]\u001b[0m Trial 98 finished with value: -0.9086021505376344 and parameters: {'C': 11.224770473198857, 'gamma': 0.0038331703570443697}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:39,969]\u001b[0m Trial 99 finished with value: -0.8010752688172043 and parameters: {'C': 0.7308163481132213, 'gamma': 0.0013014921292950283}. Best is trial 49 with value: -0.9301075268817204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 4.337493225309348, 'gamma': 0.004428023949986605}\n",
      "Best Accuracy: 0.9301075268817204\n",
      "Accuracy: 93.01075268817203\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n",
    "    gamma = trial.suggest_loguniform(\"gamma\", 1e-3, 1e3)\n",
    "\n",
    "    model = SVC(C=C, gamma=gamma, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the support vector machine model with the best hyperparameters\n",
    "best_model = SVC(\n",
    "    C=study.best_params[\"C\"],\n",
    "    gamma=study.best_params[\"gamma\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c987d",
   "metadata": {},
   "source": [
    "###### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad0b7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:40,022]\u001b[0m A new study created in memory with name: no-name-2f67a592-c6f2-47e7-a6d3-63c03856505b\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,047]\u001b[0m Trial 0 finished with value: -0.8225806451612904 and parameters: {'var_smoothing': 3.192176149858837e-07}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,064]\u001b[0m Trial 1 finished with value: -0.7956989247311828 and parameters: {'var_smoothing': 3.756903056743719e-05}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,086]\u001b[0m Trial 2 finished with value: -0.7956989247311828 and parameters: {'var_smoothing': 0.0005371774259767182}. Best is trial 0 with value: -0.8225806451612904.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,110]\u001b[0m Trial 3 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 4.323427041841371e-08}. Best is trial 3 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,122]\u001b[0m Trial 4 finished with value: -0.7956989247311828 and parameters: {'var_smoothing': 4.141335773088376e-05}. Best is trial 3 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,145]\u001b[0m Trial 5 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.3517010577822918e-08}. Best is trial 3 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,162]\u001b[0m Trial 6 finished with value: -0.8064516129032258 and parameters: {'var_smoothing': 2.7366042631866382e-05}. Best is trial 3 with value: -0.8279569892473119.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,181]\u001b[0m Trial 7 finished with value: -0.8333333333333334 and parameters: {'var_smoothing': 1.1180159360482797e-07}. Best is trial 7 with value: -0.8333333333333334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,197]\u001b[0m Trial 8 finished with value: -0.8118279569892473 and parameters: {'var_smoothing': 1.6111103425051738e-05}. Best is trial 7 with value: -0.8333333333333334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,215]\u001b[0m Trial 9 finished with value: -0.7903225806451613 and parameters: {'var_smoothing': 0.00017108425921248305}. Best is trial 7 with value: -0.8333333333333334.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,238]\u001b[0m Trial 10 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.175659108031642e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,258]\u001b[0m Trial 11 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.007600213568387e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,291]\u001b[0m Trial 12 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0035374943562253e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,308]\u001b[0m Trial 13 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0475288884222481e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,344]\u001b[0m Trial 14 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 7.2930234539925555e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,362]\u001b[0m Trial 15 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.328054400170369e-06}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,386]\u001b[0m Trial 16 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.006717279474456e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,412]\u001b[0m Trial 17 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 3.153436561264885e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,437]\u001b[0m Trial 18 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 3.84356238331905e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,462]\u001b[0m Trial 19 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.3348790532046306e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,487]\u001b[0m Trial 20 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.1240116832209603e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,520]\u001b[0m Trial 21 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.3382796800197494e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,547]\u001b[0m Trial 22 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.4889412023040769e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,571]\u001b[0m Trial 23 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.727086336288923e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,604]\u001b[0m Trial 24 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0632044918753328e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,630]\u001b[0m Trial 25 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.4512778971656618e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,654]\u001b[0m Trial 26 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.3582627489312137e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,686]\u001b[0m Trial 27 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0198478060014676e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,712]\u001b[0m Trial 28 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 2.9874557209215995e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,736]\u001b[0m Trial 29 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 3.32964977142051e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,763]\u001b[0m Trial 30 finished with value: -0.8225806451612904 and parameters: {'var_smoothing': 3.0991518701035913e-07}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,795]\u001b[0m Trial 31 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0190452871851503e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,819]\u001b[0m Trial 32 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.66528475242043e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,846]\u001b[0m Trial 33 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.683649101033403e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,871]\u001b[0m Trial 34 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 2.928255589097877e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,889]\u001b[0m Trial 35 finished with value: -0.8333333333333334 and parameters: {'var_smoothing': 9.195834941418598e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,915]\u001b[0m Trial 36 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0010307233910692e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,939]\u001b[0m Trial 37 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 2.458748997129297e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,964]\u001b[0m Trial 38 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.469090051331574e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:40,990]\u001b[0m Trial 39 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.935152075143346e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,017]\u001b[0m Trial 40 finished with value: -0.8333333333333334 and parameters: {'var_smoothing': 9.110926115054418e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:41,037]\u001b[0m Trial 41 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.7093569943156465e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,070]\u001b[0m Trial 42 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.0532735252348487e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,095]\u001b[0m Trial 43 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 4.540709302914249e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,126]\u001b[0m Trial 44 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 6.516863884906183e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,154]\u001b[0m Trial 45 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.9876634930029913e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,173]\u001b[0m Trial 46 finished with value: -0.8333333333333334 and parameters: {'var_smoothing': 7.388386293307046e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,198]\u001b[0m Trial 47 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.6190093712629408e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,225]\u001b[0m Trial 48 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.87996570316203e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,254]\u001b[0m Trial 49 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.2477083417373592e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,278]\u001b[0m Trial 50 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.373311540763594e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,304]\u001b[0m Trial 51 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.6721690894634537e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,328]\u001b[0m Trial 52 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0166032563389055e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,358]\u001b[0m Trial 53 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.6878221348233491e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,379]\u001b[0m Trial 54 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.882432766959302e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,404]\u001b[0m Trial 55 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.5479989166272848e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,437]\u001b[0m Trial 56 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 3.1578265900763074e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,464]\u001b[0m Trial 57 finished with value: -0.8333333333333334 and parameters: {'var_smoothing': 8.314867319758237e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,491]\u001b[0m Trial 58 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 4.625081016769711e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,520]\u001b[0m Trial 59 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.6048458476742295e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,544]\u001b[0m Trial 60 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.274798711795111e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,578]\u001b[0m Trial 61 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.294793687535404e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,607]\u001b[0m Trial 62 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.2693563151562624e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,638]\u001b[0m Trial 63 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.7167399191115968e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,667]\u001b[0m Trial 64 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 4.284574863268248e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,697]\u001b[0m Trial 65 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.3117657642649874e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,717]\u001b[0m Trial 66 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 6.871734413684207e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,758]\u001b[0m Trial 67 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.3220321529812182e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,798]\u001b[0m Trial 68 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0471199024758138e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,826]\u001b[0m Trial 69 finished with value: -0.8279569892473119 and parameters: {'var_smoothing': 1.1862393546550145e-08}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,863]\u001b[0m Trial 70 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.2224941938250924e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,896]\u001b[0m Trial 71 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0163167426026399e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,925]\u001b[0m Trial 72 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.185047890090356e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,954]\u001b[0m Trial 73 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.5340142731945574e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:41,991]\u001b[0m Trial 74 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 4.335050884139396e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,011]\u001b[0m Trial 75 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.5712357546167446e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,037]\u001b[0m Trial 76 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 7.0121217699118215e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,087]\u001b[0m Trial 77 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.523127156387836e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,115]\u001b[0m Trial 78 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 3.1476024423765584e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,140]\u001b[0m Trial 79 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.3181649324122574e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,170]\u001b[0m Trial 80 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.101842724687276e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,195]\u001b[0m Trial 81 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.029399679757189e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,228]\u001b[0m Trial 82 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.025352665809881e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:42,255]\u001b[0m Trial 83 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.32031765438322e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,280]\u001b[0m Trial 84 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0735547313831625e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,307]\u001b[0m Trial 85 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.2947172260762947e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,329]\u001b[0m Trial 86 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.7408436775646666e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,353]\u001b[0m Trial 87 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.0026579627703786e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,378]\u001b[0m Trial 88 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.5069757876419178e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,403]\u001b[0m Trial 89 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.4535464656183618e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,430]\u001b[0m Trial 90 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 4.1845413684097666e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,453]\u001b[0m Trial 91 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.4239904053099218e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,479]\u001b[0m Trial 92 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 2.1658596345924836e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,512]\u001b[0m Trial 93 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.8027929168550433e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,538]\u001b[0m Trial 94 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.3059805963102298e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,570]\u001b[0m Trial 95 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.00397974891407e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,596]\u001b[0m Trial 96 finished with value: -0.8440860215053764 and parameters: {'var_smoothing': 2.9211786660565547e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,621]\u001b[0m Trial 97 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 5.843120255038149e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,654]\u001b[0m Trial 98 finished with value: -0.8387096774193549 and parameters: {'var_smoothing': 3.6444963430458922e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,673]\u001b[0m Trial 99 finished with value: -0.8494623655913979 and parameters: {'var_smoothing': 1.9788445791951643e-09}. Best is trial 10 with value: -0.8494623655913979.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'var_smoothing': 1.175659108031642e-09}\n",
      "Best Accuracy: 0.8494623655913979\n",
      "Accuracy: 84.94623655913979\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    var_smoothing = trial.suggest_loguniform(\"var_smoothing\", 1e-9, 1e-3)\n",
    "\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the Naive Bayes model with the best hyperparameters\n",
    "best_model = GaussianNB(var_smoothing=study.best_params[\"var_smoothing\"])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78bcf742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:42,726]\u001b[0m A new study created in memory with name: no-name-5504d6dc-a63f-4167-b116-e52e014a4df8\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,742]\u001b[0m Trial 0 finished with value: -0.23655913978494625 and parameters: {'var_smoothing': 2.2463335405604533e-05}. Best is trial 0 with value: -0.23655913978494625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,756]\u001b[0m Trial 1 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 1.2227676644561027e-06}. Best is trial 0 with value: -0.23655913978494625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,764]\u001b[0m Trial 2 finished with value: -0.23655913978494625 and parameters: {'var_smoothing': 1.3355084363159967e-05}. Best is trial 0 with value: -0.23655913978494625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,780]\u001b[0m Trial 3 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 2.110627909011757e-09}. Best is trial 0 with value: -0.23655913978494625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,788]\u001b[0m Trial 4 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 5.661722905152416e-07}. Best is trial 0 with value: -0.23655913978494625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,803]\u001b[0m Trial 5 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.0004354459886485999}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,815]\u001b[0m Trial 6 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 4.879799894775673e-07}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,823]\u001b[0m Trial 7 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 2.251325493644328e-07}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,831]\u001b[0m Trial 8 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 1.6628748407240287e-08}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,842]\u001b[0m Trial 9 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 7.968341256048212e-05}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,859]\u001b[0m Trial 10 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.0004174560806339595}. Best is trial 5 with value: -0.2903225806451613.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,876]\u001b[0m Trial 11 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006223504376805092}. Best is trial 11 with value: -0.2956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,904]\u001b[0m Trial 12 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0008288975662780251}. Best is trial 11 with value: -0.2956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,922]\u001b[0m Trial 13 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0008395018773554269}. Best is trial 11 with value: -0.2956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,936]\u001b[0m Trial 14 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 8.879101841401051e-05}. Best is trial 11 with value: -0.2956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,955]\u001b[0m Trial 15 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009209123809787445}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,971]\u001b[0m Trial 16 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 6.317063394407583e-06}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:42,996]\u001b[0m Trial 17 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 0.00011383800936256762}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,015]\u001b[0m Trial 18 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.0001844844309948318}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,038]\u001b[0m Trial 19 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.00097849854947111}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,057]\u001b[0m Trial 20 finished with value: -0.24731182795698925 and parameters: {'var_smoothing': 4.4092335319089915e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,072]\u001b[0m Trial 21 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0008911755590727605}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,099]\u001b[0m Trial 22 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00021678737677859356}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,118]\u001b[0m Trial 23 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.0002068239127432024}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,141]\u001b[0m Trial 24 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009329129464898025}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,156]\u001b[0m Trial 25 finished with value: -0.24731182795698925 and parameters: {'var_smoothing': 3.8002970956680556e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,171]\u001b[0m Trial 26 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00020821992002175644}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,192]\u001b[0m Trial 27 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 8.685527486775414e-06}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,205]\u001b[0m Trial 28 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009347925972628795}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,229]\u001b[0m Trial 29 finished with value: -0.23655913978494625 and parameters: {'var_smoothing': 2.3833438832675056e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,245]\u001b[0m Trial 30 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.00030093356908398043}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,262]\u001b[0m Trial 31 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005436798715631883}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,278]\u001b[0m Trial 32 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 9.277699632628171e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,296]\u001b[0m Trial 33 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009745617256833009}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,312]\u001b[0m Trial 34 finished with value: -0.27419354838709675 and parameters: {'var_smoothing': 0.00033331522113409296}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,332]\u001b[0m Trial 35 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.000978387165581921}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,353]\u001b[0m Trial 36 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.0003120226767793439}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,363]\u001b[0m Trial 37 finished with value: -0.24731182795698925 and parameters: {'var_smoothing': 4.1630789700596595e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,385]\u001b[0m Trial 38 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 0.0001422035950250373}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,398]\u001b[0m Trial 39 finished with value: -0.27419354838709675 and parameters: {'var_smoothing': 0.00033874005095547625}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,417]\u001b[0m Trial 40 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.00047577499411946984}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:43,436]\u001b[0m Trial 41 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0008694673421847314}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,453]\u001b[0m Trial 42 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00039837221663740796}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,476]\u001b[0m Trial 43 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009400733688924175}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,495]\u001b[0m Trial 44 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00016253368579700298}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,512]\u001b[0m Trial 45 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005706232768467147}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,529]\u001b[0m Trial 46 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 7.802551148276447e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,546]\u001b[0m Trial 47 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0004853140663646812}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,561]\u001b[0m Trial 48 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.00027845575751683424}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,572]\u001b[0m Trial 49 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 0.00011119960154467966}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,586]\u001b[0m Trial 50 finished with value: -0.23118279569892472 and parameters: {'var_smoothing': 2.6896664324289947e-06}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,612]\u001b[0m Trial 51 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0008844952749325135}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,637]\u001b[0m Trial 52 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0009888861646336637}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,654]\u001b[0m Trial 53 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005701171950713439}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,671]\u001b[0m Trial 54 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005273626352255442}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,695]\u001b[0m Trial 55 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00021054478152899973}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,721]\u001b[0m Trial 56 finished with value: -0.25268817204301075 and parameters: {'var_smoothing': 6.676010424546036e-05}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,741]\u001b[0m Trial 57 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 0.0001409412410724772}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,759]\u001b[0m Trial 58 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006267800268681971}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,783]\u001b[0m Trial 59 finished with value: -0.27419354838709675 and parameters: {'var_smoothing': 0.0003166931695666185}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,803]\u001b[0m Trial 60 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009775044194836704}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,828]\u001b[0m Trial 61 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009745478058873795}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,853]\u001b[0m Trial 62 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006510609580323502}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,875]\u001b[0m Trial 63 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.0002442521157889347}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,894]\u001b[0m Trial 64 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00038840838408706003}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,920]\u001b[0m Trial 65 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006126616776236368}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,938]\u001b[0m Trial 66 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.0001694652654978766}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,964]\u001b[0m Trial 67 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00042200970398191686}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:43,989]\u001b[0m Trial 68 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00020982515589584096}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,014]\u001b[0m Trial 69 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009713448110227469}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,036]\u001b[0m Trial 70 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006440629796230641}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,059]\u001b[0m Trial 71 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009437537991941931}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,078]\u001b[0m Trial 72 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00038373939526606914}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,094]\u001b[0m Trial 73 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.000700539737372272}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,111]\u001b[0m Trial 74 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.00025733206458560713}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,128]\u001b[0m Trial 75 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.0004210781408865052}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,153]\u001b[0m Trial 76 finished with value: -0.25806451612903225 and parameters: {'var_smoothing': 0.0001295796285199136}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,171]\u001b[0m Trial 77 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0007565046041984602}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,187]\u001b[0m Trial 78 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.0002870196573207149}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,228]\u001b[0m Trial 79 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00046597744426463367}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,246]\u001b[0m Trial 80 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006761417784548317}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,262]\u001b[0m Trial 81 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0009897747225792364}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,286]\u001b[0m Trial 82 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0009874782829307407}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:44,303]\u001b[0m Trial 83 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.000483324476125053}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,320]\u001b[0m Trial 84 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0007054534107071393}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,344]\u001b[0m Trial 85 finished with value: -0.27419354838709675 and parameters: {'var_smoothing': 0.0003178523414152558}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,363]\u001b[0m Trial 86 finished with value: -0.26344086021505375 and parameters: {'var_smoothing': 0.00017248160005280998}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,390]\u001b[0m Trial 87 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.00047563239293546534}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,411]\u001b[0m Trial 88 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0009815791581966216}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,434]\u001b[0m Trial 89 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0007249579150966481}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,457]\u001b[0m Trial 90 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.00023420199459098112}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,477]\u001b[0m Trial 91 finished with value: -0.3064516129032258 and parameters: {'var_smoothing': 0.0009550903022095369}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,499]\u001b[0m Trial 92 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005645162717270105}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,516]\u001b[0m Trial 93 finished with value: -0.2849462365591398 and parameters: {'var_smoothing': 0.00034375072061685154}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,536]\u001b[0m Trial 94 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0006832821554485168}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,553]\u001b[0m Trial 95 finished with value: -0.2903225806451613 and parameters: {'var_smoothing': 0.00043755101472946277}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,579]\u001b[0m Trial 96 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0007560321666529678}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,596]\u001b[0m Trial 97 finished with value: -0.26881720430107525 and parameters: {'var_smoothing': 0.0002780201160659115}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,620]\u001b[0m Trial 98 finished with value: -0.3010752688172043 and parameters: {'var_smoothing': 0.0009943462644057717}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:44,636]\u001b[0m Trial 99 finished with value: -0.2956989247311828 and parameters: {'var_smoothing': 0.0005579987487309892}. Best is trial 15 with value: -0.3064516129032258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'var_smoothing': 0.0009209123809787445}\n",
      "Best Accuracy: 0.3064516129032258\n",
      "Accuracy: 30.64516129032258\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    var_smoothing = trial.suggest_loguniform(\"var_smoothing\", 1e-9, 1e-3)\n",
    "\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the Naive Bayes model with the best hyperparameters\n",
    "best_model = GaussianNB(var_smoothing=study.best_params[\"var_smoothing\"])\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8245640",
   "metadata": {},
   "source": [
    "###### gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7de460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:16:44,683]\u001b[0m A new study created in memory with name: no-name-bd478b31-85b6-4425-a5a4-f1c4c7e1defd\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:51,594]\u001b[0m Trial 0 finished with value: -0.946236559139785 and parameters: {'n_estimators': 196, 'learning_rate': 0.058306396421710406, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:16:57,883]\u001b[0m Trial 1 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 333, 'learning_rate': 0.010090011428548191, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:00,424]\u001b[0m Trial 2 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 138, 'learning_rate': 0.020304017386952117, 'max_depth': 2, 'min_samples_split': 3}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:03,799]\u001b[0m Trial 3 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 178, 'learning_rate': 0.03655900277421078, 'max_depth': 2, 'min_samples_split': 8}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:21,408]\u001b[0m Trial 4 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 344, 'learning_rate': 0.01770663339730893, 'max_depth': 6, 'min_samples_split': 9}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:41,768]\u001b[0m Trial 5 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 400, 'learning_rate': 0.02132672387433161, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 0 with value: -0.946236559139785.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:49,487]\u001b[0m Trial 6 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 276, 'learning_rate': 0.09509191657232004, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:17:52,869]\u001b[0m Trial 7 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 199, 'learning_rate': 0.012903058767781729, 'max_depth': 2, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:00,798]\u001b[0m Trial 8 finished with value: -0.9139784946236559 and parameters: {'n_estimators': 174, 'learning_rate': 0.0333540073840475, 'max_depth': 6, 'min_samples_split': 10}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:24,464]\u001b[0m Trial 9 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 446, 'learning_rate': 0.037688398337800515, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:26,283]\u001b[0m Trial 10 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 60, 'learning_rate': 0.09994846283556887, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:34,400]\u001b[0m Trial 11 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 269, 'learning_rate': 0.09118514310561415, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:43,193]\u001b[0m Trial 12 finished with value: -0.946236559139785 and parameters: {'n_estimators': 275, 'learning_rate': 0.06078004391140295, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:52,708]\u001b[0m Trial 13 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 239, 'learning_rate': 0.06248303246880173, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:18:55,104]\u001b[0m Trial 14 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 98, 'learning_rate': 0.06529191687231277, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:08,864]\u001b[0m Trial 15 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 344, 'learning_rate': 0.049332085974536914, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:14,066]\u001b[0m Trial 16 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 227, 'learning_rate': 0.08238164309692035, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:28,441]\u001b[0m Trial 17 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 487, 'learning_rate': 0.07893332424133255, 'max_depth': 8, 'min_samples_split': 5}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:36,957]\u001b[0m Trial 18 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 307, 'learning_rate': 0.05108628622114758, 'max_depth': 3, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:51,204]\u001b[0m Trial 19 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 402, 'learning_rate': 0.0726458502301153, 'max_depth': 7, 'min_samples_split': 10}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:19:55,989]\u001b[0m Trial 20 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 133, 'learning_rate': 0.09954772485498135, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:20:06,219]\u001b[0m Trial 21 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 280, 'learning_rate': 0.05097766740725516, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:20:17,722]\u001b[0m Trial 22 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 256, 'learning_rate': 0.06901199290668754, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:20:23,616]\u001b[0m Trial 23 finished with value: -0.946236559139785 and parameters: {'n_estimators': 212, 'learning_rate': 0.053133362573583906, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:20:34,671]\u001b[0m Trial 24 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 307, 'learning_rate': 0.0802197582320767, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:20:51,759]\u001b[0m Trial 25 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 379, 'learning_rate': 0.042141737950116574, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:02,152]\u001b[0m Trial 26 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 284, 'learning_rate': 0.060217502871154766, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:05,947]\u001b[0m Trial 27 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 134, 'learning_rate': 0.08429492808054329, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:14,126]\u001b[0m Trial 28 finished with value: -0.9032258064516129 and parameters: {'n_estimators': 185, 'learning_rate': 0.07108831454415047, 'max_depth': 6, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:28,556]\u001b[0m Trial 29 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 321, 'learning_rate': 0.04340506838180835, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:37,277]\u001b[0m Trial 30 finished with value: -0.946236559139785 and parameters: {'n_estimators': 240, 'learning_rate': 0.05995416351611229, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:43,130]\u001b[0m Trial 31 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 211, 'learning_rate': 0.05803957110546787, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:21:47,286]\u001b[0m Trial 32 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 149, 'learning_rate': 0.0726500898129506, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:51,375]\u001b[0m Trial 33 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 213, 'learning_rate': 0.05443112498409148, 'max_depth': 2, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:21:55,923]\u001b[0m Trial 34 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 162, 'learning_rate': 0.04610372410037059, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:00,751]\u001b[0m Trial 35 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 253, 'learning_rate': 0.028572967830642445, 'max_depth': 2, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:10,526]\u001b[0m Trial 36 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 287, 'learning_rate': 0.05565332755787421, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:19,392]\u001b[0m Trial 37 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 198, 'learning_rate': 0.06784273715102487, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:26,475]\u001b[0m Trial 38 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 366, 'learning_rate': 0.08915544791102326, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:32,788]\u001b[0m Trial 39 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 226, 'learning_rate': 0.043239966619208696, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:36,698]\u001b[0m Trial 40 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 107, 'learning_rate': 0.03796688119322305, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:45,674]\u001b[0m Trial 41 finished with value: -0.9193548387096774 and parameters: {'n_estimators': 247, 'learning_rate': 0.0612791865577892, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:22:52,044]\u001b[0m Trial 42 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 174, 'learning_rate': 0.055994636966054646, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:01,753]\u001b[0m Trial 43 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 269, 'learning_rate': 0.062475881665205436, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:08,172]\u001b[0m Trial 44 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 231, 'learning_rate': 0.07575621210844288, 'max_depth': 3, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:21,485]\u001b[0m Trial 45 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 302, 'learning_rate': 0.06471418625172774, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:28,715]\u001b[0m Trial 46 finished with value: -0.946236559139785 and parameters: {'n_estimators': 200, 'learning_rate': 0.09052816619851231, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:45,564]\u001b[0m Trial 47 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 336, 'learning_rate': 0.05002894117029759, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:23:52,764]\u001b[0m Trial 48 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 261, 'learning_rate': 0.07533396166821357, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:01,277]\u001b[0m Trial 49 finished with value: -0.946236559139785 and parameters: {'n_estimators': 188, 'learning_rate': 0.05533041634185303, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:09,903]\u001b[0m Trial 50 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 238, 'learning_rate': 0.0673956649062666, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:17,826]\u001b[0m Trial 51 finished with value: -0.946236559139785 and parameters: {'n_estimators': 217, 'learning_rate': 0.09197391540884613, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:24,864]\u001b[0m Trial 52 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 195, 'learning_rate': 0.0831598055587587, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:30,762]\u001b[0m Trial 53 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 162, 'learning_rate': 0.07811240600558447, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:40,022]\u001b[0m Trial 54 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 208, 'learning_rate': 0.09823828611596125, 'max_depth': 5, 'min_samples_split': 10}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:48,041]\u001b[0m Trial 55 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 288, 'learning_rate': 0.09045230355174182, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:52,440]\u001b[0m Trial 56 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 120, 'learning_rate': 0.06844344839722084, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:54,734]\u001b[0m Trial 57 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 80, 'learning_rate': 0.061190683564145296, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:57,680]\u001b[0m Trial 58 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 65, 'learning_rate': 0.0684558165837185, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:24:59,646]\u001b[0m Trial 59 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 99, 'learning_rate': 0.05083234410137766, 'max_depth': 2, 'min_samples_split': 10}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:04,263]\u001b[0m Trial 60 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 126, 'learning_rate': 0.06507763879040561, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:08,498]\u001b[0m Trial 61 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 115, 'learning_rate': 0.07383683713510036, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:14,072]\u001b[0m Trial 62 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 154, 'learning_rate': 0.08300648359244556, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:21,877]\u001b[0m Trial 63 finished with value: -0.946236559139785 and parameters: {'n_estimators': 175, 'learning_rate': 0.05922887565570219, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:25:31,794]\u001b[0m Trial 64 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 320, 'learning_rate': 0.07814428888299738, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:38,683]\u001b[0m Trial 65 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 246, 'learning_rate': 0.04758556388388633, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:48,466]\u001b[0m Trial 66 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 272, 'learning_rate': 0.08714619686483802, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:25:58,215]\u001b[0m Trial 67 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 222, 'learning_rate': 0.07185003878130701, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:06,330]\u001b[0m Trial 68 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 294, 'learning_rate': 0.05253397129068183, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:18,206]\u001b[0m Trial 69 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 261, 'learning_rate': 0.09691721293732063, 'max_depth': 6, 'min_samples_split': 6}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:25,676]\u001b[0m Trial 70 finished with value: -0.946236559139785 and parameters: {'n_estimators': 204, 'learning_rate': 0.0816705413357276, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:33,870]\u001b[0m Trial 71 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 186, 'learning_rate': 0.05520440510164762, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:46,216]\u001b[0m Trial 72 finished with value: -0.9086021505376344 and parameters: {'n_estimators': 235, 'learning_rate': 0.057167043508036704, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 6 with value: -0.9516129032258065.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:26:52,645]\u001b[0m Trial 73 finished with value: -0.956989247311828 and parameters: {'n_estimators': 143, 'learning_rate': 0.06568851623231012, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:02,667]\u001b[0m Trial 74 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 171, 'learning_rate': 0.06995383999265649, 'max_depth': 7, 'min_samples_split': 7}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:06,920]\u001b[0m Trial 75 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 118, 'learning_rate': 0.06418833373377085, 'max_depth': 4, 'min_samples_split': 10}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:12,271]\u001b[0m Trial 76 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 145, 'learning_rate': 0.06183295082233185, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:18,373]\u001b[0m Trial 77 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 136, 'learning_rate': 0.08737467480399697, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:22,002]\u001b[0m Trial 78 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 81, 'learning_rate': 0.07662844912891278, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:28,283]\u001b[0m Trial 79 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 139, 'learning_rate': 0.058927833487758007, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:47,455]\u001b[0m Trial 80 finished with value: -0.946236559139785 and parameters: {'n_estimators': 437, 'learning_rate': 0.0674326444210685, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:53,265]\u001b[0m Trial 81 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 159, 'learning_rate': 0.09299932715051443, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:27:57,926]\u001b[0m Trial 82 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 127, 'learning_rate': 0.0870945895949647, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:10,077]\u001b[0m Trial 83 finished with value: -0.946236559139785 and parameters: {'n_estimators': 276, 'learning_rate': 0.0855839247504237, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:22,981]\u001b[0m Trial 84 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 249, 'learning_rate': 0.07861779956378746, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:25,431]\u001b[0m Trial 85 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 86, 'learning_rate': 0.07120752753705109, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:32,445]\u001b[0m Trial 86 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 190, 'learning_rate': 0.09536050596017653, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:42,069]\u001b[0m Trial 87 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 215, 'learning_rate': 0.05283024664394427, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:43,984]\u001b[0m Trial 88 finished with value: -0.9247311827956989 and parameters: {'n_estimators': 51, 'learning_rate': 0.07320627832232104, 'max_depth': 4, 'min_samples_split': 6}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:48,070]\u001b[0m Trial 89 finished with value: -0.946236559139785 and parameters: {'n_estimators': 146, 'learning_rate': 0.092057697361115, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:28:59,593]\u001b[0m Trial 90 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 321, 'learning_rate': 0.08388372357006409, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:29:12,136]\u001b[0m Trial 91 finished with value: -0.946236559139785 and parameters: {'n_estimators': 345, 'learning_rate': 0.08163191470815553, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:29:24,403]\u001b[0m Trial 92 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 353, 'learning_rate': 0.0873193935357571, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:29:35,086]\u001b[0m Trial 93 finished with value: -0.9516129032258065 and parameters: {'n_estimators': 300, 'learning_rate': 0.0670609189430213, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:29:46,151]\u001b[0m Trial 94 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 322, 'learning_rate': 0.06425669242452225, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:29:53,623]\u001b[0m Trial 95 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 297, 'learning_rate': 0.058475703138314176, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:30:05,704]\u001b[0m Trial 96 finished with value: -0.9408602150537635 and parameters: {'n_estimators': 319, 'learning_rate': 0.06621963929689981, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:30:11,362]\u001b[0m Trial 97 finished with value: -0.9354838709677419 and parameters: {'n_estimators': 305, 'learning_rate': 0.0752924780543345, 'max_depth': 2, 'min_samples_split': 9}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:30:20,126]\u001b[0m Trial 98 finished with value: -0.9301075268817204 and parameters: {'n_estimators': 268, 'learning_rate': 0.061733273788508396, 'max_depth': 4, 'min_samples_split': 10}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:30:34,961]\u001b[0m Trial 99 finished with value: -0.8655913978494624 and parameters: {'n_estimators': 332, 'learning_rate': 0.06900705826498994, 'max_depth': 7, 'min_samples_split': 8}. Best is trial 73 with value: -0.956989247311828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 143, 'learning_rate': 0.06568851623231012, 'max_depth': 5, 'min_samples_split': 8}\n",
      "Best Accuracy: 0.956989247311828\n",
      "Accuracy: 95.6989247311828\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the gradient boosting model with the best hyperparameters\n",
    "best_model = GradientBoostingClassifier(\n",
    "    n_estimators=study.best_params[\"n_estimators\"],\n",
    "    learning_rate=study.best_params[\"learning_rate\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff2679ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:30:40,567]\u001b[0m A new study created in memory with name: no-name-62a54a0a-a16a-40a4-ba61-821e14d18306\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:30:45,752]\u001b[0m Trial 0 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 284, 'learning_rate': 0.05008164712024572, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:30:57,498]\u001b[0m Trial 1 finished with value: -0.5591397849462365 and parameters: {'n_estimators': 439, 'learning_rate': 0.08044612866690498, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:31:12,184]\u001b[0m Trial 2 finished with value: -0.6021505376344086 and parameters: {'n_estimators': 471, 'learning_rate': 0.06858776810218326, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:31:22,219]\u001b[0m Trial 3 finished with value: -0.5913978494623656 and parameters: {'n_estimators': 179, 'learning_rate': 0.09117179224856405, 'max_depth': 8, 'min_samples_split': 10}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:31:37,395]\u001b[0m Trial 4 finished with value: -0.8225806451612904 and parameters: {'n_estimators': 439, 'learning_rate': 0.02741532967848293, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:00,161]\u001b[0m Trial 5 finished with value: -0.6021505376344086 and parameters: {'n_estimators': 392, 'learning_rate': 0.01005398479277268, 'max_depth': 8, 'min_samples_split': 10}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:05,819]\u001b[0m Trial 6 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 332, 'learning_rate': 0.021816925073171442, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:07,933]\u001b[0m Trial 7 finished with value: -0.7473118279569892 and parameters: {'n_estimators': 60, 'learning_rate': 0.08325860394227676, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:30,382]\u001b[0m Trial 8 finished with value: -0.7849462365591398 and parameters: {'n_estimators': 470, 'learning_rate': 0.021768475559150614, 'max_depth': 6, 'min_samples_split': 10}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:35,070]\u001b[0m Trial 9 finished with value: -0.6774193548387096 and parameters: {'n_estimators': 93, 'learning_rate': 0.02616206927336347, 'max_depth': 7, 'min_samples_split': 5}. Best is trial 0 with value: -0.8817204301075269.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:38,786]\u001b[0m Trial 10 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 239, 'learning_rate': 0.050299834036727255, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:42,105]\u001b[0m Trial 11 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 221, 'learning_rate': 0.04712870020620201, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:47,885]\u001b[0m Trial 12 finished with value: -0.8548387096774194 and parameters: {'n_estimators': 286, 'learning_rate': 0.047091563652332594, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:52,067]\u001b[0m Trial 13 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 186, 'learning_rate': 0.04850584612890968, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:32:57,401]\u001b[0m Trial 14 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 317, 'learning_rate': 0.058268309127076416, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:04,429]\u001b[0m Trial 15 finished with value: -0.8225806451612904 and parameters: {'n_estimators': 239, 'learning_rate': 0.03825405528838081, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:08,525]\u001b[0m Trial 16 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 145, 'learning_rate': 0.06175171499443662, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:24,472]\u001b[0m Trial 17 finished with value: -0.8010752688172043 and parameters: {'n_estimators': 355, 'learning_rate': 0.03537184898335173, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:35,305]\u001b[0m Trial 18 finished with value: -0.8494623655913979 and parameters: {'n_estimators': 254, 'learning_rate': 0.09775851895969045, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:43,102]\u001b[0m Trial 19 finished with value: -0.8333333333333334 and parameters: {'n_estimators': 287, 'learning_rate': 0.06806093219893529, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:45,253]\u001b[0m Trial 20 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 131, 'learning_rate': 0.054092932227348706, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 10 with value: -0.8924731182795699.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:47,282]\u001b[0m Trial 21 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 106, 'learning_rate': 0.053033662597125254, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:49,431]\u001b[0m Trial 22 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 121, 'learning_rate': 0.039540046018163, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:51,272]\u001b[0m Trial 23 finished with value: -0.8602150537634409 and parameters: {'n_estimators': 64, 'learning_rate': 0.0567511155554084, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:33:54,136]\u001b[0m Trial 24 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 149, 'learning_rate': 0.071300328701071, 'max_depth': 2, 'min_samples_split': 3}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:01,647]\u001b[0m Trial 25 finished with value: -0.8172043010752689 and parameters: {'n_estimators': 203, 'learning_rate': 0.055675962292193765, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:04,808]\u001b[0m Trial 26 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 112, 'learning_rate': 0.04213910773511907, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:08,177]\u001b[0m Trial 27 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 174, 'learning_rate': 0.07677799304223766, 'max_depth': 2, 'min_samples_split': 8}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:10,948]\u001b[0m Trial 28 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 97, 'learning_rate': 0.03237511886775102, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:13,800]\u001b[0m Trial 29 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 147, 'learning_rate': 0.05405216050642541, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:15,754]\u001b[0m Trial 30 finished with value: -0.7956989247311828 and parameters: {'n_estimators': 54, 'learning_rate': 0.06479524638922086, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:18,686]\u001b[0m Trial 31 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 149, 'learning_rate': 0.05350384587600495, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:34:21,233]\u001b[0m Trial 32 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 129, 'learning_rate': 0.04436839753253285, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:22,756]\u001b[0m Trial 33 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 81, 'learning_rate': 0.05091399502856877, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:28,572]\u001b[0m Trial 34 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 215, 'learning_rate': 0.08324144353399035, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:31,752]\u001b[0m Trial 35 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 169, 'learning_rate': 0.07141944682139696, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:43,950]\u001b[0m Trial 36 finished with value: -0.8279569892473119 and parameters: {'n_estimators': 239, 'learning_rate': 0.059483601096423026, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:47,831]\u001b[0m Trial 37 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 200, 'learning_rate': 0.05036717125456597, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:52,285]\u001b[0m Trial 38 finished with value: -0.8494623655913979 and parameters: {'n_estimators': 159, 'learning_rate': 0.06325764524924704, 'max_depth': 3, 'min_samples_split': 8}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:56,743]\u001b[0m Trial 39 finished with value: -0.8333333333333334 and parameters: {'n_estimators': 123, 'learning_rate': 0.04210916915685975, 'max_depth': 4, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:34:58,364]\u001b[0m Trial 40 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 82, 'learning_rate': 0.07366236636832388, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:00,785]\u001b[0m Trial 41 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 125, 'learning_rate': 0.04246450493510762, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:02,531]\u001b[0m Trial 42 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 94, 'learning_rate': 0.05208482114318413, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:06,121]\u001b[0m Trial 43 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 132, 'learning_rate': 0.044152465142713836, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:08,180]\u001b[0m Trial 44 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 109, 'learning_rate': 0.03753884407990768, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:14,876]\u001b[0m Trial 45 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 393, 'learning_rate': 0.04765740540749167, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:26,563]\u001b[0m Trial 46 finished with value: -0.6720430107526881 and parameters: {'n_estimators': 182, 'learning_rate': 0.05626712288045523, 'max_depth': 8, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:33,657]\u001b[0m Trial 47 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 264, 'learning_rate': 0.06293348067212108, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:37,376]\u001b[0m Trial 48 finished with value: -0.8172043010752689 and parameters: {'n_estimators': 73, 'learning_rate': 0.04644281207932544, 'max_depth': 6, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:45,366]\u001b[0m Trial 49 finished with value: -0.8279569892473119 and parameters: {'n_estimators': 141, 'learning_rate': 0.05227737131173863, 'max_depth': 7, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:49,022]\u001b[0m Trial 50 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 190, 'learning_rate': 0.08438225774085871, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:51,004]\u001b[0m Trial 51 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 104, 'learning_rate': 0.0437777033443953, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:53,537]\u001b[0m Trial 52 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 131, 'learning_rate': 0.040071112418041094, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:35:56,760]\u001b[0m Trial 53 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 167, 'learning_rate': 0.04561345713791951, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:05,132]\u001b[0m Trial 54 finished with value: -0.8387096774193549 and parameters: {'n_estimators': 302, 'learning_rate': 0.03562656289522991, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:10,491]\u001b[0m Trial 55 finished with value: -0.8387096774193549 and parameters: {'n_estimators': 220, 'learning_rate': 0.05695598104447265, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:19,169]\u001b[0m Trial 56 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 487, 'learning_rate': 0.04819012789579802, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:21,000]\u001b[0m Trial 57 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 118, 'learning_rate': 0.06654848060664068, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:29,151]\u001b[0m Trial 58 finished with value: -0.8118279569892473 and parameters: {'n_estimators': 345, 'learning_rate': 0.042091197553288946, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:32,106]\u001b[0m Trial 59 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 155, 'learning_rate': 0.05894120712313249, 'max_depth': 2, 'min_samples_split': 3}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:37,805]\u001b[0m Trial 60 finished with value: -0.8010752688172043 and parameters: {'n_estimators': 136, 'learning_rate': 0.053270748523979304, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:40,753]\u001b[0m Trial 61 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 155, 'learning_rate': 0.052633673431638266, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:42,439]\u001b[0m Trial 62 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 86, 'learning_rate': 0.049801951952128054, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:43,500]\u001b[0m Trial 63 finished with value: -0.8602150537634409 and parameters: {'n_estimators': 51, 'learning_rate': 0.060845386209822765, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:36:45,876]\u001b[0m Trial 64 finished with value: -0.8655913978494624 and parameters: {'n_estimators': 107, 'learning_rate': 0.047059690782964486, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:49,436]\u001b[0m Trial 65 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 196, 'learning_rate': 0.05474242859447254, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:53,894]\u001b[0m Trial 66 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 235, 'learning_rate': 0.06716234597067405, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:36:56,879]\u001b[0m Trial 67 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 154, 'learning_rate': 0.04366278530992156, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:01,565]\u001b[0m Trial 68 finished with value: -0.8494623655913979 and parameters: {'n_estimators': 171, 'learning_rate': 0.04064302021485668, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:03,942]\u001b[0m Trial 69 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 123, 'learning_rate': 0.037084876044499636, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:09,567]\u001b[0m Trial 70 finished with value: -0.8548387096774194 and parameters: {'n_estimators': 207, 'learning_rate': 0.038061051377082676, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:11,819]\u001b[0m Trial 71 finished with value: -0.8602150537634409 and parameters: {'n_estimators': 123, 'learning_rate': 0.049741678415622846, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:13,059]\u001b[0m Trial 72 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 73, 'learning_rate': 0.03370197603360878, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:14,611]\u001b[0m Trial 73 finished with value: -0.8655913978494624 and parameters: {'n_estimators': 96, 'learning_rate': 0.030432970544898102, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:16,718]\u001b[0m Trial 74 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 141, 'learning_rate': 0.04552526506300507, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:18,629]\u001b[0m Trial 75 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 113, 'learning_rate': 0.05286500256630864, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:21,077]\u001b[0m Trial 76 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 129, 'learning_rate': 0.05904477144937163, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:22,813]\u001b[0m Trial 77 finished with value: -0.8440860215053764 and parameters: {'n_estimators': 65, 'learning_rate': 0.03966051198998787, 'max_depth': 3, 'min_samples_split': 2}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:29,160]\u001b[0m Trial 78 finished with value: -0.8118279569892473 and parameters: {'n_estimators': 180, 'learning_rate': 0.04841756308760363, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:36,359]\u001b[0m Trial 79 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 384, 'learning_rate': 0.05556142552850092, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:38,341]\u001b[0m Trial 80 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 101, 'learning_rate': 0.042661292578776946, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:41,434]\u001b[0m Trial 81 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 162, 'learning_rate': 0.04327107457844688, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:44,167]\u001b[0m Trial 82 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 141, 'learning_rate': 0.04478102532917587, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:46,938]\u001b[0m Trial 83 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 153, 'learning_rate': 0.051115545393841694, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:49,591]\u001b[0m Trial 84 finished with value: -0.8763440860215054 and parameters: {'n_estimators': 151, 'learning_rate': 0.0365556418836521, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:53,063]\u001b[0m Trial 85 finished with value: -0.8548387096774194 and parameters: {'n_estimators': 123, 'learning_rate': 0.040481298581596915, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:56,118]\u001b[0m Trial 86 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 164, 'learning_rate': 0.06331458020843594, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:37:57,652]\u001b[0m Trial 87 finished with value: -0.8548387096774194 and parameters: {'n_estimators': 84, 'learning_rate': 0.04851754271908734, 'max_depth': 3, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:02,226]\u001b[0m Trial 88 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 253, 'learning_rate': 0.04519194248033716, 'max_depth': 2, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:05,731]\u001b[0m Trial 89 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 184, 'learning_rate': 0.054228263486924354, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:07,930]\u001b[0m Trial 90 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 115, 'learning_rate': 0.058400989290396145, 'max_depth': 2, 'min_samples_split': 3}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:10,739]\u001b[0m Trial 91 finished with value: -0.8924731182795699 and parameters: {'n_estimators': 148, 'learning_rate': 0.04954798922942541, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:13,718]\u001b[0m Trial 92 finished with value: -0.8870967741935484 and parameters: {'n_estimators': 155, 'learning_rate': 0.051206001937841444, 'max_depth': 2, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:20,425]\u001b[0m Trial 93 finished with value: -0.8333333333333334 and parameters: {'n_estimators': 131, 'learning_rate': 0.038612117697503216, 'max_depth': 6, 'min_samples_split': 6}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:23,708]\u001b[0m Trial 94 finished with value: -0.8978494623655914 and parameters: {'n_estimators': 172, 'learning_rate': 0.051716038435170704, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:26,739]\u001b[0m Trial 95 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 171, 'learning_rate': 0.046276046360893636, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-30 09:38:29,438]\u001b[0m Trial 96 finished with value: -0.8817204301075269 and parameters: {'n_estimators': 138, 'learning_rate': 0.06129300354828444, 'max_depth': 2, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:33,174]\u001b[0m Trial 97 finished with value: -0.8709677419354839 and parameters: {'n_estimators': 193, 'learning_rate': 0.055857508402025906, 'max_depth': 2, 'min_samples_split': 4}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:38,529]\u001b[0m Trial 98 finished with value: -0.6559139784946236 and parameters: {'n_estimators': 91, 'learning_rate': 0.0418552547191322, 'max_depth': 7, 'min_samples_split': 5}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n",
      "\u001b[32m[I 2023-05-30 09:38:46,127]\u001b[0m Trial 99 finished with value: -0.8333333333333334 and parameters: {'n_estimators': 280, 'learning_rate': 0.0526725510591582, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 21 with value: -0.8978494623655914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 106, 'learning_rate': 0.053033662597125254, 'max_depth': 2, 'min_samples_split': 5}\n",
      "Best Accuracy: 0.8978494623655914\n",
      "Accuracy: 89.78494623655914\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return -accuracy_score(y_test, y_pred)  # maximize accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and the best accuracy achieved\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", -study.best_value)\n",
    "\n",
    "# Train the gradient boosting model with the best hyperparameters\n",
    "best_model = GradientBoostingClassifier(\n",
    "    n_estimators=study.best_params[\"n_estimators\"],\n",
    "    learning_rate=study.best_params[\"learning_rate\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_samples_split=study.best_params[\"min_samples_split\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "219fea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ca638",
   "metadata": {},
   "source": [
    "### using randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b98a8",
   "metadata": {},
   "source": [
    "###### gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09305582",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8228d830",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12732\\1776440536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Perform Randomized Search CV to find the best hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Get the best model and its parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1769\u001b[0m             ParameterSampler(\n\u001b[0;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     )\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    377\u001b[0m             )\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting classifier\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search CV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting classifier\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search CV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the best parameters found during hyperparameter tuning\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c1b66",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc844ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 0.05, 'max_depth': 3, 'max_features': None, 'n_estimators': 73, 'subsample': 0.5}\n",
      "Accuracy on Test Set: 92.47%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"n_estimators\": sp_randint(10, 100),\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"max_depth\": sp_randint(1, 10),\n",
    "    \"subsample\": [0.5, 0.7, 1.0],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af948dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 0.05, 'max_depth': 3, 'max_features': None, 'n_estimators': 73, 'subsample': 0.5}\n",
      "Accuracy on Test Set: 83.87%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"n_estimators\": sp_randint(10, 100),\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"max_depth\": sp_randint(1, 10),\n",
    "    \"subsample\": [0.5, 0.7, 1.0],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbb643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d3497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ae2056",
   "metadata": {},
   "source": [
    "###### decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d772403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 33, 'min_samples_leaf': 10, 'min_samples_split': 7}\n",
      "Accuracy on Test Set: 87.10%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": sp_randint(1, 10),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"max_features\": sp_randint(1, X.shape[1] + 1),\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a52a4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 24, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Accuracy on Test Set: 77.42%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": sp_randint(1, 10),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"max_features\": sp_randint(1, X.shape[1] + 1),\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e00d23",
   "metadata": {},
   "source": [
    "###### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c7d7c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 8, 'max_features': 29, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 80}\n",
      "Accuracy on Test Set: 94.62%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"n_estimators\": sp_randint(10, 100),\n",
    "    \"max_depth\": [None] + list(range(1, 10)),\n",
    "    \"max_features\": sp_randint(1, X.shape[1] + 1),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d3f77c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 8, 'max_features': 29, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 80}\n",
      "Accuracy on Test Set: 88.17%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"n_estimators\": sp_randint(10, 100),\n",
    "    \"max_depth\": [None] + list(range(1, 10)),\n",
    "    \"max_features\": sp_randint(1, X.shape[1] + 1),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce8386d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1705372",
   "metadata": {},
   "source": [
    "###### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e4fae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 2.473544037332349, 'penalty': 'l2'}\n",
      "Accuracy on Test Set: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": uniform(loc=0, scale=4)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb8db7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 0.23233444867279784, 'penalty': 'l2'}\n",
      "Accuracy on Test Set: 89.25%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": uniform(loc=0, scale=4)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7287e188",
   "metadata": {},
   "source": [
    "###### using support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90a49cfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12732\\1201541107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Perform RandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Print the best hyperparameters found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1769\u001b[0m             ParameterSampler(\n\u001b[0;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     )\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"C\": uniform(loc=0, scale=10),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_dist = {\n",
    "    \"C\": uniform(loc=0, scale=10),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1d7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4950b5e",
   "metadata": {},
   "source": [
    "### using bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b531231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     ------------------------------------- 100.3/100.3 kB 52.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from scikit-optimize) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from scikit-optimize) (1.9.1)\n",
      "Requirement already satisfied: PyYAML in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\set ups\\anaconda\\ecow\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03e5413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea78d51",
   "metadata": {},
   "source": [
    "###### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b81bb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('C', 9.961646744450592), ('fit_intercept', False), ('penalty', 'l1'), ('solver', 'liblinear')])\n",
      "Accuracy on Test Set: 86.56%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"C\": (0.01, 10.0, \"log-uniform\"),\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"solver\": [\"liblinear\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a0e7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('C', 0.010253943538922507), ('fit_intercept', True), ('penalty', 'l2'), ('solver', 'liblinear')])\n",
      "Accuracy on Test Set: 90.86%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"C\": (0.01, 10.0, \"log-uniform\"),\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"solver\": [\"liblinear\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09338a",
   "metadata": {},
   "source": [
    "###### decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "132347c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('criterion', 'gini'), ('max_depth', 7), ('max_features', 50), ('min_samples_leaf', 5), ('min_samples_split', 5)])\n",
      "Accuracy on Test Set: 85.48%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": (1, 10),\n",
    "    \"min_samples_split\": (2, 11),\n",
    "    \"min_samples_leaf\": (1, 11),\n",
    "    \"max_features\": (1, X.shape[1] + 1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c6ade34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('criterion', 'gini'), ('max_depth', 8), ('max_features', 57), ('min_samples_leaf', 1), ('min_samples_split', 11)])\n",
      "Accuracy on Test Set: 62.37%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": (1, 10),\n",
    "    \"min_samples_split\": (2, 11),\n",
    "    \"min_samples_leaf\": (1, 11),\n",
    "    \"max_features\": (1, X.shape[1] + 1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79984ec",
   "metadata": {},
   "source": [
    "###### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd0dbe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('max_depth', 6), ('max_features', 57), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 100)])\n",
      "Accuracy on Test Set: 94.62%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"n_estimators\": (10, 100),\n",
    "    \"max_depth\": (1, 10),\n",
    "    \"min_samples_split\": (2, 11),\n",
    "    \"min_samples_leaf\": (1, 11),\n",
    "    \"max_features\": (1, X.shape[1] + 1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17e3df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('max_depth', 5), ('max_features', 52), ('min_samples_leaf', 2), ('min_samples_split', 6), ('n_estimators', 27)])\n",
      "Accuracy on Test Set: 79.57%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"n_estimators\": (10, 100),\n",
    "    \"max_depth\": (1, 10),\n",
    "    \"min_samples_split\": (2, 11),\n",
    "    \"min_samples_leaf\": (1, 11),\n",
    "    \"max_features\": (1, X.shape[1] + 1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37cc1a7",
   "metadata": {},
   "source": [
    "###### support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abbbf7c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6372\\103109817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mbayes_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Print the best hyperparameters found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                 optim_result = self._step(\n\u001b[0m\u001b[0;32m    513\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                     \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[0mall_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         \u001b[1;31m# Feed the point and objective value back into optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;31m# Optimizer minimizes objective, hence provide negative score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     )\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Set Ups\\Anaconda\\ecow\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"C\": (0.01, 10.0, \"log-uniform\"),\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": (0.01, 10.0, \"log-uniform\")\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26aa32d",
   "metadata": {},
   "source": [
    "###### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca18636f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6372\\1176325628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Perform cross-validation to evaluate the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Print the cross-validation scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Perform cross-validation to evaluate the classifier\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Average Accuracy: {:.2f}%\".format(scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151ed5f",
   "metadata": {},
   "source": [
    "###### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "156e1412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('n_neighbors', 10), ('p', 2), ('weights', 'distance')])\n",
      "Accuracy on Test Set: 81.18%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"n_neighbors\": (1, 10),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d085a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  OrderedDict([('n_neighbors', 2), ('p', 1), ('weights', 'distance')])\n",
      "Accuracy on Test Set: 89.25%\n"
     ]
    }
   ],
   "source": [
    "# Define the classifier\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    \"n_neighbors\": (1, 10),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization for hyperparameter tuning\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_space,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters: \", bayes_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b991a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea7c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebd1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334aca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed861f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfd0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1335ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f092a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bdc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702097b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
