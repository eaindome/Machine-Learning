{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46c5e77-c369-4468-88e9-afb8479d7c69",
   "metadata": {},
   "source": [
    "# Regression of Used Car Prices\n",
    "\n",
    "### Overview\n",
    "Welcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting an approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n",
    "\n",
    "### Your Goal: \n",
    "The goal of this competition is to predict the price of used cars based on various attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba62b179-f3c4-4c51-9e08-55b1ce097ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b96b0c-df72-4231-9013-c942cd6bb6b1",
   "metadata": {},
   "source": [
    "## Data\n",
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6e5bcf-55c9-4ccb-a21f-0547f89ab75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (188533, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MINI</td>\n",
       "      <td>Cooper S Base</td>\n",
       "      <td>2007</td>\n",
       "      <td>213000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>LS V8</td>\n",
       "      <td>2002</td>\n",
       "      <td>143250</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Beige</td>\n",
       "      <td>At least 1 accident or damage reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Silverado 2500 LT</td>\n",
       "      <td>2002</td>\n",
       "      <td>136731</td>\n",
       "      <td>E85 Flex Fuel</td>\n",
       "      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>G90 5.0 Ultimate</td>\n",
       "      <td>2017</td>\n",
       "      <td>19500</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>Transmission w/Dual Shift Mode</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>Metris Base</td>\n",
       "      <td>2021</td>\n",
       "      <td>7388</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>7-Speed A/T</td>\n",
       "      <td>Black</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>97500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          brand              model  model_year  milage      fuel_type  \\\n",
       "0   0           MINI      Cooper S Base        2007  213000       Gasoline   \n",
       "1   1        Lincoln              LS V8        2002  143250       Gasoline   \n",
       "2   2      Chevrolet  Silverado 2500 LT        2002  136731  E85 Flex Fuel   \n",
       "3   3        Genesis   G90 5.0 Ultimate        2017   19500       Gasoline   \n",
       "4   4  Mercedes-Benz        Metris Base        2021    7388       Gasoline   \n",
       "\n",
       "                                              engine  \\\n",
       "0       172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n",
       "1       252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n",
       "2  320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n",
       "3       420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n",
       "4       208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n",
       "\n",
       "                     transmission ext_col int_col  \\\n",
       "0                             A/T  Yellow    Gray   \n",
       "1                             A/T  Silver   Beige   \n",
       "2                             A/T    Blue    Gray   \n",
       "3  Transmission w/Dual Shift Mode   Black   Black   \n",
       "4                     7-Speed A/T   Black   Beige   \n",
       "\n",
       "                                 accident clean_title  price  \n",
       "0                           None reported         Yes   4200  \n",
       "1  At least 1 accident or damage reported         Yes   4999  \n",
       "2                           None reported         Yes  13900  \n",
       "3                           None reported         Yes  45000  \n",
       "4                           None reported         Yes  97500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "train = pd.read_csv('train.csv')\n",
    "print(f\"Shape: {train.shape}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec61615b-e8fb-47b8-8f1e-ad5b11f768ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine',\n",
       "       'transmission', 'ext_col', 'int_col', 'accident', 'clean_title',\n",
       "       'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the availabe columns\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4c8f1b-b80c-4722-abd5-8a4829f2dfb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (125690, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover LR2 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>98000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188534</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover Defender SE</td>\n",
       "      <td>2020</td>\n",
       "      <td>9142</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188535</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Expedition Limited</td>\n",
       "      <td>2022</td>\n",
       "      <td>28121</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n",
       "      <td>10-Speed Automatic</td>\n",
       "      <td>White</td>\n",
       "      <td>Ebony</td>\n",
       "      <td>None reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188536</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A6 2.0T Sport</td>\n",
       "      <td>2016</td>\n",
       "      <td>61258</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>2.0 Liter TFSI</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Silician Yellow</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188537</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A6 2.0T Premium Plus</td>\n",
       "      <td>2018</td>\n",
       "      <td>59000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id brand                 model  model_year  milage fuel_type  \\\n",
       "0  188533  Land        Rover LR2 Base        2015   98000  Gasoline   \n",
       "1  188534  Land     Rover Defender SE        2020    9142    Hybrid   \n",
       "2  188535  Ford    Expedition Limited        2022   28121  Gasoline   \n",
       "3  188536  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n",
       "4  188537  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n",
       "\n",
       "                                              engine        transmission  \\\n",
       "0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n",
       "1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n",
       "2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n",
       "3                                     2.0 Liter TFSI           Automatic   \n",
       "4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n",
       "\n",
       "           ext_col int_col       accident clean_title  \n",
       "0            White   Beige  None reported         Yes  \n",
       "1           Silver   Black  None reported         Yes  \n",
       "2            White   Ebony  None reported         NaN  \n",
       "3  Silician Yellow   Black  None reported         NaN  \n",
       "4             Gray   Black  None reported         Yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "test = pd.read_csv('test.csv')\n",
    "print(f\"Shape: {test.shape}\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6177f4b-4e0b-45d8-ac15-e722b75014a2",
   "metadata": {},
   "source": [
    "### About data\n",
    "#### 1. train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0cabf5-e6b9-4c5d-8491-9ccae91a3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188533 entries, 0 to 188532\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            188533 non-null  int64 \n",
      " 1   brand         188533 non-null  object\n",
      " 2   model         188533 non-null  object\n",
      " 3   model_year    188533 non-null  int64 \n",
      " 4   milage        188533 non-null  int64 \n",
      " 5   fuel_type     183450 non-null  object\n",
      " 6   engine        188533 non-null  object\n",
      " 7   transmission  188533 non-null  object\n",
      " 8   ext_col       188533 non-null  object\n",
      " 9   int_col       188533 non-null  object\n",
      " 10  accident      186081 non-null  object\n",
      " 11  clean_title   167114 non-null  object\n",
      " 12  price         188533 non-null  int64 \n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 18.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# train information\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd60ee18-a9e9-4a85-bbbc-6422f29a7b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>188533.000000</td>\n",
       "      <td>188533.000000</td>\n",
       "      <td>188533.000000</td>\n",
       "      <td>1.885330e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94266.000000</td>\n",
       "      <td>2015.829998</td>\n",
       "      <td>65705.295174</td>\n",
       "      <td>4.387802e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54424.933488</td>\n",
       "      <td>5.660967</td>\n",
       "      <td>49798.158076</td>\n",
       "      <td>7.881952e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47133.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>24115.000000</td>\n",
       "      <td>1.700000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>94266.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>57785.000000</td>\n",
       "      <td>3.082500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>141399.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>95400.000000</td>\n",
       "      <td>4.990000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>188532.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>405000.000000</td>\n",
       "      <td>2.954083e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     model_year         milage         price\n",
       "count  188533.000000  188533.000000  188533.000000  1.885330e+05\n",
       "mean    94266.000000    2015.829998   65705.295174  4.387802e+04\n",
       "std     54424.933488       5.660967   49798.158076  7.881952e+04\n",
       "min         0.000000    1974.000000     100.000000  2.000000e+03\n",
       "25%     47133.000000    2013.000000   24115.000000  1.700000e+04\n",
       "50%     94266.000000    2017.000000   57785.000000  3.082500e+04\n",
       "75%    141399.000000    2020.000000   95400.000000  4.990000e+04\n",
       "max    188532.000000    2024.000000  405000.000000  2.954083e+06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical information\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669931d-37b0-4ee1-a2c8-1d6a46807ba3",
   "metadata": {},
   "source": [
    "#### 2. test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "291a9984-b078-449a-b0da-fb55d8d54b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125690 entries, 0 to 125689\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            125690 non-null  int64 \n",
      " 1   brand         125690 non-null  object\n",
      " 2   model         125690 non-null  object\n",
      " 3   model_year    125690 non-null  int64 \n",
      " 4   milage        125690 non-null  int64 \n",
      " 5   fuel_type     122307 non-null  object\n",
      " 6   engine        125690 non-null  object\n",
      " 7   transmission  125690 non-null  object\n",
      " 8   ext_col       125690 non-null  object\n",
      " 9   int_col       125690 non-null  object\n",
      " 10  accident      124058 non-null  object\n",
      " 11  clean_title   111451 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# test information\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c550b3eb-4f23-4b38-af95-246180037540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125690.000000</td>\n",
       "      <td>125690.000000</td>\n",
       "      <td>125690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>251377.500000</td>\n",
       "      <td>2015.797526</td>\n",
       "      <td>66042.581510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36283.722005</td>\n",
       "      <td>5.673797</td>\n",
       "      <td>50223.858435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>188533.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>219955.250000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>24500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>251377.500000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>57500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>282799.750000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>95798.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>314222.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>405000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     model_year         milage\n",
       "count  125690.000000  125690.000000  125690.000000\n",
       "mean   251377.500000    2015.797526   66042.581510\n",
       "std     36283.722005       5.673797   50223.858435\n",
       "min    188533.000000    1974.000000     100.000000\n",
       "25%    219955.250000    2013.000000   24500.000000\n",
       "50%    251377.500000    2017.000000   57500.000000\n",
       "75%    282799.750000    2020.000000   95798.000000\n",
       "max    314222.000000    2024.000000  405000.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical information\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5456305-df61-4ade-93bb-f7328d0a18a9",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b7c9f6-6808-450e-bdd8-b90a8c290328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle missing values\n",
    "def missing_values(df):\n",
    "    # filling in missing values for numerical columns\n",
    "    for column in df.select_dtypes(include=['number']).columns:\n",
    "        if df[column].isnull().any():\n",
    "            median_value = df[column].median()\n",
    "            df[column].fillna(median_value, inplace=True)\n",
    "\n",
    "    # filling in missing values for categorical columns\n",
    "    for column in df.select_dtypes(include=['object']).columns:\n",
    "        if df[column].isnull().any():\n",
    "            mode_value = df[column].mode()[0]\n",
    "            df[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98dc96c-63b1-43b5-a36c-1d00e9f89915",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10573b4a-6e52-435e-94b9-91242c2d06d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "brand               0\n",
       "model               0\n",
       "model_year          0\n",
       "milage              0\n",
       "fuel_type        5083\n",
       "engine              0\n",
       "transmission        0\n",
       "ext_col             0\n",
       "int_col             0\n",
       "accident         2452\n",
       "clean_title     21419\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf3c239a-04f2-4c51-9ac8-1dad98c8a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values\n",
    "train = missing_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b6dee3-0bd3-4d87-bcc8-194299f108c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "brand           0\n",
       "model           0\n",
       "model_year      0\n",
       "milage          0\n",
       "fuel_type       0\n",
       "engine          0\n",
       "transmission    0\n",
       "ext_col         0\n",
       "int_col         0\n",
       "accident        0\n",
       "clean_title     0\n",
       "price           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-check for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea246d7f-8cb7-4a95-b5b7-8532a27a851f",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f32c48af-3fed-4842-847d-a962d4dd8966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "brand               0\n",
       "model               0\n",
       "model_year          0\n",
       "milage              0\n",
       "fuel_type        3383\n",
       "engine              0\n",
       "transmission        0\n",
       "ext_col             0\n",
       "int_col             0\n",
       "accident         1632\n",
       "clean_title     14239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values in test data\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f943cca5-ee74-454c-a9c5-5638a3553fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "test = missing_values(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13c98710-fe09-4e87-8aaa-a99fc2643494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "brand           0\n",
       "model           0\n",
       "model_year      0\n",
       "milage          0\n",
       "fuel_type       0\n",
       "engine          0\n",
       "transmission    0\n",
       "ext_col         0\n",
       "int_col         0\n",
       "accident        0\n",
       "clean_title     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173c1af-22a8-4f7e-932e-1e69db6a4609",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8e91d17-9e09-4a28-b71f-f2a1a8c191a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "# check for duplicates\n",
    "duplicates = train.duplicated()\n",
    "\n",
    "# view duplicate info\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3afd0d7f-99d7-4b65-af58-78b17e154b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "train_cleaned = train.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0e6f6b5-a71f-40da-acd7-f64d7304868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "## Test\n",
    "# check for duplicates in test data\n",
    "duplicates = test.duplicated()\n",
    "\n",
    "# view duplicate info\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca49c185-dc07-4386-a368-ec7587143a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "test_cleaned = test.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d69e4-ddb5-441b-a112-9802437c9abd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Log Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c48efc-4a97-41f0-9d11-ba4e4b23f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb06c4-8341-4a1e-80ef-51a0eb6d9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check skewness of price and milage\n",
    "print(f\"Skewness of price: {skew(train_cleaned['price'])}\")\n",
    "print(f\"Skewness of milage: {skew(train_cleaned['milage'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed747c-bca1-4b6d-b058-4a16f9107539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transformation to price and milage\n",
    "train_cleaned['price_log'] = np.log1p(train_cleaned['price'])  # log1p handles zero and small values\n",
    "train_cleaned['milage_log'] = np.log1p(train_cleaned['milage'])\n",
    "\n",
    "# apply log transformation to test milage\n",
    "test_cleaned['milage_log'] = np.log1p(test_cleaned['milage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3de544-14df-4c96-99f6-3719c0dbdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518811ce-87c1-4e16-9ff7-52a38ddc1f22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a7464-7cd4-4cc1-bb5f-1200dbbd6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation threshold\n",
    "correlation_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7154ba1-2684-4f76-abbb-894581be25b5",
   "metadata": {},
   "source": [
    "##### Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b88dc4-eceb-4ac0-9974-28828066de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train data\n",
    "train_copy = train.copy()\n",
    "\n",
    "# initialize label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# loop through columns and apply label encoding to object\n",
    "for column in train_copy.select_dtypes(include=['object']).columns:\n",
    "    train_copy[column] = le.fit_transform(train_copy[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75e4fc-d770-41bb-b681-49cf4e6f5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix for all columns\n",
    "correlation_matrix = train_copy.corr()\n",
    "\n",
    "# upper triangular matrix\n",
    "upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc46819-8a5a-4a06-9de0-f6f229b620fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the columns and rows to find correlations greater than or equal to threshold\n",
    "for column in upper_tri.columns:\n",
    "    for row in upper_tri.index:\n",
    "        correlation_value = upper_tri.loc[row, column]\n",
    "        if abs(correlation_value) >= correlation_threshold:\n",
    "            print(f\"Correlation between {row} and {column}: {correlation_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db5d91-3f7f-4fd2-a1b2-cbd6bd583737",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "204f7956-7bd3-4607-8013-021ef708738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import encoding library\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f46900-abc3-4aa9-bde8-250f08af224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform feature analysis\n",
    "def feature_engineering_and_importance(df, is_test=False):\n",
    "    ## Feature Engineering\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # engine Power (Horsepower)\n",
    "    # df_encoded['horsepower'] = df_encoded['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "\n",
    "    # label encoding\n",
    "    label_encoders = {}\n",
    "    for col in df_encoded.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].fillna('Unknown'))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # creating new features\n",
    "    # car age\n",
    "    df_encoded['car_age'] = 2024 - df_encoded['model_year']\n",
    "\n",
    "    # mileage per Year\n",
    "    df_encoded['mileage_per_year'] = df_encoded['milage'] / df_encoded['car_age']\n",
    "    df_encoded['mileage_per_year'].replace([np.inf, -np.inf], 0, inplace=True)  # handle division by zero\n",
    "\n",
    "    # drop irrelevant columns\n",
    "    df_encoded.drop(['id', 'model_year'], axis=1, inplace=True)\n",
    "\n",
    "    # return test dataframe and performing the above\n",
    "    if is_test:\n",
    "        return df_encoded    \n",
    "    \n",
    "    # split dataset into features and target\n",
    "    X = df_encoded.drop(columns=['price'])\n",
    "    y = df_encoded['price']\n",
    "\n",
    "    # split dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # train a model to assess feature importance\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    \n",
    "    ## Feature Importance\n",
    "    importance = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # prediction and evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # display results\n",
    "    print(f\"Model RMSE: {rmse}\\n\")\n",
    "    print(\"Feature Importance: \")\n",
    "    print(feature_importance_df)\n",
    "    print()    \n",
    "\n",
    "    return feature_importance_df, df_encoded, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c59a789a-be79-47af-bd55-2837ccd519fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 73499.72816268813\n",
      "\n",
      "Feature Importance: \n",
      "             Feature  Importance\n",
      "2             milage    0.248320\n",
      "11  mileage_per_year    0.204314\n",
      "1              model    0.109004\n",
      "4             engine    0.101177\n",
      "6            ext_col    0.093748\n",
      "7            int_col    0.065107\n",
      "10           car_age    0.063416\n",
      "5       transmission    0.060187\n",
      "0              brand    0.036831\n",
      "3          fuel_type    0.009149\n",
      "8           accident    0.008747\n",
      "9        clean_title    0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using feature analysis function\n",
    "feature_importance, train_cleaned, X_train, X_test, y_train, y_test = feature_engineering_and_importance(train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f017d49-a22b-4956-8c9b-28ab29d9ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cleaned = train_cleaned.drop(columns=['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e499b2c1-8bbb-4011-ac04-4204f4ef0074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand               0\n",
       "model               0\n",
       "milage              0\n",
       "fuel_type           0\n",
       "engine              0\n",
       "transmission        0\n",
       "ext_col             0\n",
       "int_col             0\n",
       "accident            0\n",
       "clean_title         0\n",
       "price               0\n",
       "car_age             0\n",
       "mileage_per_year    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d97c4-4f39-4a1f-a1f2-4ebabc8e7267",
   "metadata": {},
   "source": [
    "### Model Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0df9ea55-dfcd-41de-92af-540f8467cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some necessary libraries for tunning\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "950f65ac-f461-4402-a898-59202e28b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for baseline models\n",
    "def baseline_models(df):\n",
    "    X = df.drop(columns=['price'])\n",
    "    y = df['price']\n",
    "\n",
    "    # train-test split\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    results = {}\n",
    "    models = {}\n",
    "\n",
    "    # model 1: Linear Regression\n",
    "    try:\n",
    "        lr = LinearRegression()\n",
    "        # lr.fit(X_train, y_train)\n",
    "        # lr_pred = lr.predict(X_test)\n",
    "        # results['Linear Regression'] = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "        # models['Linear Regression'] = lr\n",
    "\n",
    "        lr_cv_scores = cross_val_score(lr, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['Linear Regression'] = -np.mean(lr_cv_scores)  # Convert to positive RMSE\n",
    "        models['Linear Regression'] = lr\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with Linear Regression: {error}\")\n",
    "\n",
    "    # model 2: Random Forest\n",
    "    try:\n",
    "        rf = RandomForestRegressor()\n",
    "        # rf.fit(X_train, y_train)\n",
    "        # rf_pred = rf.predict(X_test)\n",
    "        # results['Random Forest'] = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "        # models['Random Forest'] = rf\n",
    "\n",
    "        rf_cv_scores = cross_val_score(rf, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['Random Forest'] = -np.mean(rf_cv_scores)  # Convert to positive RMSE\n",
    "        models['Random Forest'] = rf\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with Random Forest: {error}\")\n",
    "\n",
    "    # model 3: Elastic Net\n",
    "    try:\n",
    "        en = ElasticNet()\n",
    "        # en.fit(X_train, y_train)\n",
    "        # en_pred = en.predict(X_test)\n",
    "        # results['Elastic Net'] = np.sqrt(mean_squared_error(y_test, en_pred))\n",
    "        # models['Elastic Net'] = en\n",
    "\n",
    "        en_cv_scores = cross_val_score(en, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['Elastic Net'] = -np.mean(en_cv_scores)  # Convert to positive RMSE\n",
    "        models['Elastic Net'] = en\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with Elastic Net: {error}\")\n",
    "\n",
    "    # results\n",
    "    for model, rmse in results.items():\n",
    "        print(f\"{model} RMSE: {rmse:.2f}\")\n",
    "\n",
    "    # return the best model based on rmse\n",
    "    best_model_name = min(results, key=results.get)\n",
    "    best_model_instance = models[best_model_name]\n",
    "    return best_model_name, best_model_instance, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "716a4663-1cf4-48b7-a61f-87eb0028e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for baseline models\n",
    "def complex_models(df):\n",
    "    X = df.drop(columns=['price'])\n",
    "    y = df['price']\n",
    "\n",
    "    # train-test split\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    results = {}\n",
    "    models = {}\n",
    "\n",
    "    # model 4: Gradient Boosting\n",
    "    try:\n",
    "        gb = GradientBoostingRegressor()\n",
    "        # gb.fit(X_train, y_train)\n",
    "        # gb_pred = gb.predict(X_test)\n",
    "        # results['Gradient Boosting'] = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
    "        # models['Gradient Boosting'] = gb\n",
    "\n",
    "        gb_cv_scores = cross_val_score(gb, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['Gradient Boosting'] = -np.mean(gb_cv_scores)  # Convert to positive RMSE\n",
    "        models['Gradient Boosting'] = gb\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with Gradient Boosting: {error}\")\n",
    "\n",
    "    # model 5: XGBoost\n",
    "    try:\n",
    "        xgb = XGBRegressor()\n",
    "        # xgb.fit(X_train, y_train)\n",
    "        # xgb_pred = xgb.predict(X_test)\n",
    "        # results['XGBoost'] = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "        # models['XGBoost'] = xgb\n",
    "\n",
    "        xgb_cv_scores = cross_val_score(xgb, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['XGBoost'] = -np.mean(xgb_cv_scores)  # Convert to positive RMSE\n",
    "        models['XGBoost'] = xgb\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with XGB: {error}\")\n",
    "\n",
    "     # model 6: LightGBM\n",
    "    try:\n",
    "        lgb = LGBMRegressor(learning_rate=0.1, n_estimators=100)\n",
    "        # lgb.fit(X_train, y_train)\n",
    "        # lgb_pred = lgb.predict(X_test)\n",
    "        # results['LightGBM'] = np.sqrt(mean_squared_error(y_test, lgb_pred))\n",
    "        # models['LightGBM'] = lgb\n",
    "\n",
    "        lgb_cv_scores = cross_val_score(lgb, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "        results['LightGBM'] = -np.mean(lgb_cv_scores)  # Convert to positive RMSE\n",
    "        models['LightGBM'] = lgb\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred with LightGBM: {error}\")\n",
    "\n",
    "    # print results\n",
    "    for model, rmse in results.items():\n",
    "        print(f\"{model} RMSE: {rmse:.2f}\")\n",
    "\n",
    "    # return best model based on RMSE\n",
    "    best_model_name = min(results, key=results.get)\n",
    "    best_model_instance = models[best_model_name]\n",
    "    return best_model_name, best_model_instance, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7f85e-6372-4079-b3c3-4890ca9e89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare baseline and complex models\n",
    "def baseline_vs_complex(baseline_results, complex_results):\n",
    "    print(\"\\nComparison of Baseline and Complex Models:\")\n",
    "    combined_results = {**baseline_results[1], **complex_results[1]}\n",
    "    \n",
    "    for model, rmse in combined_results.items():\n",
    "        print(f\"{model} RMSE: {rmse:.2f}\")\n",
    "\n",
    "    best_model = min(combined_results, key=combined_results.get)\n",
    "    print(f\"\\nBest Model: {best_model} with RMSE: {combined_results[best_model]:.2f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "126115f3-cb5f-4e56-8254-f43ed1c1f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 74699.55\n",
      "Random Forest RMSE: 77916.09\n",
      "Elastic Net RMSE: 74879.00\n"
     ]
    }
   ],
   "source": [
    "# baseline model results\n",
    "baseline_model, baseline_model_instance, baseline_result = baseline_models(train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50cdcc1d-0daf-44e6-9079-255c3e44784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model: Linear Regression\n",
      "\n",
      "Baseline model instance: LinearRegression()\n",
      "\n",
      "Baseline model result: {'Linear Regression': 74699.55302524555, 'Random Forest': 77916.09088362011, 'Elastic Net': 74879.00182217477}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baseline model: {baseline_model}\\n\")\n",
    "print(f\"Baseline model instance: {baseline_model_instance}\\n\")\n",
    "print(f\"Baseline model result: {baseline_result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04e8d066-d6ca-4da9-9c36-d2d37dddaf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1535\n",
      "[LightGBM] [Info] Number of data points in the train set: 150826, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 43859.547492\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1537\n",
      "[LightGBM] [Info] Number of data points in the train set: 150826, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 43829.197671\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1536\n",
      "[LightGBM] [Info] Number of data points in the train set: 150826, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 43923.098219\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1535\n",
      "[LightGBM] [Info] Number of data points in the train set: 150827, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 43968.734504\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1537\n",
      "[LightGBM] [Info] Number of data points in the train set: 150827, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 43809.502854\n",
      "Gradient Boosting RMSE: 72982.47\n",
      "XGBoost RMSE: 75714.83\n",
      "LightGBM RMSE: 72986.03\n"
     ]
    }
   ],
   "source": [
    "# complex model results\n",
    "complex_model, complex_model_instance, complex_result = complex_models(train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81ec2dc3-ab6c-45c7-9bdb-914f71ebe6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex model: Gradient Boosting\n",
      "\n",
      "Complex model instance: GradientBoostingRegressor()\n",
      "\n",
      "Complex model result: {'Gradient Boosting': 72982.47272820731, 'XGBoost': 75714.83029075306, 'LightGBM': 72986.03045340911}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Complex model: {complex_model}\\n\")\n",
    "print(f\"Complex model instance: {complex_model_instance}\\n\")\n",
    "print(f\"Complex model result: {complex_result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849df097-3ed9-4e40-a664-6768a2118f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model\n",
    "best_model = baseline_vs_complex(baseline_result, complex_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98732ab4-4a7b-4478-9858-c9d15d57bb6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e764b9-96b5-4d56-ae90-e1a422241bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for hyperparameter tuning\n",
    "def tuning_function(df, best_model):\n",
    "    X = df.drop(columns=['price'])\n",
    "    y = df['price']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if best_model == 'Linear Regression':\n",
    "        model = LinearRegression()\n",
    "        param_grid = {}\n",
    "    elif best_model == 'Random Forest':\n",
    "        model = RandomForestRegressor()\n",
    "        param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}\n",
    "    elif best_model == 'Gradient Boosting':\n",
    "        model = GradientBoostingRegressor()\n",
    "        param_grid = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "    elif best_model == 'XGBoost':\n",
    "        model = XGBRegressor()\n",
    "        param_grid = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "    elif best_model == 'LightGBM':\n",
    "        model = LGBMRegressor()\n",
    "        param_grid = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "    else:\n",
    "        print(\"Model not recognized.\")\n",
    "        return\n",
    "\n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Grid Search Best Parameters: {grid_search.best_params_} with RMSE: {np.sqrt(-cross_val_score(grid_search.best_estimator_, X_test, y_test, cv=5, scoring='neg_mean_squared_error')).mean()}\\n\\n\\n\\n\")\n",
    "\n",
    "    # Randomized Search\n",
    "    random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=5)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(f\"Randomized Search Best Parameters: {random_search.best_params_} with RMSE: {np.sqrt(-cross_val_score(random_search.best_estimator_, X_test, y_test, cv=5, scoring='neg_mean_squared_error')).mean()}\\n\\n\\n\\n\")\n",
    "\n",
    "    # Optuna\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.05, 0.2),  # Restricted range\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 40)\n",
    "        }\n",
    "        model.set_params(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        return mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    print(f\"Optuna Best Parameters: {study.best_params} with RMSE: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82604d51-b5e2-4191-b0ac-3168d490f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 'LightGBM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2bd10-a4d0-4e32-916f-901107eeda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tunning\n",
    "tuning_function(train_cleaned, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d9f0f-676f-48cd-9745-55754ed9cd14",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4c38d81-3df8-49af-86b2-667811ba4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using feature analysis function on test data\n",
    "test_cleaned = feature_engineering_and_importance(test_cleaned, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfd46758-7516-4ba6-bff2-1fb0069d8ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (188533, 13)\n",
      "Test shape: (125690, 12)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train_cleaned.shape}\")\n",
    "print(f\"Test shape: {test_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "691b89ba-bc30-4d38-a158-e46543635f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns from train to test and fill with 0\n",
    "missing_cols = set(train_cleaned.columns) - set(test_cleaned.columns)\n",
    "for col in missing_cols:\n",
    "    test_cleaned[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cae304cb-5fd6-4696-a742-b506de3cd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the test data has the same features as the train data used by the best model\n",
    "test_cleaned = test_cleaned.reindex(columns=train_cleaned.columns, fill_value=0)\n",
    "\n",
    "# remove price column from test data\n",
    "test_cleaned_features = test_cleaned.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ca47acb-c8d2-4b68-ac20-d7699be096df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GradientBoostingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# make predictions using the best model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m complex_model_instance\u001b[38;5;241m.\u001b[39mpredict(test_cleaned_features)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:2124\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2120\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   2121\u001b[0m     X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2122\u001b[0m )\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m-> 2124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:961\u001b[0m, in \u001b[0;36mBaseGradientBoosting._raw_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raw_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    960\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    962\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict_init(X)\n\u001b[1;32m    963\u001b[0m     predict_stages(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_, X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate, raw_predictions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GradientBoostingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# make predictions using the best model\n",
    "predictions = complex_model_instance.predict(test_cleaned_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427584b-bff3-4c0a-9457-40add4acf3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4cf24-f306-43f7-9dc3-66da83f0ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['price'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b65b3-fc65-4c13-8464-578dcfd54279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7a284-9524-45ab-adaa-f8766d2b2e18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Improving Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913f545-5402-4b70-8182-afc0517305b8",
   "metadata": {},
   "source": [
    "### Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bb22f-21f4-48fd-8397-db25bc6f837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0bd28-3db7-4a3f-92ec-f9b157cb2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create stacking features from base models\n",
    "def get_stacking_data(X, y, base_models, n_folds=5):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "    \n",
    "    for i, model in enumerate(base_models):\n",
    "        for train_index, val_index in kf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            # Clone the model to avoid affecting the original instance\n",
    "            cloned_model = clone(model)\n",
    "            cloned_model.fit(X_train, y_train)\n",
    "            out_of_fold_predictions[val_index, i] = cloned_model.predict(X_val)\n",
    "    \n",
    "    return out_of_fold_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050c156-e0cb-463c-a1dd-6434e7607203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d7035-e9b9-4747-aadf-766f54e519ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate out-of-fold predictions (meta-features)\n",
    "X_stack_train = get_stacking_data(X_train, y_train, base_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a972328-59e2-4b52-b775-5ac3e4dd6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train meta-model (you can use any regressor; Ridge or Lasso can be good choices)\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_stack_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe32c9f-278d-4864-9b21-9df26bde05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stacking features for test data\n",
    "X_stack_test = np.column_stack([model.fit(X_train, y_train).predict(X_test) for model in base_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725341d-d173-4d11-a583-e95ef05b112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final predictions\n",
    "final_predictions = meta_model.predict(X_stack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576bb1c-9e47-4d6a-b941-845225ad0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meta_model.predict(test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0005b46-fb10-4065-8056-f4c4a3221b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b456dd-d17f-4de1-a278-9cf4c21d9daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d21d7dd-2d1b-4295-ad13-257106b7d68e",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6677565-fddd-446c-8ece-1c48a7549815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57194671-33d1-4457-8d97-a7c485e6dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify categorical columns\n",
    "categorical_cols = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248dc70-7cc9-4217-b48f-b59bd3b3081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train CatBoost\n",
    "catboost_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    cat_features=categorical_cols,  # Pass the categorical columns directly\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936041a3-2b6f-4ffa-b358-853734d10f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (ensure the data has no missing values or duplicates)\n",
    "catboost_model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11472386-b5ba-4c18-87b1-61e57a7c7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "catboost_predictions = catboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05638e2e-fc35-4dc2-9cf1-ff73faa3829d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b0141-cda3-45a4-8a14-61ea92e931a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create stacking features from base models\n",
    "def get_stacking_data(X, y, base_models, n_folds=5):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "    \n",
    "    for i, model in enumerate(base_models):\n",
    "        for train_index, val_index in kf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            # Clone the model to avoid affecting the original instance\n",
    "            cloned_model = clone(model)\n",
    "            cloned_model.fit(X_train, y_train)\n",
    "            out_of_fold_predictions[val_index, i] = cloned_model.predict(X_val)\n",
    "    \n",
    "    return out_of_fold_predictions\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "]\n",
    "\n",
    "# Generate out-of-fold predictions (meta-features)\n",
    "X_stack_train = get_stacking_data(X_train, y_train, base_models)\n",
    "\n",
    "# Train meta-model (you can use any regressor; Ridge or Lasso can be good choices)\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_stack_train, y_train)\n",
    "\n",
    "# Generate stacking features for test data\n",
    "X_stack_test = np.column_stack([model.fit(X_train, y_train).predict(X_test) for model in base_models])\n",
    "\n",
    "# Make final predictions\n",
    "final_predictions = meta_model.predict(X_stack_test)\n",
    "\n",
    "# Calculate RMSE on validation set (if you have one)\n",
    "# Assuming X_val and y_val are your validation data\n",
    "X_val_stack = get_stacking_data(X_val, y_val, base_models)\n",
    "final_val_predictions = meta_model.predict(X_val_stack)\n",
    "rmse = mean_squared_error(y_val, final_val_predictions, squared=False)\n",
    "print(f'Validation RMSE: {rmse:.2f}')\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_cleaned['id'],  # Replace with the correct identifier column\n",
    "    'price': final_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79841115-a5af-4762-b100-8b4197a7ae69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
