{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442c7e10-687c-43a4-a69d-75bc4180b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')   # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06969be9-d019-4709-aa01-67773417964b",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b924c4-2609-44e0-b8dc-77f37fdc36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "      <th>label</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL1KWCMY</td>\n",
       "      <td>Me &amp;amp; The Big Homie meanboy3000 #MEANBOY #M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E3303EME</td>\n",
       "      <td>I'm 100% thinking of devoting my career to pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4IVFSMS</td>\n",
       "      <td>#whatcausesautism VACCINES, DO NOT VACCINATE Y...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DR6ROZ4</td>\n",
       "      <td>I mean if they immunize my kid with something ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J77ENIIE</td>\n",
       "      <td>Thanks to &lt;user&gt; Catch me performing at La Nui...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text  label  \\\n",
       "0  CL1KWCMY  Me &amp; The Big Homie meanboy3000 #MEANBOY #M...    0.0   \n",
       "1  E3303EME  I'm 100% thinking of devoting my career to pro...    1.0   \n",
       "2  M4IVFSMS  #whatcausesautism VACCINES, DO NOT VACCINATE Y...   -1.0   \n",
       "3  1DR6ROZ4  I mean if they immunize my kid with something ...   -1.0   \n",
       "4  J77ENIIE  Thanks to <user> Catch me performing at La Nui...    0.0   \n",
       "\n",
       "   agreement  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "df_train = pd.read_csv('Train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fd84bc-98a6-45fa-abc8-ef5053ce1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5177, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; ... &amp;amp; 4 a vaccine given 2 he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>Students starting school without whooping coug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>I'm kinda over every ep of &lt;user&gt; being \"rippe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>How many innocent children die for lack of vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>CDC eyeing bird flu vaccine for humans, though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text\n",
       "0  00BHHHP1  <user> <user> ... &amp; 4 a vaccine given 2 he...\n",
       "1  00UNMD0E  Students starting school without whooping coug...\n",
       "2  01AXPTJF  I'm kinda over every ep of <user> being \"rippe...\n",
       "3  01HOEQJW  How many innocent children die for lack of vac...\n",
       "4  01JUKMAO  CDC eyeing bird flu vaccine for humans, though..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "df_test = pd.read_csv('Test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b915bff-9e79-4946-8737-5a4a4d1c04ac",
   "metadata": {},
   "source": [
    "### Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32441466-6ec0-4e0b-8ebb-5aa74e256147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5177 entries, 0 to 5176\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   5177 non-null   object\n",
      " 1   safe_text  5176 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 81.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# information \n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122d175f-459b-45e0-8621-83b8ae331b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "safe_text    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af801f5-3b2b-4a58-8ce6-506680895747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a65c4-e3e2-406e-9432-5b54d7d9fe91",
   "metadata": {},
   "source": [
    "##### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6552f07-7e63-417a-8ef1-6a3b55838fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: label\n",
      "Mean round: 0\n",
      "Column: agreement\n",
      "Mean round: 1\n"
     ]
    }
   ],
   "source": [
    "# fill missing values\n",
    "# label and aggreement are floating numbers, use mean and round\n",
    "cols = ['label', 'agreement']\n",
    "for col in cols:\n",
    "    print(f'Column: {col}')\n",
    "    mean_rounded = round(df_train[col].mean())\n",
    "    print(f'Mean round: {mean_rounded}')\n",
    "    df_train[col].fillna(mean_rounded, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7c1e44-872b-4001-9e0a-d20c5962eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      " 0    4909\n",
      " 1    4054\n",
      "-1    1038\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# there are some inconsistencies, label values should either be 1, 0, -1\n",
    "\n",
    "# Check the values in the target variable and handle any inconsistencies\n",
    "df_train['label'] = df_train['label'].round().astype(int)\n",
    "\n",
    "# Verify the counts of the target variable after handling inconsistencies\n",
    "label_counts = df_train['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85072a6-2e58-4936-9446-0b9bfc2c5ea9",
   "metadata": {},
   "source": [
    "#### Further preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed9c42-3344-4938-b736-376b9888b23c",
   "metadata": {},
   "source": [
    "##### Handle texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a97a7991-c5e9-476b-8d58-6b9c6277be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7793268-af94-47e8-b0de-bc00feb937ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downloading nltk resources\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9821755-e23a-4fe5-8297-deba3e376c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8976bc71-267e-47bb-9ceb-48376fbacb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "This is an example sentence for text preprocessing, including tokenization, lowercasing, stop word removal, and lemmatization.\n",
      "\n",
      "Preprocessed Text:\n",
      "example sentence text preprocessing including tokenization lowercasing stop word removal lemmatization\n"
     ]
    }
   ],
   "source": [
    "# Tokenization, lowercasing, removal of stop words, and lemmatization\n",
    "# function to preprocess texts\n",
    "def preprocess_text(text):\n",
    "    # tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # removal of punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # removal of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example text\n",
    "text = \"This is an example sentence for text preprocessing, including tokenization, lowercasing, stop word removal, and lemmatization.\"\n",
    "\n",
    "# Preprocess the example text\n",
    "preprocessed_text = preprocess_text(text)\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nPreprocessed Text:\")\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b45a82-24f2-4019-9d06-b84438f5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess texts in 'safe_text' column in train data\n",
    "df_train['safe_text'] = df_train['safe_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18a5100a-c8b0-4f1f-8c3b-f390435054ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'safe_text' column to strings\n",
    "df_test['safe_text'] = df_test['safe_text'].astype(str)\n",
    "\n",
    "# preprocess texts in 'safe_text' column in test_data\n",
    "df_test['safe_text'] = df_test['safe_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b2123e-ea7e-4900-9e69-7d9958d931a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46d211bd-a0c6-44a4-9a2e-f88bf7d2d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_text = vectorizer.fit_transform(df_train['safe_text'])\n",
    "X_test_text = vectorizer.transform(df_test['safe_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5775873d-7042-43a9-95ab-d38cc9cba4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text features with selected numerical features\n",
    "X_train_num = df_train.drop(columns=['label', 'agreement', 'tweet_id'])\n",
    "X_test_num = df_test.drop(columns=['tweet_id'])\n",
    "X_train = pd.concat([X_train_num, pd.DataFrame(X_train_text.toarray(), columns=vectorizer.get_feature_names_out())], axis=1)\n",
    "X_test = pd.concat([X_test_num, pd.DataFrame(X_test_text.toarray(), columns=vectorizer.get_feature_names_out())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9433aab-22ff-4172-9067-955e114ed8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric columns before feature selection\n",
    "X_train_numeric = X_train.select_dtypes(include=['float64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64'])\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(score_func=f_classif, k=23)\n",
    "X_train_selected = selector.fit_transform(X_train_numeric, df_train['label'])\n",
    "X_test_selected = selector.transform(X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c490ea8d-e4ee-4a0b-ab5b-089eb33b16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_selected, df_train['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4b64ff7-baba-471f-a882-eaeeb3f24629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imbalanced data\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f7f2f0-3ea2-49fa-adc1-f87e9196bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fb67e78-908a-4689-af0e-0c3dbf87af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b72b51e0-48cd-469f-b96a-ab5a6db2ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e8e953a-6d95-489d-92f2-a69e20e45370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Perform GridSearchCV\u001b[39;00m\n\u001b[0;32m      2\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b91bb2-30a0-4305-8036-a974d0f73e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e736df-39c7-4712-8233-0dbe09703cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model from GridSearchCV\n",
    "best_rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fba97d-6057-42b0-ad22-5f9fc80ee597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred_val = best_rf_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", accuracy*100)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05674877-31e5-4322-a143-46b337ff7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function check for overfitting or underfitting\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    # Check for overfitting or underfitting\n",
    "    diff_scores = train_scores_mean - test_scores_mean\n",
    "    if np.any(diff_scores > 0):\n",
    "        print(\"Yes, overfitting\")\n",
    "    elif np.any(diff_scores < 0):\n",
    "        print(\"Yes, underfitting\")\n",
    "    else:\n",
    "        print(\"No overfitting or underfitting\")\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5882c6e-da8e-46e8-827c-2030ab0f2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "title = \"Learning Curves (Random Forest Classifier)\"\n",
    "plot_learning_curve(best_rf_model, title, X_train_resampled, y_train_resampled, cv=5, n_jobs=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08f260-4a94-479f-894f-a9c3cf0e2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data and create submission DataFrame\n",
    "test_predictions = best_rf_model.predict(X_test_selected)\n",
    "submission_df = pd.DataFrame({'tweet_id': df_test['tweet_id'], 'label': test_predictions})\n",
    "submission_df.to_csv('submission_rf_gridsearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f51f9-f149-46a1-a395-76c24f77784b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff2cb9-a702-4165-b7d0-84dd7da176f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42797271-9e14-4c98-81ef-e065d6673b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7204a-8515-485d-ba7b-2e5d2d87d7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
