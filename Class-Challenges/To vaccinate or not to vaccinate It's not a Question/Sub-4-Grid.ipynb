{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442c7e10-687c-43a4-a69d-75bc4180b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')   # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06969be9-d019-4709-aa01-67773417964b",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b924c4-2609-44e0-b8dc-77f37fdc36a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "      <th>label</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL1KWCMY</td>\n",
       "      <td>Me &amp;amp; The Big Homie meanboy3000 #MEANBOY #M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E3303EME</td>\n",
       "      <td>I'm 100% thinking of devoting my career to pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4IVFSMS</td>\n",
       "      <td>#whatcausesautism VACCINES, DO NOT VACCINATE Y...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DR6ROZ4</td>\n",
       "      <td>I mean if they immunize my kid with something ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J77ENIIE</td>\n",
       "      <td>Thanks to &lt;user&gt; Catch me performing at La Nui...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text  label  \\\n",
       "0  CL1KWCMY  Me &amp; The Big Homie meanboy3000 #MEANBOY #M...    0.0   \n",
       "1  E3303EME  I'm 100% thinking of devoting my career to pro...    1.0   \n",
       "2  M4IVFSMS  #whatcausesautism VACCINES, DO NOT VACCINATE Y...   -1.0   \n",
       "3  1DR6ROZ4  I mean if they immunize my kid with something ...   -1.0   \n",
       "4  J77ENIIE  Thanks to <user> Catch me performing at La Nui...    0.0   \n",
       "\n",
       "   agreement  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "df_train = pd.read_csv('Train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fd84bc-98a6-45fa-abc8-ef5053ce1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5177, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00BHHHP1</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; ... &amp;amp; 4 a vaccine given 2 he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00UNMD0E</td>\n",
       "      <td>Students starting school without whooping coug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AXPTJF</td>\n",
       "      <td>I'm kinda over every ep of &lt;user&gt; being \"rippe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01HOEQJW</td>\n",
       "      <td>How many innocent children die for lack of vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01JUKMAO</td>\n",
       "      <td>CDC eyeing bird flu vaccine for humans, though...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text\n",
       "0  00BHHHP1  <user> <user> ... &amp; 4 a vaccine given 2 he...\n",
       "1  00UNMD0E  Students starting school without whooping coug...\n",
       "2  01AXPTJF  I'm kinda over every ep of <user> being \"rippe...\n",
       "3  01HOEQJW  How many innocent children die for lack of vac...\n",
       "4  01JUKMAO  CDC eyeing bird flu vaccine for humans, though..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "df_test = pd.read_csv('Test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b915bff-9e79-4946-8737-5a4a4d1c04ac",
   "metadata": {},
   "source": [
    "### Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32441466-6ec0-4e0b-8ebb-5aa74e256147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5177 entries, 0 to 5176\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   5177 non-null   object\n",
      " 1   safe_text  5176 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 81.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# information \n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122d175f-459b-45e0-8621-83b8ae331b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "safe_text    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af801f5-3b2b-4a58-8ce6-506680895747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a65c4-e3e2-406e-9432-5b54d7d9fe91",
   "metadata": {},
   "source": [
    "##### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6552f07-7e63-417a-8ef1-6a3b55838fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: label\n",
      "Mean round: 0\n",
      "Column: agreement\n",
      "Mean round: 1\n"
     ]
    }
   ],
   "source": [
    "# fill missing values\n",
    "# label and aggreement are floating numbers, use mean and round\n",
    "cols = ['label', 'agreement']\n",
    "for col in cols:\n",
    "    print(f'Column: {col}')\n",
    "    mean_rounded = round(df_train[col].mean())\n",
    "    print(f'Mean round: {mean_rounded}')\n",
    "    df_train[col].fillna(mean_rounded, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7c1e44-872b-4001-9e0a-d20c5962eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      " 0    4909\n",
      " 1    4054\n",
      "-1    1038\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# there are some inconsistencies, label values should either be 1, 0, -1\n",
    "\n",
    "# Check the values in the target variable and handle any inconsistencies\n",
    "df_train['label'] = df_train['label'].round().astype(int)\n",
    "\n",
    "# Verify the counts of the target variable after handling inconsistencies\n",
    "label_counts = df_train['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85072a6-2e58-4936-9446-0b9bfc2c5ea9",
   "metadata": {},
   "source": [
    "#### Further preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed9c42-3344-4938-b736-376b9888b23c",
   "metadata": {},
   "source": [
    "##### Handle texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a97a7991-c5e9-476b-8d58-6b9c6277be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7793268-af94-47e8-b0de-bc00feb937ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downloading nltk resources\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9821755-e23a-4fe5-8297-deba3e376c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8976bc71-267e-47bb-9ceb-48376fbacb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "This is an example sentence for text preprocessing, including tokenization, lowercasing, stop word removal, and lemmatization.\n",
      "\n",
      "Preprocessed Text:\n",
      "example sentence text preprocessing including tokenization lowercasing stop word removal lemmatization\n"
     ]
    }
   ],
   "source": [
    "# Tokenization, lowercasing, removal of stop words, and lemmatization\n",
    "# function to preprocess texts\n",
    "def preprocess_text(text):\n",
    "    # tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # removal of punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # removal of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Example text\n",
    "text = \"This is an example sentence for text preprocessing, including tokenization, lowercasing, stop word removal, and lemmatization.\"\n",
    "\n",
    "# Preprocess the example text\n",
    "preprocessed_text = preprocess_text(text)\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"\\nPreprocessed Text:\")\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b45a82-24f2-4019-9d06-b84438f5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess texts in 'safe_text' column in train data\n",
    "df_train['safe_text'] = df_train['safe_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18a5100a-c8b0-4f1f-8c3b-f390435054ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'safe_text' column to strings\n",
    "df_test['safe_text'] = df_test['safe_text'].astype(str)\n",
    "\n",
    "# preprocess texts in 'safe_text' column in test_data\n",
    "df_test['safe_text'] = df_test['safe_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17b2123e-ea7e-4900-9e69-7d9958d931a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f113db-8eb4-4e27-a46a-8ed86fda8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d211bd-a0c6-44a4-9a2e-f88bf7d2d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_text = vectorizer.fit_transform(df_train['safe_text'])\n",
    "X_test_text = vectorizer.transform(df_test['safe_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5775873d-7042-43a9-95ab-d38cc9cba4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text features with selected numerical features\n",
    "X_train_num = df_train.drop(columns=['label', 'agreement', 'tweet_id'])\n",
    "X_test_num = df_test.drop(columns=['tweet_id'])\n",
    "X_train = pd.concat([X_train_num, pd.DataFrame(X_train_text.toarray(), columns=vectorizer.get_feature_names_out())], axis=1)\n",
    "X_test = pd.concat([X_test_num, pd.DataFrame(X_test_text.toarray(), columns=vectorizer.get_feature_names_out())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9433aab-22ff-4172-9067-955e114ed8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric columns before feature selection\n",
    "X_train_numeric = X_train.select_dtypes(include=['float64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['float64'])\n",
    "\n",
    "# Feature Selection\n",
    "selector = SelectKBest(score_func=f_classif, k=23)\n",
    "X_train_selected = selector.fit_transform(X_train_numeric, df_train['label'])\n",
    "X_test_selected = selector.transform(X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c490ea8d-e4ee-4a0b-ab5b-089eb33b16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_selected, df_train['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4b64ff7-baba-471f-a882-eaeeb3f24629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imbalanced data\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f7f2f0-3ea2-49fa-adc1-f87e9196bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65ad1a-b1f1-4bb5-b1bb-fbd449b1af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training with Hyperparameter Tuning (Using Support Vector Machines)\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb427a-0379-47cf-b259-2542de021c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e953a-6d95-489d-92f2-a69e20e45370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "y_pred_val = best_svm_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", accuracy*100)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05674877-31e5-4322-a143-46b337ff7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function check for overfitting or underfitting\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    # Check for overfitting or underfitting\n",
    "    diff_scores = train_scores_mean - test_scores_mean\n",
    "    if np.any(diff_scores > 0):\n",
    "        print(\"Yes, overfitting\")\n",
    "    elif np.any(diff_scores < 0):\n",
    "        print(\"Yes, underfitting\")\n",
    "    else:\n",
    "        print(\"No overfitting or underfitting\")\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5882c6e-da8e-46e8-827c-2030ab0f2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "title = \"Learning Curves (Support Vector Machines)\"\n",
    "plot_learning_curve(best_svm_model, title, X_train_resampled, y_train_resampled, cv=5, n_jobs=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08f260-4a94-479f-894f-a9c3cf0e2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data and create submission DataFrame\n",
    "test_predictions = best_svm_model.predict(X_test_selected)\n",
    "submission_df = pd.DataFrame({'tweet_id': df_test['tweet_id'], 'label': test_predictions})\n",
    "submission_df.to_csv('submission_svm_gridsearch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f51f9-f149-46a1-a395-76c24f77784b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff2cb9-a702-4165-b7d0-84dd7da176f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42797271-9e14-4c98-81ef-e065d6673b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7204a-8515-485d-ba7b-2e5d2d87d7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
