{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/imgremlin/Photos/master/electricity.jpg\" width=\"1000px\"> \n",
    "# Fraud Detection in Electricity and Gas Consumption Challenge\n",
    "**by team GORNYAKI (Tsepa Oleksii and Samoshin Andriy [Ukraine, KPI, IASA])**\n",
    "\n",
    "Thanks to the organizers for this [challenge](https://zindi.africa/competitions/ai-hack-tunisia-4-predictive-analytics-challenge-1) and everyone for participating! In this notebook you will find:\n",
    "\n",
    "* importing libraries\n",
    "* basic EDA\n",
    "* feature engeneering\n",
    "* modelling\n",
    "* prediction \n",
    "* submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "seed=47\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "invoice_test = pd.read_csv('invoice_test.csv',low_memory=False)\n",
    "invoice_train = pd.read_csv('invoice_train.csv',low_memory=False)\n",
    "client_test = pd.read_csv('client_test.csv',low_memory=False)\n",
    "client_train = pd.read_csv('client_train.csv',low_memory=False)\n",
    "sample_submission = pd.read_csv('submission_fraud-3.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Basic EDA</h2>\n",
    "\n",
    "We won't show full EDA, just want to attract your attention to tips which help us to reach good score.\n",
    "\n",
    "In next two cells you will find value counts according each column in train and test set. This information we'll use in feature engeneering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = client_train.groupby(['target'])['client_id'].count()\n",
    "plt.bar(x=ds.index, height=ds.values, tick_label =[0,1])\n",
    "plt.title('target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['disrict','region','client_catg']:\n",
    "    ds = client_train.groupby([col])['client_id'].count()\n",
    "    plt.bar(x=ds.index, height=ds.values)\n",
    "    plt.title(col+' distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing rows in invoice_train:',invoice_train.isna().sum().sum())\n",
    "print('Number of missing rows in invoice_test:',invoice_test.isna().sum().sum(),'\\n')\n",
    "print('Number of missing rows in client_train:',client_train.isna().sum().sum())\n",
    "print('Number of missing rows in client_test:',client_test.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique values in invoice_train:')\n",
    "for col in invoice_train.columns:\n",
    "    print(f\"{col} - {invoice_train[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature engeneering</h2>\n",
    "\n",
    "In this part we want to explain the most powerful decision in our notebook - feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_change(cl, inv):\n",
    "\n",
    "    cl['client_catg'] = cl['client_catg'].astype('category')\n",
    "    cl['disrict'] = cl['disrict'].astype('category')\n",
    "    cl['region'] = cl['region'].astype('category')\n",
    "    cl['region_group'] = cl['region'].apply(lambda x: 100 if x<100 else 300 if x>300 else 200)\n",
    "    cl['creation_date'] = pd.to_datetime(cl['creation_date'])\n",
    "    \n",
    "    cl['coop_time'] = (2019 - cl['creation_date'].dt.year)*12 - cl['creation_date'].dt.month\n",
    "\n",
    "    inv['counter_type'] = inv['counter_type'].map({\"ELEC\":1,\"GAZ\":0})\n",
    "    inv['counter_statue'] = inv['counter_statue'].map({0:0,1:1,2:2,3:3,4:4,5:5,769:5,'0':0,'5':5,'1':1,'4':4,'A':0,618:5,269375:5,46:5,420:5})\n",
    "    \n",
    "    inv['invoice_date'] = pd.to_datetime(inv['invoice_date'], dayfirst=True)\n",
    "    inv['invoice_month'] = inv['invoice_date'].dt.month\n",
    "    inv['invoice_year'] = inv['invoice_date'].dt.year\n",
    "    inv['is_weekday'] = ((pd.DatetimeIndex(inv.invoice_date).dayofweek) // 5 == 1).astype(float)\n",
    "    inv['delta_index'] = inv['new_index'] - inv['old_index']\n",
    "    \n",
    "    return cl, inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'client_catg', 'district' and 'region' were assigned as categories to use them as categorical features in lgbm (as for me, lgbm for default threats with cat features slightly better than other encoders such as catboost/target encoder)\n",
    "* 'region_group' created simply by dividing 'region' in 3 groups (we purposed that regions weren't randomly decoded)\n",
    "* 'coop_time' - amount of time since account creation in months\n",
    "* 'counter_type' was binary encoded \n",
    "* 'counter_statue' cleaned from mislabeled values\n",
    "* extracted month, year from 'invoice_date', also added binary feature - 'is_weekday'\n",
    "* not sure about any logical sense in 'delta_index', but it improved score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7944\\2795683553.py:7: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  cl['creation_date'] = pd.to_datetime(cl['creation_date'])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7944\\2795683553.py:14: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  inv['invoice_date'] = pd.to_datetime(inv['invoice_date'], dayfirst=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7944\\2795683553.py:7: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  cl['creation_date'] = pd.to_datetime(cl['creation_date'])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7944\\2795683553.py:14: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  inv['invoice_date'] = pd.to_datetime(inv['invoice_date'], dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "client_train1, invoice_train1 = feature_change(client_train, invoice_train)\n",
    "client_test1, invoice_test1 = feature_change(client_test, invoice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_feature(invoice, client_df, agg_stat):\n",
    "    \n",
    "    invoice['delta_time'] = invoice.sort_values(['client_id','invoice_date']).groupby('client_id')['invoice_date'].diff().dt.days.reset_index(drop=True)\n",
    "    agg_trans = invoice.groupby('client_id')[agg_stat+['delta_time']].agg(['mean','std','min','max'])\n",
    "    \n",
    "    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = invoice.groupby('client_id').size().reset_index(name='transactions_count')\n",
    "    agg_trans = pd.merge(df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    weekday_avg = invoice.groupby('client_id')[['is_weekday']].agg(['mean'])\n",
    "    weekday_avg.columns = ['_'.join(col).strip() for col in weekday_avg.columns.values]\n",
    "    weekday_avg.reset_index(inplace=True)\n",
    "    client_df = pd.merge(client_df, weekday_avg, on='client_id', how='left')\n",
    "    \n",
    "    full_df = pd.merge(client_df, agg_trans, on='client_id', how='left')\n",
    "    \n",
    "    full_df['invoice_per_cooperation'] = full_df['transactions_count'] / full_df['coop_time']\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* created some aggregation features (min/max/mean/std) over continious columns per every client\n",
    "* added 'delta_time' - amount of time between invoices for each user\n",
    "* created 'invoice_per_cooperation' - number of transactions per some amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stat_columns = [\n",
    " 'tarif_type',\n",
    " 'counter_number',\n",
    " 'counter_statue',\n",
    " 'counter_code',\n",
    " 'reading_remarque',\n",
    " 'consommation_level_1',\n",
    " 'consommation_level_2',\n",
    " 'consommation_level_3',\n",
    " 'consommation_level_4',\n",
    " 'old_index',\n",
    " 'new_index',\n",
    " 'months_number',\n",
    " 'counter_type',\n",
    " 'invoice_month',\n",
    " 'invoice_year',\n",
    " 'delta_index'\n",
    "]\n",
    "\n",
    "train_df1 = agg_feature(invoice_train1, client_train1, agg_stat_columns)\n",
    "test_df1 = agg_feature(invoice_test1, client_test1, agg_stat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    \n",
    "    for col in agg_stat_columns:\n",
    "        df[col+'_range'] = df[col+'_max'] - df[col+'_min']\n",
    "        df[col+'_max_mean'] = df[col+'_max']/df[col+'_mean']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we created statistical 'max_mean' and 'range' features which noticeably improved score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = new_features(train_df1)\n",
    "test_df2 = new_features(test_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's review how many features did we create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of columns:  29\n",
      "Number of columns now:  111\n"
     ]
    }
   ],
   "source": [
    "print('Initial number of columns: ', len(client_train.columns)+len(invoice_train.columns))\n",
    "print('Number of columns now: ', len(train_df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(df):\n",
    "\n",
    "    col_drop = ['client_id', 'creation_date']\n",
    "    for col in col_drop:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we created really a lot of features and sure, not all of them were usefull, so we dropped some unnessesary columns in next few cells\n",
    "* 'drop_col' array was made after using our own backward feature selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop(train_df2)\n",
    "test_df = drop(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df.drop('target',axis=1)\n",
    "\n",
    "feature_name = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['reading_remarque_max','counter_statue_min','counter_type_min','counter_type_max','counter_type_range',\n",
    "          'tarif_type_max', 'delta_index_min', 'consommation_level_4_mean']\n",
    "\n",
    "X = X.drop(drop_col, axis=1)\n",
    "test_df = test_df.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid with simplified hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(100, 500),  # Reduced range\n",
    "    'num_leaves': np.arange(2, 256),\n",
    "    'max_depth': np.arange(2, 64),  # Reduced range\n",
    "    'learning_rate': np.logspace(-3, 0, num=50),  # Reduced number of values\n",
    "    'random_state': [seed]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=LGBMClassifier(),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Info] Number of positive: 7566, number of negative: 127927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20201\n",
      "[LightGBM] [Info] Number of data points in the train set: 135493, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055841 -> initscore=-2.827795\n",
      "[LightGBM] [Info] Start training from score -2.827795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.001     , 0.0011514 , 0.00132571, 0.00152642, 0.00175751,\n",
       "       0.00202359, 0.00232995, 0.0026827 , 0.00308884, 0.00355648,\n",
       "       0.00409492, 0.00471487, 0.00542868, 0.00625055, 0.00719686,\n",
       "       0.00828643, 0.00954095, 0.01098541, 0.01264855, 0.01456348,\n",
       "       0.01676833, 0.01930698...\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255]),\n",
       "                                        &#x27;random_state&#x27;: [47]},\n",
       "                   random_state=47, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.001     , 0.0011514 , 0.00132571, 0.00152642, 0.00175751,\n",
       "       0.00202359, 0.00232995, 0.0026827 , 0.00308884, 0.00355648,\n",
       "       0.00409492, 0.00471487, 0.00542868, 0.00625055, 0.00719686,\n",
       "       0.00828643, 0.00954095, 0.01098541, 0.01264855, 0.01456348,\n",
       "       0.01676833, 0.01930698...\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255]),\n",
       "                                        &#x27;random_state&#x27;: [47]},\n",
       "                   random_state=47, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.001     , 0.0011514 , 0.00132571, 0.00152642, 0.00175751,\n",
       "       0.00202359, 0.00232995, 0.0026827 , 0.00308884, 0.00355648,\n",
       "       0.00409492, 0.00471487, 0.00542868, 0.00625055, 0.00719686,\n",
       "       0.00828643, 0.00954095, 0.01098541, 0.01264855, 0.01456348,\n",
       "       0.01676833, 0.01930698...\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255]),\n",
       "                                        'random_state': [47]},\n",
       "                   random_state=47, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform randomized search for best hyperparameters\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'random_state': 47, 'num_leaves': 158, 'n_estimators': 473, 'max_depth': 54, 'learning_rate': 0.012648552168552958}\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model with best hyperparameters\n",
    "model = LGBMClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stratified k-fold for cross-validation\n",
    "stkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(X, y, model, cv):\n",
    "    res=[]\n",
    "    local_probs=pd.DataFrame()\n",
    "    probs = pd.DataFrame()\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
    "        \n",
    "        preds = model.predict_proba(X_valid)\n",
    "        oof_predict = model.predict_proba(test_df)\n",
    "        local_probs['fold_%i'%i] = oof_predict[:,1]\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "\n",
    "    print()\n",
    "    print('ROC AUC:', round(np.mean(res), 6))    \n",
    "    local_probs['res'] = local_probs.mean(axis=1)\n",
    "    probs['target'] = local_probs['res']\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6053, number of negative: 102341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20092\n",
      "[LightGBM] [Info] Number of data points in the train set: 108394, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055843 -> initscore=-2.827756\n",
      "[LightGBM] [Info] Start training from score -2.827756\n",
      "[LightGBM] [Info] Number of positive: 6053, number of negative: 102341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20076\n",
      "[LightGBM] [Info] Number of data points in the train set: 108394, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055843 -> initscore=-2.827756\n",
      "[LightGBM] [Info] Start training from score -2.827756\n",
      "[LightGBM] [Info] Number of positive: 6052, number of negative: 102342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20092\n",
      "[LightGBM] [Info] Number of data points in the train set: 108394, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055833 -> initscore=-2.827931\n",
      "[LightGBM] [Info] Start training from score -2.827931\n",
      "[LightGBM] [Info] Number of positive: 6053, number of negative: 102342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20082\n",
      "[LightGBM] [Info] Number of data points in the train set: 108395, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055842 -> initscore=-2.827766\n",
      "[LightGBM] [Info] Start training from score -2.827766\n",
      "[LightGBM] [Info] Number of positive: 6053, number of negative: 102342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20092\n",
      "[LightGBM] [Info] Number of data points in the train set: 108395, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055842 -> initscore=-2.827766\n",
      "[LightGBM] [Info] Start training from score -2.827766\n",
      "\n",
      "ROC AUC: 0.883688\n",
      "CPU times: total: 17min 14s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "probs = calc(X, y, model, stkfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modelling</h2>\n",
    "\n",
    "* we used [optuna](https://optuna.org/) for hyperparameters tuning\n",
    "* it was performed with respect to StratifiedKFold cross validation on 5 folds\n",
    "* you can check parameters for tuning and their final values in cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "import gc\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "category_cols = ['disrict', 'client_catg', 'region']\n",
    "\n",
    "def objective(trial:Trial):\n",
    "    \n",
    "    gc.collect()\n",
    "    models=[]\n",
    "    validScore=0\n",
    "   \n",
    "    model,log = fitLGBM(trial,X,y)\n",
    "    \n",
    "    models.append(model)\n",
    "    gc.collect()\n",
    "    validScore+=log\n",
    "    validScore/=len(models)\n",
    "    \n",
    "    return validScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitLGBM(trial,X, y):\n",
    "    \n",
    "    params={\n",
    "      'n_estimators':trial.suggest_int('n_estimators', 0, 1000), \n",
    "      'num_leaves':trial.suggest_int('num_leaves', 2, 512),\n",
    "      'max_depth':trial.suggest_int('max_depth', 2, 128),\n",
    "      'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.15),\n",
    "      'min_split_gain': trial.suggest_loguniform('min_split_gain', 0.001, 0.1),\n",
    "      'feature_fraction':trial.suggest_uniform('feature_fraction',0.1, 1.0),\n",
    "      'bagging_freq':trial.suggest_int('bagging_freq',0.1,10),\n",
    "      'verbosity': -1,\n",
    "      'random_state':seed\n",
    "            }\n",
    "    stkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    res=[]\n",
    "    for i, (tdx, vdx) in enumerate(stkfold.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
    "        preds = model.predict_proba(X_valid)\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "    \n",
    "    err = np.mean(res)\n",
    "    \n",
    "    return model, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model using the best hyperparameters\n",
    "model = LGBMClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = LGBMClassifier(random_state=seed, n_estimators=830,num_leaves=454, max_depth=61,\n",
    "                       learning_rate=0.006910869038433314, min_split_gain=0.00667926424629105, \n",
    "                       feature_fraction=0.3764303138879782, bagging_freq=8, early_stopping_rounds=30,\n",
    "                 verbose=-1)'''\n",
    "\n",
    "stkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "def calc(X, y, model, cv):\n",
    "    res=[]\n",
    "    local_probs=pd.DataFrame()\n",
    "    probs = pd.DataFrame()\n",
    "\n",
    "    for i, (tdx, vdx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[tdx], X.iloc[vdx], y[tdx], y[vdx]\n",
    "        model.fit(X_train, y_train,\n",
    "                 eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
    "        \n",
    "        preds = model.predict_proba(X_valid)\n",
    "        oof_predict = model.predict_proba(test_df)\n",
    "        local_probs['fold_%i'%i] = oof_predict[:,1]\n",
    "        res.append(roc_auc_score(y_valid, preds[:,1]))\n",
    "\n",
    "    print('ROC AUC:', round(np.mean(res), 6))    \n",
    "    local_probs['res'] = local_probs.mean(axis=1)\n",
    "    probs['target'] = local_probs['res']\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediction and submission</h2>\n",
    "\n",
    "In the next few cells you can see our local cross validation which almost match  LB score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "probs = calc(X, y, model, stkfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"client_id\": sample_submission[\"client_id\"],\n",
    "        \"target\": probs['target']\n",
    "    })\n",
    "submission.to_csv('submission-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, at the time of publication of the notebook, we got 4th place in this competition!Thank you for watching, waiting your comments!\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/imgremlin/Photos/master/lb.png\" width=\"700\"> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
