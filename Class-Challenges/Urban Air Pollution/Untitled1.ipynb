{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09f7ef0-1de0-4d8c-8b25-49cfed82de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ef2eba-5781-40f1-b76c-ee213c77e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b700fde-9b75-4e1f-8fe5-0cb7a6325afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place_ID X Date</th>\n",
       "      <th>Date</th>\n",
       "      <th>Place_ID</th>\n",
       "      <th>target</th>\n",
       "      <th>target_min</th>\n",
       "      <th>target_max</th>\n",
       "      <th>target_variance</th>\n",
       "      <th>target_count</th>\n",
       "      <th>precipitable_water_entire_atmosphere</th>\n",
       "      <th>relative_humidity_2m_above_ground</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_SO2_sensor_zenith_angle</th>\n",
       "      <th>L3_SO2_solar_azimuth_angle</th>\n",
       "      <th>L3_SO2_solar_zenith_angle</th>\n",
       "      <th>L3_CH4_CH4_column_volume_mixing_ratio_dry_air</th>\n",
       "      <th>L3_CH4_aerosol_height</th>\n",
       "      <th>L3_CH4_aerosol_optical_depth</th>\n",
       "      <th>L3_CH4_sensor_azimuth_angle</th>\n",
       "      <th>L3_CH4_sensor_zenith_angle</th>\n",
       "      <th>L3_CH4_solar_azimuth_angle</th>\n",
       "      <th>L3_CH4_solar_zenith_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010Q650 X 2020-01-02</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>010Q650</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>769.50</td>\n",
       "      <td>92</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.200001</td>\n",
       "      <td>...</td>\n",
       "      <td>38.593017</td>\n",
       "      <td>-61.752587</td>\n",
       "      <td>22.363665</td>\n",
       "      <td>1793.793579</td>\n",
       "      <td>3227.855469</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>74.481049</td>\n",
       "      <td>37.501499</td>\n",
       "      <td>-62.142639</td>\n",
       "      <td>22.545118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010Q650 X 2020-01-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>010Q650</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1319.85</td>\n",
       "      <td>91</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>48.799999</td>\n",
       "      <td>...</td>\n",
       "      <td>59.624912</td>\n",
       "      <td>-67.693509</td>\n",
       "      <td>28.614804</td>\n",
       "      <td>1789.960449</td>\n",
       "      <td>3384.226562</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>75.630043</td>\n",
       "      <td>55.657486</td>\n",
       "      <td>-53.868134</td>\n",
       "      <td>19.293652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010Q650 X 2020-01-04</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>010Q650</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1181.96</td>\n",
       "      <td>96</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>...</td>\n",
       "      <td>49.839714</td>\n",
       "      <td>-78.342701</td>\n",
       "      <td>34.296977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010Q650 X 2020-01-05</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>010Q650</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1113.67</td>\n",
       "      <td>96</td>\n",
       "      <td>6.911948</td>\n",
       "      <td>21.300001</td>\n",
       "      <td>...</td>\n",
       "      <td>29.181258</td>\n",
       "      <td>-73.896588</td>\n",
       "      <td>30.545446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010Q650 X 2020-01-06</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>010Q650</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1164.82</td>\n",
       "      <td>95</td>\n",
       "      <td>13.900001</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797294</td>\n",
       "      <td>-68.612480</td>\n",
       "      <td>26.899694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Place_ID X Date        Date Place_ID  target  target_min  target_max  \\\n",
       "0  010Q650 X 2020-01-02  2020-01-02  010Q650    38.0        23.0        53.0   \n",
       "1  010Q650 X 2020-01-03  2020-01-03  010Q650    39.0        25.0        63.0   \n",
       "2  010Q650 X 2020-01-04  2020-01-04  010Q650    24.0         8.0        56.0   \n",
       "3  010Q650 X 2020-01-05  2020-01-05  010Q650    49.0        10.0        55.0   \n",
       "4  010Q650 X 2020-01-06  2020-01-06  010Q650    21.0         9.0        52.0   \n",
       "\n",
       "   target_variance  target_count  precipitable_water_entire_atmosphere  \\\n",
       "0           769.50            92                             11.000000   \n",
       "1          1319.85            91                             14.600000   \n",
       "2          1181.96            96                             16.400000   \n",
       "3          1113.67            96                              6.911948   \n",
       "4          1164.82            95                             13.900001   \n",
       "\n",
       "   relative_humidity_2m_above_ground  ...  L3_SO2_sensor_zenith_angle  \\\n",
       "0                          60.200001  ...                   38.593017   \n",
       "1                          48.799999  ...                   59.624912   \n",
       "2                          33.400002  ...                   49.839714   \n",
       "3                          21.300001  ...                   29.181258   \n",
       "4                          44.700001  ...                    0.797294   \n",
       "\n",
       "   L3_SO2_solar_azimuth_angle  L3_SO2_solar_zenith_angle  \\\n",
       "0                  -61.752587                  22.363665   \n",
       "1                  -67.693509                  28.614804   \n",
       "2                  -78.342701                  34.296977   \n",
       "3                  -73.896588                  30.545446   \n",
       "4                  -68.612480                  26.899694   \n",
       "\n",
       "   L3_CH4_CH4_column_volume_mixing_ratio_dry_air  L3_CH4_aerosol_height  \\\n",
       "0                                    1793.793579            3227.855469   \n",
       "1                                    1789.960449            3384.226562   \n",
       "2                                            NaN                    NaN   \n",
       "3                                            NaN                    NaN   \n",
       "4                                            NaN                    NaN   \n",
       "\n",
       "   L3_CH4_aerosol_optical_depth  L3_CH4_sensor_azimuth_angle  \\\n",
       "0                      0.010579                    74.481049   \n",
       "1                      0.015104                    75.630043   \n",
       "2                           NaN                          NaN   \n",
       "3                           NaN                          NaN   \n",
       "4                           NaN                          NaN   \n",
       "\n",
       "   L3_CH4_sensor_zenith_angle  L3_CH4_solar_azimuth_angle  \\\n",
       "0                   37.501499                  -62.142639   \n",
       "1                   55.657486                  -53.868134   \n",
       "2                         NaN                         NaN   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "   L3_CH4_solar_zenith_angle  \n",
       "0                  22.545118  \n",
       "1                  19.293652  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22952005-bb40-4739-b0be-48d87e20eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Here, we can extract date-related features from 'Date' column, for example, day, month, year\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
    "train_data['day'] = train_data['Date'].dt.day\n",
    "train_data['month'] = train_data['Date'].dt.month\n",
    "train_data['year'] = train_data['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67292f2-bfba-473e-b0e8-d3c37d31fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
    "test_data['day'] = test_data['Date'].dt.day\n",
    "test_data['month'] = test_data['Date'].dt.month\n",
    "test_data['year'] = test_data['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b70caa-eff2-4f9b-8f21-ddb5e15dd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd9c91c-f379-4ff9-aeb2-a72f9ce1f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Exclude target-related columns when selecting numeric columns\n",
    "numeric_columns = train_data.select_dtypes(include=['number']).drop(columns=['target', 'target_min', 'target_max', 'target_variance', 'target_count']).columns\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Handle missing values in numeric columns\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "train_data_numeric = pd.DataFrame(numeric_imputer.fit_transform(train_data[numeric_columns]), columns=numeric_columns)\n",
    "test_data_numeric = pd.DataFrame(numeric_imputer.transform(test_data[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "train_data_encoded = pd.DataFrame(categorical_encoder.fit_transform(train_data[categorical_columns]).toarray(),\n",
    "                                  columns=categorical_encoder.get_feature_names_out(categorical_columns))\n",
    "test_data_encoded = pd.DataFrame(categorical_encoder.transform(test_data[categorical_columns]).toarray(),\n",
    "                                 columns=categorical_encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Concatenate numeric and encoded categorical columns\n",
    "train_data_processed = pd.concat([train_data_numeric, train_data_encoded], axis=1)\n",
    "test_data_processed = pd.concat([test_data_numeric, test_data_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e294490-e405-440a-9ac3-3b63b2f0554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "# For simplicity, let's use one-hot encoding for 'Place_ID' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['Place_ID'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2199ea37-22c0-4546-89a5-a4be3f8f608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection/Dimensionality Reduction\n",
    "# We'll use PCA to reduce dimensionality\n",
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91bcbbed-cbc1-43cc-8deb-605b239c6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection and Training\n",
    "# Let's train a RandomForestRegressor and a GradientBoostingRegressor\n",
    "rf_regressor = RandomForestRegressor()\n",
    "gb_regressor = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452f5329-787f-49bb-90fe-6b781116a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitable_water_entire_atmosphere</th>\n",
       "      <th>relative_humidity_2m_above_ground</th>\n",
       "      <th>specific_humidity_2m_above_ground</th>\n",
       "      <th>temperature_2m_above_ground</th>\n",
       "      <th>u_component_of_wind_10m_above_ground</th>\n",
       "      <th>v_component_of_wind_10m_above_ground</th>\n",
       "      <th>L3_NO2_NO2_column_number_density</th>\n",
       "      <th>L3_NO2_NO2_slant_column_number_density</th>\n",
       "      <th>L3_NO2_absorbing_aerosol_index</th>\n",
       "      <th>L3_NO2_cloud_fraction</th>\n",
       "      <th>...</th>\n",
       "      <th>Place_ID_YAQHNNY</th>\n",
       "      <th>Place_ID_YAXBMZ6</th>\n",
       "      <th>Place_ID_YCXA4V5</th>\n",
       "      <th>Place_ID_YDW4K0H</th>\n",
       "      <th>Place_ID_YJENTFL</th>\n",
       "      <th>Place_ID_YLLOKEY</th>\n",
       "      <th>Place_ID_YLZOBFW</th>\n",
       "      <th>Place_ID_YPXSK14</th>\n",
       "      <th>Place_ID_YSIXKFZ</th>\n",
       "      <th>Place_ID_YWSFY6Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.200001</td>\n",
       "      <td>0.00804</td>\n",
       "      <td>18.516840</td>\n",
       "      <td>1.996377</td>\n",
       "      <td>-1.227395</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-1.231330</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>48.799999</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>22.546533</td>\n",
       "      <td>3.330430</td>\n",
       "      <td>-1.188108</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-1.082553</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.400000</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>27.031030</td>\n",
       "      <td>5.065727</td>\n",
       "      <td>3.500559</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-1.001242</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.911948</td>\n",
       "      <td>21.300001</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>23.971857</td>\n",
       "      <td>3.004001</td>\n",
       "      <td>1.099468</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>-0.777019</td>\n",
       "      <td>0.055765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.900001</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>16.816309</td>\n",
       "      <td>2.621787</td>\n",
       "      <td>2.670559</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.366323</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   precipitable_water_entire_atmosphere  relative_humidity_2m_above_ground  \\\n",
       "0                             11.000000                          60.200001   \n",
       "1                             14.600000                          48.799999   \n",
       "2                             16.400000                          33.400002   \n",
       "3                              6.911948                          21.300001   \n",
       "4                             13.900001                          44.700001   \n",
       "\n",
       "   specific_humidity_2m_above_ground  temperature_2m_above_ground  \\\n",
       "0                            0.00804                    18.516840   \n",
       "1                            0.00839                    22.546533   \n",
       "2                            0.00750                    27.031030   \n",
       "3                            0.00391                    23.971857   \n",
       "4                            0.00535                    16.816309   \n",
       "\n",
       "   u_component_of_wind_10m_above_ground  v_component_of_wind_10m_above_ground  \\\n",
       "0                              1.996377                             -1.227395   \n",
       "1                              3.330430                             -1.188108   \n",
       "2                              5.065727                              3.500559   \n",
       "3                              3.004001                              1.099468   \n",
       "4                              2.621787                              2.670559   \n",
       "\n",
       "   L3_NO2_NO2_column_number_density  L3_NO2_NO2_slant_column_number_density  \\\n",
       "0                          0.000074                                0.000156   \n",
       "1                          0.000076                                0.000197   \n",
       "2                          0.000067                                0.000170   \n",
       "3                          0.000083                                0.000175   \n",
       "4                          0.000070                                0.000142   \n",
       "\n",
       "   L3_NO2_absorbing_aerosol_index  L3_NO2_cloud_fraction  ...  \\\n",
       "0                       -1.231330               0.006507  ...   \n",
       "1                       -1.082553               0.018360  ...   \n",
       "2                       -1.001242               0.015904  ...   \n",
       "3                       -0.777019               0.055765  ...   \n",
       "4                        0.366323               0.028530  ...   \n",
       "\n",
       "   Place_ID_YAQHNNY  Place_ID_YAXBMZ6  Place_ID_YCXA4V5  Place_ID_YDW4K0H  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Place_ID_YJENTFL  Place_ID_YLLOKEY  Place_ID_YLZOBFW  Place_ID_YPXSK14  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Place_ID_YSIXKFZ  Place_ID_YWSFY6Q  \n",
       "0               0.0               0.0  \n",
       "1               0.0               0.0  \n",
       "2               0.0               0.0  \n",
       "3               0.0               0.0  \n",
       "4               0.0               0.0  \n",
       "\n",
       "[5 rows x 30974 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f506228-e0e9-4200-b5e3-4d202253ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize cross-validation to evaluate model performance and tune hyperparameters\n",
    "# For simplicity, we'll use cross-validation on the entire dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = preprocessor.fit_transform(train_data.drop(columns=['Date', 'target']))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train = train_data_imputed['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7866f2-66bd-4687-8ee4-172220f77445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efc512-e586-42e3-9f2f-504d131b2e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de30c0c-5485-487d-8d31-0711023594b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887e931-a997-4b83-ae44-5182732dbd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008312f9-f67e-4503-819e-1ac3ac63f8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc351e46-141c-4836-b080-b5448251d8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf81ebe-ac07-4944-a0fa-c54f7f68c251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb420daa-2ed8-4cc5-8470-8032fd74326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560a9de-7357-4720-993b-102f4ce8cf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75137bd3-7386-4b5d-ba40-8b8fd4f6945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RandomForestRegressor with cross-validation\n",
    "rf_scores = cross_val_score(rf_regressor, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_rmse_scores = np.sqrt(-rf_scores)\n",
    "print(\"Random Forest RMSE: \", rf_rmse_scores.mean())\n",
    "\n",
    "# GradientBoostingRegressor with cross-validation\n",
    "gb_scores = cross_val_score(gb_regressor, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "gb_rmse_scores = np.sqrt(-gb_scores)\n",
    "print(\"Gradient Boosting RMSE: \", gb_rmse_scores.mean())\n",
    "\n",
    "# Model Evaluation\n",
    "# Evaluate models using appropriate evaluation metrics\n",
    "# For simplicity, let's use RMSE for evaluation\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "rf_regressor.fit(X_train_scaled, y_train)\n",
    "y_train_pred_rf = rf_regressor.predict(X_train_scaled)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n",
    "rf_mae = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "rf_r2 = r2_score(y_train, y_train_pred_rf)\n",
    "print(\"Random Forest RMSE on training set: \", rf_rmse)\n",
    "print(\"Random Forest MAE on training set: \", rf_mae)\n",
    "print(\"Random Forest R-squared on training set: \", rf_r2)\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "gb_regressor.fit(X_train_scaled, y_train)\n",
    "y_train_pred_gb = gb_regressor.predict(X_train_scaled)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_gb))\n",
    "gb_mae = mean_absolute_error(y_train, y_train_pred_gb)\n",
    "gb_r2 = r2_score(y_train, y_train_pred_gb)\n",
    "print(\"Gradient Boosting RMSE on training set: \", gb_rmse)\n",
    "print(\"Gradient Boosting MAE on training set: \", gb_mae)\n",
    "print(\"Gradient Boosting R-squared on training set: \", gb_r2)\n",
    "\n",
    "# Ensemble\n",
    "ensemble_regressor = VotingRegressor([('rf', rf_regressor), ('gb', gb_regressor)])\n",
    "ensemble_regressor.fit(X_train_scaled, y_train)\n",
    "y_train_pred_ensemble = ensemble_regressor.predict(X_train_scaled)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_ensemble))\n",
    "ensemble_mae = mean_absolute_error(y_train, y_train_pred_ensemble)\n",
    "ensemble_r2 = r2_score(y_train, y_train_pred_ensemble)\n",
    "print(\"Ensemble RMSE on training set: \", ensemble_rmse)\n",
    "print(\"Ensemble MAE on training set: \", ensemble_mae)\n",
    "print(\"Ensemble R-squared on training set: \", ensemble_r2)\n",
    "\n",
    "# Prediction\n",
    "# Make predictions on the test dataset using the trained model\n",
    "X_test = preprocessor.transform(test_data_imputed.drop(columns=['Date']))\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predictions using the ensemble model\n",
    "test_predictions = ensemble_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Submission\n",
    "submission_df = pd.DataFrame({'Place_ID X Date': test_data['Place_ID X Date'], 'target': test_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
